Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:2
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1510]  eta: 1:03:30  lr: 0.000100  loss: 3.5798 (3.5798)  labels_encoder: 3.5798 (3.5798)  labels_encoder_unscaled: 3.5798 (3.5798)  time: 2.5233  data: 2.3984  max mem: 483
Epoch: [1]  [  50/1510]  eta: 0:02:18  lr: 0.000100  loss: 1.0651 (1.1707)  labels_encoder: 1.0651 (1.1707)  labels_encoder_unscaled: 1.0651 (1.1707)  time: 0.0430  data: 0.0030  max mem: 593
Epoch: [1]  [ 100/1510]  eta: 0:01:39  lr: 0.000100  loss: 0.9329 (1.0790)  labels_encoder: 0.9329 (1.0790)  labels_encoder_unscaled: 0.9329 (1.0790)  time: 0.0459  data: 0.0184  max mem: 593
Epoch: [1]  [ 150/1510]  eta: 0:01:26  lr: 0.000100  loss: 0.8624 (1.0448)  labels_encoder: 0.8624 (1.0448)  labels_encoder_unscaled: 0.8624 (1.0448)  time: 0.0485  data: 0.0172  max mem: 593
Epoch: [1]  [ 200/1510]  eta: 0:01:19  lr: 0.000100  loss: 0.9324 (1.0167)  labels_encoder: 0.9324 (1.0167)  labels_encoder_unscaled: 0.9324 (1.0167)  time: 0.0550  data: 0.0268  max mem: 593
Epoch: [1]  [ 250/1510]  eta: 0:01:13  lr: 0.000100  loss: 0.8704 (0.9902)  labels_encoder: 0.8704 (0.9902)  labels_encoder_unscaled: 0.8704 (0.9902)  time: 0.0495  data: 0.0220  max mem: 593
Epoch: [1]  [ 300/1510]  eta: 0:01:08  lr: 0.000100  loss: 0.8185 (0.9637)  labels_encoder: 0.8185 (0.9637)  labels_encoder_unscaled: 0.8185 (0.9637)  time: 0.0477  data: 0.0197  max mem: 593
Epoch: [1]  [ 350/1510]  eta: 0:01:04  lr: 0.000100  loss: 0.8337 (0.9468)  labels_encoder: 0.8337 (0.9468)  labels_encoder_unscaled: 0.8337 (0.9468)  time: 0.0473  data: 0.0200  max mem: 593
Epoch: [1]  [ 400/1510]  eta: 0:01:00  lr: 0.000100  loss: 0.8803 (0.9316)  labels_encoder: 0.8803 (0.9316)  labels_encoder_unscaled: 0.8803 (0.9316)  time: 0.0485  data: 0.0210  max mem: 593
Epoch: [1]  [ 450/1510]  eta: 0:00:57  lr: 0.000100  loss: 0.8137 (0.9225)  labels_encoder: 0.8137 (0.9225)  labels_encoder_unscaled: 0.8137 (0.9225)  time: 0.0529  data: 0.0233  max mem: 593
Epoch: [1]  [ 500/1510]  eta: 0:00:54  lr: 0.000100  loss: 0.7690 (0.9114)  labels_encoder: 0.7690 (0.9114)  labels_encoder_unscaled: 0.7690 (0.9114)  time: 0.0460  data: 0.0125  max mem: 593
Epoch: [1]  [ 550/1510]  eta: 0:00:50  lr: 0.000100  loss: 0.8178 (0.9032)  labels_encoder: 0.8178 (0.9032)  labels_encoder_unscaled: 0.8178 (0.9032)  time: 0.0482  data: 0.0217  max mem: 593
Epoch: [1]  [ 600/1510]  eta: 0:00:47  lr: 0.000100  loss: 0.7949 (0.8966)  labels_encoder: 0.7949 (0.8966)  labels_encoder_unscaled: 0.7949 (0.8966)  time: 0.0481  data: 0.0189  max mem: 593
Epoch: [1]  [ 650/1510]  eta: 0:00:44  lr: 0.000100  loss: 0.7990 (0.8904)  labels_encoder: 0.7990 (0.8904)  labels_encoder_unscaled: 0.7990 (0.8904)  time: 0.0478  data: 0.0212  max mem: 593
Epoch: [1]  [ 700/1510]  eta: 0:00:42  lr: 0.000100  loss: 0.7727 (0.8831)  labels_encoder: 0.7727 (0.8831)  labels_encoder_unscaled: 0.7727 (0.8831)  time: 0.0473  data: 0.0198  max mem: 593
Epoch: [1]  [ 750/1510]  eta: 0:00:39  lr: 0.000100  loss: 0.8089 (0.8762)  labels_encoder: 0.8089 (0.8762)  labels_encoder_unscaled: 0.8089 (0.8762)  time: 0.0490  data: 0.0208  max mem: 593
Epoch: [1]  [ 800/1510]  eta: 0:00:36  lr: 0.000100  loss: 0.7510 (0.8693)  labels_encoder: 0.7510 (0.8693)  labels_encoder_unscaled: 0.7510 (0.8693)  time: 0.0500  data: 0.0148  max mem: 593
Epoch: [1]  [ 850/1510]  eta: 0:00:34  lr: 0.000100  loss: 0.7432 (0.8644)  labels_encoder: 0.7432 (0.8644)  labels_encoder_unscaled: 0.7432 (0.8644)  time: 0.0506  data: 0.0210  max mem: 593
Epoch: [1]  [ 900/1510]  eta: 0:00:31  lr: 0.000100  loss: 0.6987 (0.8573)  labels_encoder: 0.6987 (0.8573)  labels_encoder_unscaled: 0.6987 (0.8573)  time: 0.0549  data: 0.0210  max mem: 593
Epoch: [1]  [ 950/1510]  eta: 0:00:28  lr: 0.000100  loss: 0.6787 (0.8509)  labels_encoder: 0.6787 (0.8509)  labels_encoder_unscaled: 0.6787 (0.8509)  time: 0.0461  data: 0.0064  max mem: 593
Epoch: [1]  [1000/1510]  eta: 0:00:26  lr: 0.000100  loss: 0.7325 (0.8443)  labels_encoder: 0.7325 (0.8443)  labels_encoder_unscaled: 0.7325 (0.8443)  time: 0.0482  data: 0.0200  max mem: 593
Epoch: [1]  [1050/1510]  eta: 0:00:23  lr: 0.000100  loss: 0.7491 (0.8389)  labels_encoder: 0.7491 (0.8389)  labels_encoder_unscaled: 0.7491 (0.8389)  time: 0.0527  data: 0.0229  max mem: 593
Epoch: [1]  [1100/1510]  eta: 0:00:20  lr: 0.000100  loss: 0.7106 (0.8342)  labels_encoder: 0.7106 (0.8342)  labels_encoder_unscaled: 0.7106 (0.8342)  time: 0.0497  data: 0.0212  max mem: 593
Epoch: [1]  [1150/1510]  eta: 0:00:18  lr: 0.000100  loss: 0.7236 (0.8292)  labels_encoder: 0.7236 (0.8292)  labels_encoder_unscaled: 0.7236 (0.8292)  time: 0.0477  data: 0.0176  max mem: 593
Epoch: [1]  [1200/1510]  eta: 0:00:15  lr: 0.000100  loss: 0.6405 (0.8239)  labels_encoder: 0.6405 (0.8239)  labels_encoder_unscaled: 0.6405 (0.8239)  time: 0.0505  data: 0.0203  max mem: 593
Epoch: [1]  [1250/1510]  eta: 0:00:13  lr: 0.000100  loss: 0.7565 (0.8207)  labels_encoder: 0.7565 (0.8207)  labels_encoder_unscaled: 0.7565 (0.8207)  time: 0.0482  data: 0.0187  max mem: 593
Epoch: [1]  [1300/1510]  eta: 0:00:10  lr: 0.000100  loss: 0.7251 (0.8155)  labels_encoder: 0.7251 (0.8155)  labels_encoder_unscaled: 0.7251 (0.8155)  time: 0.0488  data: 0.0204  max mem: 593
Epoch: [1]  [1350/1510]  eta: 0:00:08  lr: 0.000100  loss: 0.6964 (0.8111)  labels_encoder: 0.6964 (0.8111)  labels_encoder_unscaled: 0.6964 (0.8111)  time: 0.0491  data: 0.0188  max mem: 593
Epoch: [1]  [1400/1510]  eta: 0:00:05  lr: 0.000100  loss: 0.7405 (0.8082)  labels_encoder: 0.7405 (0.8082)  labels_encoder_unscaled: 0.7405 (0.8082)  time: 0.0489  data: 0.0198  max mem: 593
Epoch: [1]  [1450/1510]  eta: 0:00:03  lr: 0.000100  loss: 0.6903 (0.8042)  labels_encoder: 0.6903 (0.8042)  labels_encoder_unscaled: 0.6903 (0.8042)  time: 0.0493  data: 0.0220  max mem: 593
Epoch: [1]  [1500/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6883 (0.8012)  labels_encoder: 0.6883 (0.8012)  labels_encoder_unscaled: 0.6883 (0.8012)  time: 0.0515  data: 0.0200  max mem: 593
Epoch: [1]  [1509/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6883 (0.8003)  labels_encoder: 0.6883 (0.8003)  labels_encoder_unscaled: 0.6883 (0.8003)  time: 0.0467  data: 0.0156  max mem: 593
Epoch: [1] Total time: 0:01:16 (0.0505 s / it)
Averaged stats: lr: 0.000100  loss: 0.6883 (0.8003)  labels_encoder: 0.6883 (0.8003)  labels_encoder_unscaled: 0.6883 (0.8003)
Test:  [  0/559]  eta: 0:16:35  loss: 0.5647 (0.5647)  labels_encoder: 0.5647 (0.5647)  labels_encoder_unscaled: 0.5647 (0.5647)  time: 1.7802  data: 1.7599  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.8022 (0.9952)  labels_encoder: 0.8022 (0.9952)  labels_encoder_unscaled: 0.8022 (0.9952)  time: 0.0512  data: 0.0347  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.4878 (0.9314)  labels_encoder: 0.4878 (0.9314)  labels_encoder_unscaled: 0.4878 (0.9314)  time: 0.0463  data: 0.0303  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.7631 (0.9575)  labels_encoder: 0.7631 (0.9575)  labels_encoder_unscaled: 0.7631 (0.9575)  time: 0.0489  data: 0.0331  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.4334 (0.8714)  labels_encoder: 0.4334 (0.8714)  labels_encoder_unscaled: 0.4334 (0.8714)  time: 0.0483  data: 0.0327  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7552 (0.9975)  labels_encoder: 0.7552 (0.9975)  labels_encoder_unscaled: 0.7552 (0.9975)  time: 0.0510  data: 0.0334  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1246 (1.0380)  labels_encoder: 1.1246 (1.0380)  labels_encoder_unscaled: 1.1246 (1.0380)  time: 0.0483  data: 0.0331  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7894 (1.0684)  labels_encoder: 0.7894 (1.0684)  labels_encoder_unscaled: 0.7894 (1.0684)  time: 0.0479  data: 0.0323  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3794 (1.0429)  labels_encoder: 0.3794 (1.0429)  labels_encoder_unscaled: 0.3794 (1.0429)  time: 0.0496  data: 0.0339  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4184 (1.0152)  labels_encoder: 0.4184 (1.0152)  labels_encoder_unscaled: 0.4184 (1.0152)  time: 0.0490  data: 0.0333  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5587 (0.9946)  labels_encoder: 0.5587 (0.9946)  labels_encoder_unscaled: 0.5587 (0.9946)  time: 0.0521  data: 0.0356  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6878 (0.9659)  labels_encoder: 0.6878 (0.9659)  labels_encoder_unscaled: 0.6878 (0.9659)  time: 0.0453  data: 0.0303  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3941 (0.9588)  labels_encoder: 0.3941 (0.9588)  labels_encoder_unscaled: 0.3941 (0.9588)  time: 0.0455  data: 0.0309  max mem: 593
Test: Total time: 0:00:29 (0.0525 s / it)
Averaged stats: loss: 0.3941 (0.9588)  labels_encoder: 0.3941 (0.9588)  labels_encoder_unscaled: 0.3941 (0.9588)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1108, mcAP: 0.8631

BaseballPitch: 0.0198
BasketballDunk: 0.0510
Billiards: 0.0055
CleanAndJerk: 0.4099
CliffDiving: 0.3462
CricketBowling: 0.0944
CricketShot: 0.0960
Diving: 0.0032
FrisbeeCatch: 0.0950
GolfSwing: 0.0598
HammerThrow: 0.0869
HighJump: 0.0373
JavelinThrow: 0.0364
LongJump: 0.2937
PoleVault: 0.0928
Shotput: 0.1198
SoccerPenalty: 0.0528
TennisSwing: 0.1783
ThrowDiscus: 0.0231
VolleyballSpiking: 0.1146
Epoch: [2]  [   0/1510]  eta: 0:46:07  lr: 0.000010  loss: 0.6038 (0.6038)  labels_encoder: 0.6038 (0.6038)  labels_encoder_unscaled: 0.6038 (0.6038)  time: 1.8327  data: 1.8020  max mem: 593
Epoch: [2]  [  50/1510]  eta: 0:02:06  lr: 0.000010  loss: 0.6527 (0.6823)  labels_encoder: 0.6527 (0.6823)  labels_encoder_unscaled: 0.6527 (0.6823)  time: 0.0475  data: 0.0119  max mem: 593
Epoch: [2]  [ 100/1510]  eta: 0:01:33  lr: 0.000010  loss: 0.7002 (0.6961)  labels_encoder: 0.7002 (0.6961)  labels_encoder_unscaled: 0.7002 (0.6961)  time: 0.0459  data: 0.0181  max mem: 593
Epoch: [2]  [ 150/1510]  eta: 0:01:22  lr: 0.000010  loss: 0.6792 (0.6900)  labels_encoder: 0.6792 (0.6900)  labels_encoder_unscaled: 0.6792 (0.6900)  time: 0.0518  data: 0.0240  max mem: 593
Epoch: [2]  [ 200/1510]  eta: 0:01:15  lr: 0.000010  loss: 0.6242 (0.6854)  labels_encoder: 0.6242 (0.6854)  labels_encoder_unscaled: 0.6242 (0.6854)  time: 0.0484  data: 0.0199  max mem: 593
Epoch: [2]  [ 250/1510]  eta: 0:01:10  lr: 0.000010  loss: 0.5997 (0.6791)  labels_encoder: 0.5997 (0.6791)  labels_encoder_unscaled: 0.5997 (0.6791)  time: 0.0515  data: 0.0221  max mem: 593
Epoch: [2]  [ 300/1510]  eta: 0:01:06  lr: 0.000010  loss: 0.6287 (0.6738)  labels_encoder: 0.6287 (0.6738)  labels_encoder_unscaled: 0.6287 (0.6738)  time: 0.0483  data: 0.0198  max mem: 593
Epoch: [2]  [ 350/1510]  eta: 0:01:02  lr: 0.000010  loss: 0.6492 (0.6694)  labels_encoder: 0.6492 (0.6694)  labels_encoder_unscaled: 0.6492 (0.6694)  time: 0.0493  data: 0.0208  max mem: 593
Epoch: [2]  [ 400/1510]  eta: 0:00:59  lr: 0.000010  loss: 0.5850 (0.6639)  labels_encoder: 0.5850 (0.6639)  labels_encoder_unscaled: 0.5850 (0.6639)  time: 0.0503  data: 0.0178  max mem: 593
Epoch: [2]  [ 450/1510]  eta: 0:00:55  lr: 0.000010  loss: 0.5752 (0.6600)  labels_encoder: 0.5752 (0.6600)  labels_encoder_unscaled: 0.5752 (0.6600)  time: 0.0482  data: 0.0200  max mem: 593
Epoch: [2]  [ 500/1510]  eta: 0:00:52  lr: 0.000010  loss: 0.5835 (0.6550)  labels_encoder: 0.5835 (0.6550)  labels_encoder_unscaled: 0.5835 (0.6550)  time: 0.0493  data: 0.0221  max mem: 593
Epoch: [2]  [ 550/1510]  eta: 0:00:50  lr: 0.000010  loss: 0.6333 (0.6535)  labels_encoder: 0.6333 (0.6535)  labels_encoder_unscaled: 0.6333 (0.6535)  time: 0.0499  data: 0.0232  max mem: 593
Epoch: [2]  [ 600/1510]  eta: 0:00:47  lr: 0.000010  loss: 0.6355 (0.6520)  labels_encoder: 0.6355 (0.6520)  labels_encoder_unscaled: 0.6355 (0.6520)  time: 0.0506  data: 0.0232  max mem: 593
Epoch: [2]  [ 650/1510]  eta: 0:00:44  lr: 0.000010  loss: 0.6418 (0.6515)  labels_encoder: 0.6418 (0.6515)  labels_encoder_unscaled: 0.6418 (0.6515)  time: 0.0484  data: 0.0213  max mem: 593
Epoch: [2]  [ 700/1510]  eta: 0:00:41  lr: 0.000010  loss: 0.5319 (0.6479)  labels_encoder: 0.5319 (0.6479)  labels_encoder_unscaled: 0.5319 (0.6479)  time: 0.0481  data: 0.0219  max mem: 593
Epoch: [2]  [ 750/1510]  eta: 0:00:38  lr: 0.000010  loss: 0.5530 (0.6461)  labels_encoder: 0.5530 (0.6461)  labels_encoder_unscaled: 0.5530 (0.6461)  time: 0.0479  data: 0.0227  max mem: 593
Epoch: [2]  [ 800/1510]  eta: 0:00:36  lr: 0.000010  loss: 0.6010 (0.6451)  labels_encoder: 0.6010 (0.6451)  labels_encoder_unscaled: 0.6010 (0.6451)  time: 0.0494  data: 0.0208  max mem: 593
Epoch: [2]  [ 850/1510]  eta: 0:00:33  lr: 0.000010  loss: 0.5897 (0.6429)  labels_encoder: 0.5897 (0.6429)  labels_encoder_unscaled: 0.5897 (0.6429)  time: 0.0520  data: 0.0239  max mem: 593
Epoch: [2]  [ 900/1510]  eta: 0:00:31  lr: 0.000010  loss: 0.6218 (0.6413)  labels_encoder: 0.6218 (0.6413)  labels_encoder_unscaled: 0.6218 (0.6413)  time: 0.0505  data: 0.0230  max mem: 593
Epoch: [2]  [ 950/1510]  eta: 0:00:28  lr: 0.000010  loss: 0.5450 (0.6391)  labels_encoder: 0.5450 (0.6391)  labels_encoder_unscaled: 0.5450 (0.6391)  time: 0.0471  data: 0.0199  max mem: 593
Epoch: [2]  [1000/1510]  eta: 0:00:25  lr: 0.000010  loss: 0.5617 (0.6368)  labels_encoder: 0.5617 (0.6368)  labels_encoder_unscaled: 0.5617 (0.6368)  time: 0.0474  data: 0.0213  max mem: 593
Epoch: [2]  [1050/1510]  eta: 0:00:23  lr: 0.000010  loss: 0.6351 (0.6370)  labels_encoder: 0.6351 (0.6370)  labels_encoder_unscaled: 0.6351 (0.6370)  time: 0.0457  data: 0.0161  max mem: 593
Epoch: [2]  [1100/1510]  eta: 0:00:20  lr: 0.000010  loss: 0.5893 (0.6370)  labels_encoder: 0.5893 (0.6370)  labels_encoder_unscaled: 0.5893 (0.6370)  time: 0.0509  data: 0.0244  max mem: 593
Epoch: [2]  [1150/1510]  eta: 0:00:18  lr: 0.000010  loss: 0.5685 (0.6354)  labels_encoder: 0.5685 (0.6354)  labels_encoder_unscaled: 0.5685 (0.6354)  time: 0.0491  data: 0.0207  max mem: 593
Epoch: [2]  [1200/1510]  eta: 0:00:15  lr: 0.000010  loss: 0.5478 (0.6338)  labels_encoder: 0.5478 (0.6338)  labels_encoder_unscaled: 0.5478 (0.6338)  time: 0.0503  data: 0.0219  max mem: 593
Epoch: [2]  [1250/1510]  eta: 0:00:13  lr: 0.000010  loss: 0.5082 (0.6318)  labels_encoder: 0.5082 (0.6318)  labels_encoder_unscaled: 0.5082 (0.6318)  time: 0.0474  data: 0.0123  max mem: 593
Epoch: [2]  [1300/1510]  eta: 0:00:10  lr: 0.000010  loss: 0.5905 (0.6310)  labels_encoder: 0.5905 (0.6310)  labels_encoder_unscaled: 0.5905 (0.6310)  time: 0.0483  data: 0.0200  max mem: 593
Epoch: [2]  [1350/1510]  eta: 0:00:08  lr: 0.000010  loss: 0.5641 (0.6302)  labels_encoder: 0.5641 (0.6302)  labels_encoder_unscaled: 0.5641 (0.6302)  time: 0.0495  data: 0.0210  max mem: 593
Epoch: [2]  [1400/1510]  eta: 0:00:05  lr: 0.000010  loss: 0.6606 (0.6292)  labels_encoder: 0.6606 (0.6292)  labels_encoder_unscaled: 0.6606 (0.6292)  time: 0.0524  data: 0.0233  max mem: 593
Epoch: [2]  [1450/1510]  eta: 0:00:02  lr: 0.000010  loss: 0.5866 (0.6287)  labels_encoder: 0.5866 (0.6287)  labels_encoder_unscaled: 0.5866 (0.6287)  time: 0.0472  data: 0.0159  max mem: 593
Epoch: [2]  [1500/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5302 (0.6267)  labels_encoder: 0.5302 (0.6267)  labels_encoder_unscaled: 0.5302 (0.6267)  time: 0.0500  data: 0.0207  max mem: 593
Epoch: [2]  [1509/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5516 (0.6267)  labels_encoder: 0.5516 (0.6267)  labels_encoder_unscaled: 0.5516 (0.6267)  time: 0.0469  data: 0.0180  max mem: 593
Epoch: [2] Total time: 0:01:15 (0.0502 s / it)
Averaged stats: lr: 0.000010  loss: 0.5516 (0.6267)  labels_encoder: 0.5516 (0.6267)  labels_encoder_unscaled: 0.5516 (0.6267)
Test:  [  0/559]  eta: 0:16:34  loss: 0.5956 (0.5956)  labels_encoder: 0.5956 (0.5956)  labels_encoder_unscaled: 0.5956 (0.5956)  time: 1.7790  data: 1.7585  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.6832 (0.8527)  labels_encoder: 0.6832 (0.8527)  labels_encoder_unscaled: 0.6832 (0.8527)  time: 0.0531  data: 0.0375  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.7575 (0.8752)  labels_encoder: 0.7575 (0.8752)  labels_encoder_unscaled: 0.7575 (0.8752)  time: 0.0529  data: 0.0379  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.5605 (0.8989)  labels_encoder: 0.5605 (0.8989)  labels_encoder_unscaled: 0.5605 (0.8989)  time: 0.0484  data: 0.0315  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6615 (0.8382)  labels_encoder: 0.6615 (0.8382)  labels_encoder_unscaled: 0.6615 (0.8382)  time: 0.0479  data: 0.0322  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7719 (0.9466)  labels_encoder: 0.7719 (0.9466)  labels_encoder_unscaled: 0.7719 (0.9466)  time: 0.0537  data: 0.0358  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1418 (0.9934)  labels_encoder: 1.1418 (0.9934)  labels_encoder_unscaled: 1.1418 (0.9934)  time: 0.0559  data: 0.0403  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8010 (1.0113)  labels_encoder: 0.8010 (1.0113)  labels_encoder_unscaled: 0.8010 (1.0113)  time: 0.0516  data: 0.0333  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3391 (0.9863)  labels_encoder: 0.3391 (0.9863)  labels_encoder_unscaled: 0.3391 (0.9863)  time: 0.0476  data: 0.0324  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3753 (0.9595)  labels_encoder: 0.3753 (0.9595)  labels_encoder_unscaled: 0.3753 (0.9595)  time: 0.0500  data: 0.0331  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6123 (0.9418)  labels_encoder: 0.6123 (0.9418)  labels_encoder_unscaled: 0.6123 (0.9418)  time: 0.0470  data: 0.0319  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7720 (0.9151)  labels_encoder: 0.7720 (0.9151)  labels_encoder_unscaled: 0.7720 (0.9151)  time: 0.0459  data: 0.0295  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4210 (0.9087)  labels_encoder: 0.4210 (0.9087)  labels_encoder_unscaled: 0.4210 (0.9087)  time: 0.0454  data: 0.0293  max mem: 593
Test: Total time: 0:00:29 (0.0534 s / it)
Averaged stats: loss: 0.4210 (0.9087)  labels_encoder: 0.4210 (0.9087)  labels_encoder_unscaled: 0.4210 (0.9087)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1231, mcAP: 0.8761

BaseballPitch: 0.0367
BasketballDunk: 0.1110
Billiards: 0.0050
CleanAndJerk: 0.3814
CliffDiving: 0.3189
CricketBowling: 0.1057
CricketShot: 0.1149
Diving: 0.0044
FrisbeeCatch: 0.1570
GolfSwing: 0.0739
HammerThrow: 0.0634
HighJump: 0.0338
JavelinThrow: 0.0543
LongJump: 0.3181
PoleVault: 0.1031
Shotput: 0.1259
SoccerPenalty: 0.0482
TennisSwing: 0.1837
ThrowDiscus: 0.0597
VolleyballSpiking: 0.1624
Epoch: [3]  [   0/1510]  eta: 0:50:30  lr: 0.000001  loss: 0.4087 (0.4087)  labels_encoder: 0.4087 (0.4087)  labels_encoder_unscaled: 0.4087 (0.4087)  time: 2.0070  data: 1.9652  max mem: 593
Epoch: [3]  [  50/1510]  eta: 0:02:05  lr: 0.000001  loss: 0.5969 (0.6072)  labels_encoder: 0.5969 (0.6072)  labels_encoder_unscaled: 0.5969 (0.6072)  time: 0.0494  data: 0.0109  max mem: 593
Epoch: [3]  [ 100/1510]  eta: 0:01:36  lr: 0.000001  loss: 0.5598 (0.5928)  labels_encoder: 0.5598 (0.5928)  labels_encoder_unscaled: 0.5598 (0.5928)  time: 0.0486  data: 0.0201  max mem: 593
Epoch: [3]  [ 150/1510]  eta: 0:01:24  lr: 0.000001  loss: 0.5768 (0.5980)  labels_encoder: 0.5768 (0.5980)  labels_encoder_unscaled: 0.5768 (0.5980)  time: 0.0488  data: 0.0157  max mem: 593
Epoch: [3]  [ 200/1510]  eta: 0:01:17  lr: 0.000001  loss: 0.5095 (0.5926)  labels_encoder: 0.5095 (0.5926)  labels_encoder_unscaled: 0.5095 (0.5926)  time: 0.0471  data: 0.0169  max mem: 593
Epoch: [3]  [ 250/1510]  eta: 0:01:11  lr: 0.000001  loss: 0.5845 (0.5924)  labels_encoder: 0.5845 (0.5924)  labels_encoder_unscaled: 0.5845 (0.5924)  time: 0.0509  data: 0.0226  max mem: 593
Epoch: [3]  [ 300/1510]  eta: 0:01:08  lr: 0.000001  loss: 0.5315 (0.5906)  labels_encoder: 0.5315 (0.5906)  labels_encoder_unscaled: 0.5315 (0.5906)  time: 0.0555  data: 0.0282  max mem: 593
Epoch: [3]  [ 350/1510]  eta: 0:01:04  lr: 0.000001  loss: 0.6182 (0.5913)  labels_encoder: 0.6182 (0.5913)  labels_encoder_unscaled: 0.6182 (0.5913)  time: 0.0489  data: 0.0228  max mem: 593
Epoch: [3]  [ 400/1510]  eta: 0:01:00  lr: 0.000001  loss: 0.6055 (0.5954)  labels_encoder: 0.6055 (0.5954)  labels_encoder_unscaled: 0.6055 (0.5954)  time: 0.0487  data: 0.0160  max mem: 593
Epoch: [3]  [ 450/1510]  eta: 0:00:57  lr: 0.000001  loss: 0.5754 (0.5958)  labels_encoder: 0.5754 (0.5958)  labels_encoder_unscaled: 0.5754 (0.5958)  time: 0.0493  data: 0.0234  max mem: 593
Epoch: [3]  [ 500/1510]  eta: 0:00:54  lr: 0.000001  loss: 0.5461 (0.5943)  labels_encoder: 0.5461 (0.5943)  labels_encoder_unscaled: 0.5461 (0.5943)  time: 0.0479  data: 0.0217  max mem: 593
Epoch: [3]  [ 550/1510]  eta: 0:00:50  lr: 0.000001  loss: 0.5647 (0.5930)  labels_encoder: 0.5647 (0.5930)  labels_encoder_unscaled: 0.5647 (0.5930)  time: 0.0486  data: 0.0202  max mem: 593
Epoch: [3]  [ 600/1510]  eta: 0:00:48  lr: 0.000001  loss: 0.5694 (0.5926)  labels_encoder: 0.5694 (0.5926)  labels_encoder_unscaled: 0.5694 (0.5926)  time: 0.0504  data: 0.0229  max mem: 593
Epoch: [3]  [ 650/1510]  eta: 0:00:45  lr: 0.000001  loss: 0.6124 (0.5941)  labels_encoder: 0.6124 (0.5941)  labels_encoder_unscaled: 0.6124 (0.5941)  time: 0.0488  data: 0.0189  max mem: 593
Epoch: [3]  [ 700/1510]  eta: 0:00:42  lr: 0.000001  loss: 0.5901 (0.5922)  labels_encoder: 0.5901 (0.5922)  labels_encoder_unscaled: 0.5901 (0.5922)  time: 0.0497  data: 0.0214  max mem: 593
Epoch: [3]  [ 750/1510]  eta: 0:00:39  lr: 0.000001  loss: 0.5625 (0.5925)  labels_encoder: 0.5625 (0.5925)  labels_encoder_unscaled: 0.5625 (0.5925)  time: 0.0480  data: 0.0197  max mem: 593
Epoch: [3]  [ 800/1510]  eta: 0:00:36  lr: 0.000001  loss: 0.5602 (0.5908)  labels_encoder: 0.5602 (0.5908)  labels_encoder_unscaled: 0.5602 (0.5908)  time: 0.0484  data: 0.0152  max mem: 593
Epoch: [3]  [ 850/1510]  eta: 0:00:33  lr: 0.000001  loss: 0.5634 (0.5914)  labels_encoder: 0.5634 (0.5914)  labels_encoder_unscaled: 0.5634 (0.5914)  time: 0.0471  data: 0.0188  max mem: 593
Epoch: [3]  [ 900/1510]  eta: 0:00:31  lr: 0.000001  loss: 0.5459 (0.5902)  labels_encoder: 0.5459 (0.5902)  labels_encoder_unscaled: 0.5459 (0.5902)  time: 0.0516  data: 0.0233  max mem: 593
Epoch: [3]  [ 950/1510]  eta: 0:00:28  lr: 0.000001  loss: 0.5954 (0.5898)  labels_encoder: 0.5954 (0.5898)  labels_encoder_unscaled: 0.5954 (0.5898)  time: 0.0499  data: 0.0220  max mem: 593
Epoch: [3]  [1000/1510]  eta: 0:00:26  lr: 0.000001  loss: 0.5823 (0.5895)  labels_encoder: 0.5823 (0.5895)  labels_encoder_unscaled: 0.5823 (0.5895)  time: 0.0476  data: 0.0172  max mem: 593
Epoch: [3]  [1050/1510]  eta: 0:00:23  lr: 0.000001  loss: 0.5878 (0.5892)  labels_encoder: 0.5878 (0.5892)  labels_encoder_unscaled: 0.5878 (0.5892)  time: 0.0482  data: 0.0199  max mem: 593
Epoch: [3]  [1100/1510]  eta: 0:00:20  lr: 0.000001  loss: 0.5755 (0.5889)  labels_encoder: 0.5755 (0.5889)  labels_encoder_unscaled: 0.5755 (0.5889)  time: 0.0482  data: 0.0197  max mem: 593
Epoch: [3]  [1150/1510]  eta: 0:00:18  lr: 0.000001  loss: 0.5384 (0.5883)  labels_encoder: 0.5384 (0.5883)  labels_encoder_unscaled: 0.5384 (0.5883)  time: 0.0483  data: 0.0204  max mem: 593
Epoch: [3]  [1200/1510]  eta: 0:00:15  lr: 0.000001  loss: 0.6062 (0.5887)  labels_encoder: 0.6062 (0.5887)  labels_encoder_unscaled: 0.6062 (0.5887)  time: 0.0478  data: 0.0200  max mem: 593
Epoch: [3]  [1250/1510]  eta: 0:00:13  lr: 0.000001  loss: 0.5583 (0.5886)  labels_encoder: 0.5583 (0.5886)  labels_encoder_unscaled: 0.5583 (0.5886)  time: 0.0495  data: 0.0216  max mem: 593
Epoch: [3]  [1300/1510]  eta: 0:00:10  lr: 0.000001  loss: 0.5129 (0.5882)  labels_encoder: 0.5129 (0.5882)  labels_encoder_unscaled: 0.5129 (0.5882)  time: 0.0493  data: 0.0211  max mem: 593
Epoch: [3]  [1350/1510]  eta: 0:00:08  lr: 0.000001  loss: 0.5582 (0.5881)  labels_encoder: 0.5582 (0.5881)  labels_encoder_unscaled: 0.5582 (0.5881)  time: 0.0515  data: 0.0222  max mem: 593
Epoch: [3]  [1400/1510]  eta: 0:00:05  lr: 0.000001  loss: 0.5537 (0.5885)  labels_encoder: 0.5537 (0.5885)  labels_encoder_unscaled: 0.5537 (0.5885)  time: 0.0472  data: 0.0187  max mem: 593
Epoch: [3]  [1450/1510]  eta: 0:00:03  lr: 0.000001  loss: 0.5456 (0.5891)  labels_encoder: 0.5456 (0.5891)  labels_encoder_unscaled: 0.5456 (0.5891)  time: 0.0469  data: 0.0186  max mem: 593
Epoch: [3]  [1500/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5855 (0.5891)  labels_encoder: 0.5855 (0.5891)  labels_encoder_unscaled: 0.5855 (0.5891)  time: 0.0466  data: 0.0198  max mem: 593
Epoch: [3]  [1509/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5958 (0.5889)  labels_encoder: 0.5958 (0.5889)  labels_encoder_unscaled: 0.5958 (0.5889)  time: 0.0450  data: 0.0185  max mem: 593
Epoch: [3] Total time: 0:01:16 (0.0504 s / it)
Averaged stats: lr: 0.000001  loss: 0.5958 (0.5889)  labels_encoder: 0.5958 (0.5889)  labels_encoder_unscaled: 0.5958 (0.5889)
Test:  [  0/559]  eta: 0:16:54  loss: 0.6123 (0.6123)  labels_encoder: 0.6123 (0.6123)  labels_encoder_unscaled: 0.6123 (0.6123)  time: 1.8148  data: 1.7977  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 0.7550 (0.8900)  labels_encoder: 0.7550 (0.8900)  labels_encoder_unscaled: 0.7550 (0.8900)  time: 0.0485  data: 0.0327  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.4816 (0.8294)  labels_encoder: 0.4816 (0.8294)  labels_encoder_unscaled: 0.4816 (0.8294)  time: 0.0490  data: 0.0330  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5061 (0.8590)  labels_encoder: 0.5061 (0.8590)  labels_encoder_unscaled: 0.5061 (0.8590)  time: 0.0474  data: 0.0319  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.5613 (0.8025)  labels_encoder: 0.5613 (0.8025)  labels_encoder_unscaled: 0.5613 (0.8025)  time: 0.0463  data: 0.0312  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7786 (0.9030)  labels_encoder: 0.7786 (0.9030)  labels_encoder_unscaled: 0.7786 (0.9030)  time: 0.0463  data: 0.0314  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1375 (0.9608)  labels_encoder: 1.1375 (0.9608)  labels_encoder_unscaled: 1.1375 (0.9608)  time: 0.0480  data: 0.0330  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7805 (0.9798)  labels_encoder: 0.7805 (0.9798)  labels_encoder_unscaled: 0.7805 (0.9798)  time: 0.0489  data: 0.0338  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3490 (0.9557)  labels_encoder: 0.3490 (0.9557)  labels_encoder_unscaled: 0.3490 (0.9557)  time: 0.0571  data: 0.0410  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3929 (0.9316)  labels_encoder: 0.3929 (0.9316)  labels_encoder_unscaled: 0.3929 (0.9316)  time: 0.0509  data: 0.0351  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5613 (0.9142)  labels_encoder: 0.5613 (0.9142)  labels_encoder_unscaled: 0.5613 (0.9142)  time: 0.0482  data: 0.0321  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7422 (0.8896)  labels_encoder: 0.7422 (0.8896)  labels_encoder_unscaled: 0.7422 (0.8896)  time: 0.0464  data: 0.0307  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3752 (0.8836)  labels_encoder: 0.3752 (0.8836)  labels_encoder_unscaled: 0.3752 (0.8836)  time: 0.0449  data: 0.0297  max mem: 593
Test: Total time: 0:00:29 (0.0526 s / it)
Averaged stats: loss: 0.3752 (0.8836)  labels_encoder: 0.3752 (0.8836)  labels_encoder_unscaled: 0.3752 (0.8836)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1335, mcAP: 0.8832

BaseballPitch: 0.0560
BasketballDunk: 0.0993
Billiards: 0.0059
CleanAndJerk: 0.4015
CliffDiving: 0.4603
CricketBowling: 0.0899
CricketShot: 0.1098
Diving: 0.0064
FrisbeeCatch: 0.1390
GolfSwing: 0.0664
HammerThrow: 0.1095
HighJump: 0.0548
JavelinThrow: 0.0509
LongJump: 0.3318
PoleVault: 0.1146
Shotput: 0.1303
SoccerPenalty: 0.0518
TennisSwing: 0.1619
ThrowDiscus: 0.0769
VolleyballSpiking: 0.1536
Epoch: [4]  [   0/1510]  eta: 0:45:38  lr: 0.000000  loss: 0.4573 (0.4573)  labels_encoder: 0.4573 (0.4573)  labels_encoder_unscaled: 0.4573 (0.4573)  time: 1.8137  data: 1.7818  max mem: 593
Epoch: [4]  [  50/1510]  eta: 0:02:24  lr: 0.000000  loss: 0.6239 (0.5981)  labels_encoder: 0.6239 (0.5981)  labels_encoder_unscaled: 0.6239 (0.5981)  time: 0.0635  data: 0.0245  max mem: 593
Epoch: [4]  [ 100/1510]  eta: 0:01:43  lr: 0.000000  loss: 0.5612 (0.5954)  labels_encoder: 0.5612 (0.5954)  labels_encoder_unscaled: 0.5612 (0.5954)  time: 0.0494  data: 0.0170  max mem: 593
Epoch: [4]  [ 150/1510]  eta: 0:01:29  lr: 0.000000  loss: 0.5789 (0.5862)  labels_encoder: 0.5789 (0.5862)  labels_encoder_unscaled: 0.5789 (0.5862)  time: 0.0499  data: 0.0189  max mem: 593
Epoch: [4]  [ 200/1510]  eta: 0:01:20  lr: 0.000000  loss: 0.5567 (0.5818)  labels_encoder: 0.5567 (0.5818)  labels_encoder_unscaled: 0.5567 (0.5818)  time: 0.0478  data: 0.0167  max mem: 593
Epoch: [4]  [ 250/1510]  eta: 0:01:16  lr: 0.000000  loss: 0.5353 (0.5783)  labels_encoder: 0.5353 (0.5783)  labels_encoder_unscaled: 0.5353 (0.5783)  time: 0.0546  data: 0.0261  max mem: 593
Epoch: [4]  [ 300/1510]  eta: 0:01:11  lr: 0.000000  loss: 0.5739 (0.5782)  labels_encoder: 0.5739 (0.5782)  labels_encoder_unscaled: 0.5739 (0.5782)  time: 0.0551  data: 0.0275  max mem: 593
Epoch: [4]  [ 350/1510]  eta: 0:01:07  lr: 0.000000  loss: 0.5945 (0.5808)  labels_encoder: 0.5945 (0.5808)  labels_encoder_unscaled: 0.5945 (0.5808)  time: 0.0575  data: 0.0293  max mem: 593
Epoch: [4]  [ 400/1510]  eta: 0:01:03  lr: 0.000000  loss: 0.5356 (0.5826)  labels_encoder: 0.5356 (0.5826)  labels_encoder_unscaled: 0.5356 (0.5826)  time: 0.0495  data: 0.0195  max mem: 593
Epoch: [4]  [ 450/1510]  eta: 0:01:00  lr: 0.000000  loss: 0.5770 (0.5827)  labels_encoder: 0.5770 (0.5827)  labels_encoder_unscaled: 0.5770 (0.5827)  time: 0.0574  data: 0.0291  max mem: 593
Epoch: [4]  [ 500/1510]  eta: 0:00:57  lr: 0.000000  loss: 0.5639 (0.5829)  labels_encoder: 0.5639 (0.5829)  labels_encoder_unscaled: 0.5639 (0.5829)  time: 0.0518  data: 0.0257  max mem: 593
Epoch: [4]  [ 550/1510]  eta: 0:00:53  lr: 0.000000  loss: 0.5939 (0.5834)  labels_encoder: 0.5939 (0.5834)  labels_encoder_unscaled: 0.5939 (0.5834)  time: 0.0510  data: 0.0246  max mem: 593
Epoch: [4]  [ 600/1510]  eta: 0:00:50  lr: 0.000000  loss: 0.5772 (0.5820)  labels_encoder: 0.5772 (0.5820)  labels_encoder_unscaled: 0.5772 (0.5820)  time: 0.0511  data: 0.0242  max mem: 593
Epoch: [4]  [ 650/1510]  eta: 0:00:47  lr: 0.000000  loss: 0.5907 (0.5821)  labels_encoder: 0.5907 (0.5821)  labels_encoder_unscaled: 0.5907 (0.5821)  time: 0.0516  data: 0.0233  max mem: 593
Epoch: [4]  [ 700/1510]  eta: 0:00:44  lr: 0.000000  loss: 0.5479 (0.5820)  labels_encoder: 0.5479 (0.5820)  labels_encoder_unscaled: 0.5479 (0.5820)  time: 0.0492  data: 0.0223  max mem: 593
Epoch: [4]  [ 750/1510]  eta: 0:00:41  lr: 0.000000  loss: 0.5622 (0.5825)  labels_encoder: 0.5622 (0.5825)  labels_encoder_unscaled: 0.5622 (0.5825)  time: 0.0526  data: 0.0250  max mem: 593
Epoch: [4]  [ 800/1510]  eta: 0:00:39  lr: 0.000000  loss: 0.5998 (0.5833)  labels_encoder: 0.5998 (0.5833)  labels_encoder_unscaled: 0.5998 (0.5833)  time: 0.0532  data: 0.0249  max mem: 593
Epoch: [4]  [ 850/1510]  eta: 0:00:36  lr: 0.000000  loss: 0.5457 (0.5821)  labels_encoder: 0.5457 (0.5821)  labels_encoder_unscaled: 0.5457 (0.5821)  time: 0.0501  data: 0.0219  max mem: 593
Epoch: [4]  [ 900/1510]  eta: 0:00:33  lr: 0.000000  loss: 0.5589 (0.5819)  labels_encoder: 0.5589 (0.5819)  labels_encoder_unscaled: 0.5589 (0.5819)  time: 0.0543  data: 0.0268  max mem: 593
Epoch: [4]  [ 950/1510]  eta: 0:00:30  lr: 0.000000  loss: 0.5595 (0.5823)  labels_encoder: 0.5595 (0.5823)  labels_encoder_unscaled: 0.5595 (0.5823)  time: 0.0513  data: 0.0244  max mem: 593
Epoch: [4]  [1000/1510]  eta: 0:00:27  lr: 0.000000  loss: 0.5399 (0.5812)  labels_encoder: 0.5399 (0.5812)  labels_encoder_unscaled: 0.5399 (0.5812)  time: 0.0506  data: 0.0230  max mem: 593
Epoch: [4]  [1050/1510]  eta: 0:00:24  lr: 0.000000  loss: 0.5717 (0.5816)  labels_encoder: 0.5717 (0.5816)  labels_encoder_unscaled: 0.5717 (0.5816)  time: 0.0564  data: 0.0284  max mem: 593
Epoch: [4]  [1100/1510]  eta: 0:00:22  lr: 0.000000  loss: 0.5956 (0.5819)  labels_encoder: 0.5956 (0.5819)  labels_encoder_unscaled: 0.5956 (0.5819)  time: 0.0546  data: 0.0264  max mem: 593
Epoch: [4]  [1150/1510]  eta: 0:00:19  lr: 0.000000  loss: 0.5860 (0.5827)  labels_encoder: 0.5860 (0.5827)  labels_encoder_unscaled: 0.5860 (0.5827)  time: 0.0519  data: 0.0210  max mem: 593
Epoch: [4]  [1200/1510]  eta: 0:00:16  lr: 0.000000  loss: 0.5325 (0.5830)  labels_encoder: 0.5325 (0.5830)  labels_encoder_unscaled: 0.5325 (0.5830)  time: 0.0498  data: 0.0213  max mem: 593
Epoch: [4]  [1250/1510]  eta: 0:00:13  lr: 0.000000  loss: 0.5192 (0.5828)  labels_encoder: 0.5192 (0.5828)  labels_encoder_unscaled: 0.5192 (0.5828)  time: 0.0466  data: 0.0125  max mem: 593
Epoch: [4]  [1300/1510]  eta: 0:00:11  lr: 0.000000  loss: 0.5176 (0.5814)  labels_encoder: 0.5176 (0.5814)  labels_encoder_unscaled: 0.5176 (0.5814)  time: 0.0499  data: 0.0230  max mem: 593
Epoch: [4]  [1350/1510]  eta: 0:00:08  lr: 0.000000  loss: 0.5349 (0.5812)  labels_encoder: 0.5349 (0.5812)  labels_encoder_unscaled: 0.5349 (0.5812)  time: 0.0488  data: 0.0166  max mem: 593
Epoch: [4]  [1400/1510]  eta: 0:00:05  lr: 0.000000  loss: 0.5691 (0.5813)  labels_encoder: 0.5691 (0.5813)  labels_encoder_unscaled: 0.5691 (0.5813)  time: 0.0567  data: 0.0294  max mem: 593
Epoch: [4]  [1450/1510]  eta: 0:00:03  lr: 0.000000  loss: 0.5653 (0.5814)  labels_encoder: 0.5653 (0.5814)  labels_encoder_unscaled: 0.5653 (0.5814)  time: 0.0505  data: 0.0234  max mem: 593
Epoch: [4]  [1500/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.6256 (0.5814)  labels_encoder: 0.6256 (0.5814)  labels_encoder_unscaled: 0.6256 (0.5814)  time: 0.0507  data: 0.0224  max mem: 593
Epoch: [4]  [1509/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5656 (0.5813)  labels_encoder: 0.5656 (0.5813)  labels_encoder_unscaled: 0.5656 (0.5813)  time: 0.0502  data: 0.0213  max mem: 593
Epoch: [4] Total time: 0:01:21 (0.0538 s / it)
Averaged stats: lr: 0.000000  loss: 0.5656 (0.5813)  labels_encoder: 0.5656 (0.5813)  labels_encoder_unscaled: 0.5656 (0.5813)
Test:  [  0/559]  eta: 0:18:42  loss: 0.5980 (0.5980)  labels_encoder: 0.5980 (0.5980)  labels_encoder_unscaled: 0.5980 (0.5980)  time: 2.0088  data: 1.9903  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 0.6946 (0.9020)  labels_encoder: 0.6946 (0.9020)  labels_encoder_unscaled: 0.6946 (0.9020)  time: 0.0454  data: 0.0250  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.5494 (0.8381)  labels_encoder: 0.5494 (0.8381)  labels_encoder_unscaled: 0.5494 (0.8381)  time: 0.0466  data: 0.0307  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5353 (0.8635)  labels_encoder: 0.5353 (0.8635)  labels_encoder_unscaled: 0.5353 (0.8635)  time: 0.0485  data: 0.0324  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.5950 (0.8060)  labels_encoder: 0.5950 (0.8060)  labels_encoder_unscaled: 0.5950 (0.8060)  time: 0.0467  data: 0.0317  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7900 (0.9088)  labels_encoder: 0.7900 (0.9088)  labels_encoder_unscaled: 0.7900 (0.9088)  time: 0.0486  data: 0.0325  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.0996 (0.9617)  labels_encoder: 1.0996 (0.9617)  labels_encoder_unscaled: 1.0996 (0.9617)  time: 0.0457  data: 0.0289  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8256 (0.9797)  labels_encoder: 0.8256 (0.9797)  labels_encoder_unscaled: 0.8256 (0.9797)  time: 0.0474  data: 0.0323  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3591 (0.9533)  labels_encoder: 0.3591 (0.9533)  labels_encoder_unscaled: 0.3591 (0.9533)  time: 0.0541  data: 0.0373  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4204 (0.9291)  labels_encoder: 0.4204 (0.9291)  labels_encoder_unscaled: 0.4204 (0.9291)  time: 0.0485  data: 0.0315  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5667 (0.9108)  labels_encoder: 0.5667 (0.9108)  labels_encoder_unscaled: 0.5667 (0.9108)  time: 0.0489  data: 0.0323  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7273 (0.8859)  labels_encoder: 0.7273 (0.8859)  labels_encoder_unscaled: 0.7273 (0.8859)  time: 0.0503  data: 0.0337  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3505 (0.8799)  labels_encoder: 0.3505 (0.8799)  labels_encoder_unscaled: 0.3505 (0.8799)  time: 0.0474  data: 0.0311  max mem: 593
Test: Total time: 0:00:29 (0.0526 s / it)
Averaged stats: loss: 0.3505 (0.8799)  labels_encoder: 0.3505 (0.8799)  labels_encoder_unscaled: 0.3505 (0.8799)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1280, mcAP: 0.8820

BaseballPitch: 0.0334
BasketballDunk: 0.0764
Billiards: 0.0056
CleanAndJerk: 0.4139
CliffDiving: 0.4065
CricketBowling: 0.0976
CricketShot: 0.1058
Diving: 0.0047
FrisbeeCatch: 0.1586
GolfSwing: 0.0617
HammerThrow: 0.1070
HighJump: 0.0465
JavelinThrow: 0.0349
LongJump: 0.2926
PoleVault: 0.1047
Shotput: 0.1426
SoccerPenalty: 0.0529
TennisSwing: 0.1845
ThrowDiscus: 0.0583
VolleyballSpiking: 0.1727
Training time 0:07:17
