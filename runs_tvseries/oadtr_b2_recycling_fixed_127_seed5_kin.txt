Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:2
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:5
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Warning: variables __flops__ or __params__ are already defined for the moduleGELU ptflops can affect your code!
Sequential(
  16.814 M, 99.939% Params, 0.412 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 24.936% Params, 0.004 GMac, 1.018% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    12.587 M, 74.814% Params, 0.408 GMac, 98.974% MACs, 
    (0): Sequential(
      6.294 M, 37.407% Params, 0.205 GMac, 49.804% MACs, 
      (0): BroadcastReduce(
        4.194 M, 24.930% Params, 0.071 GMac, 17.179% MACs, reduce=reduce_sum
        (0): RetroactiveUnity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 63)
        (1): CoReMultiheadAttention(
          4.194 M, 24.930% Params, 0.071 GMac, 17.179% MACs, 
          (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
        )
      )
      (1): Lambda(Sequential(
        2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
        (0): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (1): Residual(
          2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
          (fn): Sequential(
            2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
            (0): Linear(1.05 M, 6.239% Params, 0.067 GMac, 16.305% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
            (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.016% MACs, )
            (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (3): Linear(1.05 M, 6.239% Params, 0.067 GMac, 16.305% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
            (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
        (2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
      ))
    )
    (1): Lambda(Sequential(
      6.294 M, 37.407% Params, 0.203 GMac, 49.170% MACs, 
      (0): BroadcastReduce(
        4.194 M, 24.930% Params, 0.203 GMac, 49.153% MACs, reduce=sum_last_pairs
        (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
        (1): CoSiMultiheadAttention(
          4.194 M, 24.930% Params, 0.203 GMac, 49.153% MACs, 
          (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
        )
      )
      (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
      (2): BroadcastReduce(
        2.099 M, 12.477% Params, 0.0 GMac, 0.017% MACs, reduce=reduce_sum
        (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
        (1): Sequential(
          2.099 M, 12.477% Params, 0.0 GMac, 0.017% MACs, 
          (0): Linear(1.05 M, 6.239% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
          (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.016% MACs, )
          (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (3): Linear(1.05 M, 6.239% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
          (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        )
      )
      (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    ), takes_time=True)
    (2): Lambda(unity, squeeze_last, squeeze_last, takes_time=True)
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.189% Params, 0.0 GMac, 0.008% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 411997217.0
Model params: 16824351
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   67522 KB |   69842 KB |  260138 KB |  192616 KB |
|---------------------------------------------------------------------------|
| Active memory         |   67522 KB |   69842 KB |  260138 KB |  192616 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   83968 KB |   83968 KB |   83968 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   16445 KB |   16445 KB |  302954 KB |  286508 KB |
|---------------------------------------------------------------------------|
| Allocations           |      34    |     103    |    3333    |    3299    |
|---------------------------------------------------------------------------|
| Active allocs         |      34    |     103    |    3333    |    3299    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      12    |    1458    |    1448    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 69143040 71518720 69143040
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1510]  eta: 1:21:39  lr: 0.000100  loss: 3.4812 (3.4812)  labels_encoder: 3.4812 (3.4812)  labels_encoder_unscaled: 3.4812 (3.4812)  time: 3.2446  data: 2.6002  max mem: 1013
Epoch: [1]  [  50/1510]  eta: 0:04:48  lr: 0.000100  loss: 1.0308 (1.1471)  labels_encoder: 1.0308 (1.1471)  labels_encoder_unscaled: 1.0308 (1.1471)  time: 0.1316  data: 0.0002  max mem: 1206
Epoch: [1]  [ 100/1510]  eta: 0:03:58  lr: 0.000100  loss: 0.9860 (1.0743)  labels_encoder: 0.9860 (1.0743)  labels_encoder_unscaled: 0.9860 (1.0743)  time: 0.1474  data: 0.0002  max mem: 1206
Epoch: [1]  [ 150/1510]  eta: 0:03:36  lr: 0.000100  loss: 0.9156 (1.0232)  labels_encoder: 0.9156 (1.0232)  labels_encoder_unscaled: 0.9156 (1.0232)  time: 0.1401  data: 0.0002  max mem: 1206
Epoch: [1]  [ 200/1510]  eta: 0:03:22  lr: 0.000100  loss: 0.8984 (0.9889)  labels_encoder: 0.8984 (0.9889)  labels_encoder_unscaled: 0.8984 (0.9889)  time: 0.1387  data: 0.0003  max mem: 1206
Epoch: [1]  [ 250/1510]  eta: 0:03:10  lr: 0.000100  loss: 0.8259 (0.9667)  labels_encoder: 0.8259 (0.9667)  labels_encoder_unscaled: 0.8259 (0.9667)  time: 0.1420  data: 0.0002  max mem: 1206
Epoch: [1]  [ 300/1510]  eta: 0:02:57  lr: 0.000100  loss: 0.7890 (0.9492)  labels_encoder: 0.7890 (0.9492)  labels_encoder_unscaled: 0.7890 (0.9492)  time: 0.1165  data: 0.0002  max mem: 1206
Epoch: [1]  [ 350/1510]  eta: 0:02:46  lr: 0.000100  loss: 0.8167 (0.9347)  labels_encoder: 0.8167 (0.9347)  labels_encoder_unscaled: 0.8167 (0.9347)  time: 0.1246  data: 0.0002  max mem: 1206
Epoch: [1]  [ 400/1510]  eta: 0:02:38  lr: 0.000100  loss: 0.7560 (0.9175)  labels_encoder: 0.7560 (0.9175)  labels_encoder_unscaled: 0.7560 (0.9175)  time: 0.1376  data: 0.0002  max mem: 1206
Epoch: [1]  [ 450/1510]  eta: 0:02:31  lr: 0.000100  loss: 0.7386 (0.9071)  labels_encoder: 0.7386 (0.9071)  labels_encoder_unscaled: 0.7386 (0.9071)  time: 0.1358  data: 0.0002  max mem: 1206
Epoch: [1]  [ 500/1510]  eta: 0:02:24  lr: 0.000100  loss: 0.7868 (0.8931)  labels_encoder: 0.7868 (0.8931)  labels_encoder_unscaled: 0.7868 (0.8931)  time: 0.1430  data: 0.0002  max mem: 1206
Epoch: [1]  [ 550/1510]  eta: 0:02:16  lr: 0.000100  loss: 0.7721 (0.8846)  labels_encoder: 0.7721 (0.8846)  labels_encoder_unscaled: 0.7721 (0.8846)  time: 0.1410  data: 0.0002  max mem: 1206
Epoch: [1]  [ 600/1510]  eta: 0:02:09  lr: 0.000100  loss: 0.7741 (0.8732)  labels_encoder: 0.7741 (0.8732)  labels_encoder_unscaled: 0.7741 (0.8732)  time: 0.1364  data: 0.0002  max mem: 1206
Epoch: [1]  [ 650/1510]  eta: 0:02:01  lr: 0.000100  loss: 0.7080 (0.8633)  labels_encoder: 0.7080 (0.8633)  labels_encoder_unscaled: 0.7080 (0.8633)  time: 0.1370  data: 0.0002  max mem: 1206
Epoch: [1]  [ 700/1510]  eta: 0:01:54  lr: 0.000100  loss: 0.7678 (0.8545)  labels_encoder: 0.7678 (0.8545)  labels_encoder_unscaled: 0.7678 (0.8545)  time: 0.1390  data: 0.0002  max mem: 1206
Epoch: [1]  [ 750/1510]  eta: 0:01:46  lr: 0.000100  loss: 0.7712 (0.8481)  labels_encoder: 0.7712 (0.8481)  labels_encoder_unscaled: 0.7712 (0.8481)  time: 0.1266  data: 0.0001  max mem: 1206
Epoch: [1]  [ 800/1510]  eta: 0:01:39  lr: 0.000100  loss: 0.6830 (0.8409)  labels_encoder: 0.6830 (0.8409)  labels_encoder_unscaled: 0.6830 (0.8409)  time: 0.1398  data: 0.0002  max mem: 1206
Epoch: [1]  [ 850/1510]  eta: 0:01:32  lr: 0.000100  loss: 0.7473 (0.8358)  labels_encoder: 0.7473 (0.8358)  labels_encoder_unscaled: 0.7473 (0.8358)  time: 0.1360  data: 0.0002  max mem: 1206
Epoch: [1]  [ 900/1510]  eta: 0:01:24  lr: 0.000100  loss: 0.6922 (0.8292)  labels_encoder: 0.6922 (0.8292)  labels_encoder_unscaled: 0.6922 (0.8292)  time: 0.1210  data: 0.0002  max mem: 1206
Epoch: [1]  [ 950/1510]  eta: 0:01:17  lr: 0.000100  loss: 0.6521 (0.8233)  labels_encoder: 0.6521 (0.8233)  labels_encoder_unscaled: 0.6521 (0.8233)  time: 0.1271  data: 0.0002  max mem: 1206
Epoch: [1]  [1000/1510]  eta: 0:01:10  lr: 0.000100  loss: 0.7421 (0.8203)  labels_encoder: 0.7421 (0.8203)  labels_encoder_unscaled: 0.7421 (0.8203)  time: 0.1371  data: 0.0002  max mem: 1206
Epoch: [1]  [1050/1510]  eta: 0:01:03  lr: 0.000100  loss: 0.6688 (0.8135)  labels_encoder: 0.6688 (0.8135)  labels_encoder_unscaled: 0.6688 (0.8135)  time: 0.1244  data: 0.0002  max mem: 1206
Epoch: [1]  [1100/1510]  eta: 0:00:56  lr: 0.000100  loss: 0.7382 (0.8088)  labels_encoder: 0.7382 (0.8088)  labels_encoder_unscaled: 0.7382 (0.8088)  time: 0.1407  data: 0.0002  max mem: 1206
Epoch: [1]  [1150/1510]  eta: 0:00:49  lr: 0.000100  loss: 0.6854 (0.8043)  labels_encoder: 0.6854 (0.8043)  labels_encoder_unscaled: 0.6854 (0.8043)  time: 0.1415  data: 0.0002  max mem: 1206
Epoch: [1]  [1200/1510]  eta: 0:00:42  lr: 0.000100  loss: 0.6980 (0.8004)  labels_encoder: 0.6980 (0.8004)  labels_encoder_unscaled: 0.6980 (0.8004)  time: 0.1424  data: 0.0002  max mem: 1206
Epoch: [1]  [1250/1510]  eta: 0:00:35  lr: 0.000100  loss: 0.6617 (0.7959)  labels_encoder: 0.6617 (0.7959)  labels_encoder_unscaled: 0.6617 (0.7959)  time: 0.1301  data: 0.0002  max mem: 1206
Epoch: [1]  [1300/1510]  eta: 0:00:28  lr: 0.000100  loss: 0.6537 (0.7914)  labels_encoder: 0.6537 (0.7914)  labels_encoder_unscaled: 0.6537 (0.7914)  time: 0.1291  data: 0.0002  max mem: 1206
Epoch: [1]  [1350/1510]  eta: 0:00:21  lr: 0.000100  loss: 0.6226 (0.7862)  labels_encoder: 0.6226 (0.7862)  labels_encoder_unscaled: 0.6226 (0.7862)  time: 0.1215  data: 0.0002  max mem: 1206
Epoch: [1]  [1400/1510]  eta: 0:00:15  lr: 0.000100  loss: 0.6553 (0.7827)  labels_encoder: 0.6553 (0.7827)  labels_encoder_unscaled: 0.6553 (0.7827)  time: 0.1361  data: 0.0002  max mem: 1206
Epoch: [1]  [1450/1510]  eta: 0:00:08  lr: 0.000100  loss: 0.6772 (0.7782)  labels_encoder: 0.6772 (0.7782)  labels_encoder_unscaled: 0.6772 (0.7782)  time: 0.1454  data: 0.0002  max mem: 1206
Epoch: [1]  [1500/1510]  eta: 0:00:01  lr: 0.000100  loss: 0.6354 (0.7749)  labels_encoder: 0.6354 (0.7749)  labels_encoder_unscaled: 0.6354 (0.7749)  time: 0.1282  data: 0.0003  max mem: 1206
Epoch: [1]  [1509/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6006 (0.7741)  labels_encoder: 0.6006 (0.7741)  labels_encoder_unscaled: 0.6006 (0.7741)  time: 0.1154  data: 0.0002  max mem: 1206
Epoch: [1] Total time: 0:03:27 (0.1372 s / it)
Averaged stats: lr: 0.000100  loss: 0.6006 (0.7741)  labels_encoder: 0.6006 (0.7741)  labels_encoder_unscaled: 0.6006 (0.7741)
Test:  [  0/559]  eta: 0:16:30  loss: 0.7346 (0.7346)  labels_encoder: 0.7346 (0.7346)  labels_encoder_unscaled: 0.7346 (0.7346)  time: 1.7725  data: 1.7231  max mem: 1206
Test:  [ 50/559]  eta: 0:00:44  loss: 0.9108 (0.9382)  labels_encoder: 0.9108 (0.9382)  labels_encoder_unscaled: 0.9108 (0.9382)  time: 0.0564  data: 0.0060  max mem: 1206
Test:  [100/559]  eta: 0:00:34  loss: 0.5395 (0.8873)  labels_encoder: 0.5395 (0.8873)  labels_encoder_unscaled: 0.5395 (0.8873)  time: 0.0647  data: 0.0300  max mem: 1206
Test:  [150/559]  eta: 0:00:29  loss: 0.7526 (0.9169)  labels_encoder: 0.7526 (0.9169)  labels_encoder_unscaled: 0.7526 (0.9169)  time: 0.0642  data: 0.0311  max mem: 1206
Test:  [200/559]  eta: 0:00:24  loss: 0.8194 (0.8660)  labels_encoder: 0.8194 (0.8660)  labels_encoder_unscaled: 0.8194 (0.8660)  time: 0.0634  data: 0.0267  max mem: 1206
Test:  [250/559]  eta: 0:00:20  loss: 0.7028 (0.9882)  labels_encoder: 0.7028 (0.9882)  labels_encoder_unscaled: 0.7028 (0.9882)  time: 0.0516  data: 0.0021  max mem: 1206
Test:  [300/559]  eta: 0:00:16  loss: 1.2456 (1.0457)  labels_encoder: 1.2456 (1.0457)  labels_encoder_unscaled: 1.2456 (1.0457)  time: 0.0506  data: 0.0001  max mem: 1206
Test:  [350/559]  eta: 0:00:13  loss: 0.8160 (1.0610)  labels_encoder: 0.8160 (1.0610)  labels_encoder_unscaled: 0.8160 (1.0610)  time: 0.0567  data: 0.0001  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.4152 (1.0355)  labels_encoder: 0.4152 (1.0355)  labels_encoder_unscaled: 0.4152 (1.0355)  time: 0.0661  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.6469 (1.0167)  labels_encoder: 0.6469 (1.0167)  labels_encoder_unscaled: 0.6469 (1.0167)  time: 0.0591  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.6572 (1.0001)  labels_encoder: 0.6572 (1.0001)  labels_encoder_unscaled: 0.6572 (1.0001)  time: 0.0662  data: 0.0002  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.8073 (0.9703)  labels_encoder: 0.8073 (0.9703)  labels_encoder_unscaled: 0.8073 (0.9703)  time: 0.0538  data: 0.0002  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3538 (0.9636)  labels_encoder: 0.3538 (0.9636)  labels_encoder_unscaled: 0.3538 (0.9636)  time: 0.0434  data: 0.0001  max mem: 1206
Test: Total time: 0:00:34 (0.0625 s / it)
Averaged stats: loss: 0.3538 (0.9636)  labels_encoder: 0.3538 (0.9636)  labels_encoder_unscaled: 0.3538 (0.9636)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1169, mcAP: 0.8682

BaseballPitch: 0.0292
BasketballDunk: 0.1187
Billiards: 0.0056
CleanAndJerk: 0.3686
CliffDiving: 0.3107
CricketBowling: 0.0727
CricketShot: 0.0905
Diving: 0.0042
FrisbeeCatch: 0.1155
GolfSwing: 0.0659
HammerThrow: 0.1039
HighJump: 0.0570
JavelinThrow: 0.0210
LongJump: 0.3150
PoleVault: 0.0917
Shotput: 0.1169
SoccerPenalty: 0.0360
TennisSwing: 0.1842
ThrowDiscus: 0.1169
VolleyballSpiking: 0.1142
Epoch: [2]  [   0/1510]  eta: 0:55:34  lr: 0.000010  loss: 0.6701 (0.6701)  labels_encoder: 0.6701 (0.6701)  labels_encoder_unscaled: 0.6701 (0.6701)  time: 2.2085  data: 2.0502  max mem: 1206
Epoch: [2]  [  50/1510]  eta: 0:03:53  lr: 0.000010  loss: 0.6039 (0.6354)  labels_encoder: 0.6039 (0.6354)  labels_encoder_unscaled: 0.6039 (0.6354)  time: 0.1159  data: 0.0002  max mem: 1206
Epoch: [2]  [ 100/1510]  eta: 0:03:18  lr: 0.000010  loss: 0.5962 (0.6342)  labels_encoder: 0.5962 (0.6342)  labels_encoder_unscaled: 0.5962 (0.6342)  time: 0.1232  data: 0.0002  max mem: 1206
Epoch: [2]  [ 150/1510]  eta: 0:03:06  lr: 0.000010  loss: 0.5850 (0.6423)  labels_encoder: 0.5850 (0.6423)  labels_encoder_unscaled: 0.5850 (0.6423)  time: 0.1276  data: 0.0002  max mem: 1206
Epoch: [2]  [ 200/1510]  eta: 0:02:57  lr: 0.000010  loss: 0.6075 (0.6283)  labels_encoder: 0.6075 (0.6283)  labels_encoder_unscaled: 0.6075 (0.6283)  time: 0.1418  data: 0.0002  max mem: 1206
Epoch: [2]  [ 250/1510]  eta: 0:02:53  lr: 0.000010  loss: 0.5614 (0.6225)  labels_encoder: 0.5614 (0.6225)  labels_encoder_unscaled: 0.5614 (0.6225)  time: 0.1505  data: 0.0002  max mem: 1206
Epoch: [2]  [ 300/1510]  eta: 0:02:47  lr: 0.000010  loss: 0.5884 (0.6177)  labels_encoder: 0.5884 (0.6177)  labels_encoder_unscaled: 0.5884 (0.6177)  time: 0.1321  data: 0.0002  max mem: 1206
Epoch: [2]  [ 350/1510]  eta: 0:02:38  lr: 0.000010  loss: 0.5601 (0.6114)  labels_encoder: 0.5601 (0.6114)  labels_encoder_unscaled: 0.5601 (0.6114)  time: 0.1344  data: 0.0002  max mem: 1206
Epoch: [2]  [ 400/1510]  eta: 0:02:31  lr: 0.000010  loss: 0.5972 (0.6098)  labels_encoder: 0.5972 (0.6098)  labels_encoder_unscaled: 0.5972 (0.6098)  time: 0.1270  data: 0.0002  max mem: 1206
Epoch: [2]  [ 450/1510]  eta: 0:02:24  lr: 0.000010  loss: 0.6007 (0.6047)  labels_encoder: 0.6007 (0.6047)  labels_encoder_unscaled: 0.6007 (0.6047)  time: 0.1276  data: 0.0002  max mem: 1206
Epoch: [2]  [ 500/1510]  eta: 0:02:16  lr: 0.000010  loss: 0.6045 (0.6016)  labels_encoder: 0.6045 (0.6016)  labels_encoder_unscaled: 0.6045 (0.6016)  time: 0.1299  data: 0.0002  max mem: 1206
Epoch: [2]  [ 550/1510]  eta: 0:02:09  lr: 0.000010  loss: 0.5819 (0.6003)  labels_encoder: 0.5819 (0.6003)  labels_encoder_unscaled: 0.5819 (0.6003)  time: 0.1209  data: 0.0002  max mem: 1206
Epoch: [2]  [ 600/1510]  eta: 0:02:01  lr: 0.000010  loss: 0.5701 (0.5988)  labels_encoder: 0.5701 (0.5988)  labels_encoder_unscaled: 0.5701 (0.5988)  time: 0.1148  data: 0.0002  max mem: 1206
Epoch: [2]  [ 650/1510]  eta: 0:01:55  lr: 0.000010  loss: 0.6107 (0.5989)  labels_encoder: 0.6107 (0.5989)  labels_encoder_unscaled: 0.6107 (0.5989)  time: 0.1486  data: 0.0002  max mem: 1206
Epoch: [2]  [ 700/1510]  eta: 0:01:48  lr: 0.000010  loss: 0.6071 (0.5995)  labels_encoder: 0.6071 (0.5995)  labels_encoder_unscaled: 0.6071 (0.5995)  time: 0.1421  data: 0.0002  max mem: 1206
Epoch: [2]  [ 750/1510]  eta: 0:01:42  lr: 0.000010  loss: 0.5653 (0.5988)  labels_encoder: 0.5653 (0.5988)  labels_encoder_unscaled: 0.5653 (0.5988)  time: 0.1345  data: 0.0002  max mem: 1206
Epoch: [2]  [ 800/1510]  eta: 0:01:35  lr: 0.000010  loss: 0.5141 (0.5957)  labels_encoder: 0.5141 (0.5957)  labels_encoder_unscaled: 0.5141 (0.5957)  time: 0.1173  data: 0.0002  max mem: 1206
Epoch: [2]  [ 850/1510]  eta: 0:01:28  lr: 0.000010  loss: 0.5995 (0.5939)  labels_encoder: 0.5995 (0.5939)  labels_encoder_unscaled: 0.5995 (0.5939)  time: 0.1204  data: 0.0002  max mem: 1206
Epoch: [2]  [ 900/1510]  eta: 0:01:21  lr: 0.000010  loss: 0.5306 (0.5918)  labels_encoder: 0.5306 (0.5918)  labels_encoder_unscaled: 0.5306 (0.5918)  time: 0.1205  data: 0.0002  max mem: 1206
Epoch: [2]  [ 950/1510]  eta: 0:01:14  lr: 0.000010  loss: 0.5029 (0.5895)  labels_encoder: 0.5029 (0.5895)  labels_encoder_unscaled: 0.5029 (0.5895)  time: 0.1484  data: 0.0002  max mem: 1206
Epoch: [2]  [1000/1510]  eta: 0:01:08  lr: 0.000010  loss: 0.5365 (0.5885)  labels_encoder: 0.5365 (0.5885)  labels_encoder_unscaled: 0.5365 (0.5885)  time: 0.1451  data: 0.0002  max mem: 1206
Epoch: [2]  [1050/1510]  eta: 0:01:01  lr: 0.000010  loss: 0.5473 (0.5873)  labels_encoder: 0.5473 (0.5873)  labels_encoder_unscaled: 0.5473 (0.5873)  time: 0.1469  data: 0.0002  max mem: 1206
Epoch: [2]  [1100/1510]  eta: 0:00:55  lr: 0.000010  loss: 0.5526 (0.5855)  labels_encoder: 0.5526 (0.5855)  labels_encoder_unscaled: 0.5526 (0.5855)  time: 0.1358  data: 0.0002  max mem: 1206
Epoch: [2]  [1150/1510]  eta: 0:00:48  lr: 0.000010  loss: 0.5319 (0.5842)  labels_encoder: 0.5319 (0.5842)  labels_encoder_unscaled: 0.5319 (0.5842)  time: 0.1422  data: 0.0002  max mem: 1206
Epoch: [2]  [1200/1510]  eta: 0:00:41  lr: 0.000010  loss: 0.5679 (0.5834)  labels_encoder: 0.5679 (0.5834)  labels_encoder_unscaled: 0.5679 (0.5834)  time: 0.1395  data: 0.0002  max mem: 1206
Epoch: [2]  [1250/1510]  eta: 0:00:35  lr: 0.000010  loss: 0.5313 (0.5817)  labels_encoder: 0.5313 (0.5817)  labels_encoder_unscaled: 0.5313 (0.5817)  time: 0.1248  data: 0.0002  max mem: 1206
Epoch: [2]  [1300/1510]  eta: 0:00:28  lr: 0.000010  loss: 0.5045 (0.5810)  labels_encoder: 0.5045 (0.5810)  labels_encoder_unscaled: 0.5045 (0.5810)  time: 0.1350  data: 0.0002  max mem: 1206
Epoch: [2]  [1350/1510]  eta: 0:00:21  lr: 0.000010  loss: 0.5434 (0.5804)  labels_encoder: 0.5434 (0.5804)  labels_encoder_unscaled: 0.5434 (0.5804)  time: 0.1342  data: 0.0002  max mem: 1206
Epoch: [2]  [1400/1510]  eta: 0:00:14  lr: 0.000010  loss: 0.4963 (0.5794)  labels_encoder: 0.4963 (0.5794)  labels_encoder_unscaled: 0.4963 (0.5794)  time: 0.1207  data: 0.0002  max mem: 1206
Epoch: [2]  [1450/1510]  eta: 0:00:08  lr: 0.000010  loss: 0.5888 (0.5789)  labels_encoder: 0.5888 (0.5789)  labels_encoder_unscaled: 0.5888 (0.5789)  time: 0.1244  data: 0.0002  max mem: 1206
Epoch: [2]  [1500/1510]  eta: 0:00:01  lr: 0.000010  loss: 0.4996 (0.5773)  labels_encoder: 0.4996 (0.5773)  labels_encoder_unscaled: 0.4996 (0.5773)  time: 0.1163  data: 0.0004  max mem: 1206
Epoch: [2]  [1509/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.4996 (0.5769)  labels_encoder: 0.4996 (0.5769)  labels_encoder_unscaled: 0.4996 (0.5769)  time: 0.1089  data: 0.0004  max mem: 1206
Epoch: [2] Total time: 0:03:22 (0.1339 s / it)
Averaged stats: lr: 0.000010  loss: 0.4996 (0.5769)  labels_encoder: 0.4996 (0.5769)  labels_encoder_unscaled: 0.4996 (0.5769)
Test:  [  0/559]  eta: 0:15:29  loss: 0.6412 (0.6412)  labels_encoder: 0.6412 (0.6412)  labels_encoder_unscaled: 0.6412 (0.6412)  time: 1.6621  data: 1.6199  max mem: 1206
Test:  [ 50/559]  eta: 0:00:47  loss: 0.9897 (0.9658)  labels_encoder: 0.9897 (0.9658)  labels_encoder_unscaled: 0.9897 (0.9658)  time: 0.0575  data: 0.0056  max mem: 1206
Test:  [100/559]  eta: 0:00:35  loss: 0.9310 (0.9461)  labels_encoder: 0.9310 (0.9461)  labels_encoder_unscaled: 0.9310 (0.9461)  time: 0.0640  data: 0.0002  max mem: 1206
Test:  [150/559]  eta: 0:00:30  loss: 0.9210 (0.9690)  labels_encoder: 0.9210 (0.9690)  labels_encoder_unscaled: 0.9210 (0.9690)  time: 0.0636  data: 0.0002  max mem: 1206
Test:  [200/559]  eta: 0:00:25  loss: 0.8178 (0.9003)  labels_encoder: 0.8178 (0.9003)  labels_encoder_unscaled: 0.8178 (0.9003)  time: 0.0607  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:21  loss: 0.8033 (1.0005)  labels_encoder: 0.8033 (1.0005)  labels_encoder_unscaled: 0.8033 (1.0005)  time: 0.0675  data: 0.0011  max mem: 1206
Test:  [300/559]  eta: 0:00:17  loss: 1.0525 (1.0411)  labels_encoder: 1.0525 (1.0411)  labels_encoder_unscaled: 1.0525 (1.0411)  time: 0.0623  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:14  loss: 0.7198 (1.0588)  labels_encoder: 0.7198 (1.0588)  labels_encoder_unscaled: 0.7198 (1.0588)  time: 0.0635  data: 0.0010  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.4133 (1.0348)  labels_encoder: 0.4133 (1.0348)  labels_encoder_unscaled: 0.4133 (1.0348)  time: 0.0540  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:07  loss: 0.4467 (1.0054)  labels_encoder: 0.4467 (1.0054)  labels_encoder_unscaled: 0.4467 (1.0054)  time: 0.0466  data: 0.0001  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.7093 (0.9878)  labels_encoder: 0.7093 (0.9878)  labels_encoder_unscaled: 0.7093 (0.9878)  time: 0.0492  data: 0.0002  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.9238 (0.9605)  labels_encoder: 0.9238 (0.9605)  labels_encoder_unscaled: 0.9238 (0.9605)  time: 0.0570  data: 0.0151  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3779 (0.9535)  labels_encoder: 0.3779 (0.9535)  labels_encoder_unscaled: 0.3779 (0.9535)  time: 0.0517  data: 0.0142  max mem: 1206
Test: Total time: 0:00:35 (0.0626 s / it)
Averaged stats: loss: 0.3779 (0.9535)  labels_encoder: 0.3779 (0.9535)  labels_encoder_unscaled: 0.3779 (0.9535)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1143, mcAP: 0.8710

BaseballPitch: 0.0411
BasketballDunk: 0.1104
Billiards: 0.0040
CleanAndJerk: 0.3783
CliffDiving: 0.2827
CricketBowling: 0.0632
CricketShot: 0.0940
Diving: 0.0047
FrisbeeCatch: 0.1141
GolfSwing: 0.0623
HammerThrow: 0.0818
HighJump: 0.0340
JavelinThrow: 0.0969
LongJump: 0.2456
PoleVault: 0.1188
Shotput: 0.1162
SoccerPenalty: 0.0407
TennisSwing: 0.2175
ThrowDiscus: 0.0372
VolleyballSpiking: 0.1430
Epoch: [3]  [   0/1510]  eta: 0:49:43  lr: 0.000001  loss: 0.5142 (0.5142)  labels_encoder: 0.5142 (0.5142)  labels_encoder_unscaled: 0.5142 (0.5142)  time: 1.9757  data: 1.8346  max mem: 1206
Epoch: [3]  [  50/1510]  eta: 0:04:01  lr: 0.000001  loss: 0.5552 (0.5748)  labels_encoder: 0.5552 (0.5748)  labels_encoder_unscaled: 0.5552 (0.5748)  time: 0.1232  data: 0.0002  max mem: 1206
Epoch: [3]  [ 100/1510]  eta: 0:03:29  lr: 0.000001  loss: 0.5573 (0.5720)  labels_encoder: 0.5573 (0.5720)  labels_encoder_unscaled: 0.5573 (0.5720)  time: 0.1382  data: 0.0002  max mem: 1206
Epoch: [3]  [ 150/1510]  eta: 0:03:13  lr: 0.000001  loss: 0.5142 (0.5639)  labels_encoder: 0.5142 (0.5639)  labels_encoder_unscaled: 0.5142 (0.5639)  time: 0.1238  data: 0.0002  max mem: 1206
Epoch: [3]  [ 200/1510]  eta: 0:03:03  lr: 0.000001  loss: 0.4869 (0.5530)  labels_encoder: 0.4869 (0.5530)  labels_encoder_unscaled: 0.4869 (0.5530)  time: 0.1373  data: 0.0002  max mem: 1206
Epoch: [3]  [ 250/1510]  eta: 0:02:53  lr: 0.000001  loss: 0.5849 (0.5572)  labels_encoder: 0.5849 (0.5572)  labels_encoder_unscaled: 0.5849 (0.5572)  time: 0.1204  data: 0.0002  max mem: 1206
Epoch: [3]  [ 300/1510]  eta: 0:02:44  lr: 0.000001  loss: 0.5514 (0.5561)  labels_encoder: 0.5514 (0.5561)  labels_encoder_unscaled: 0.5514 (0.5561)  time: 0.1304  data: 0.0002  max mem: 1206
Epoch: [3]  [ 350/1510]  eta: 0:02:38  lr: 0.000001  loss: 0.5336 (0.5549)  labels_encoder: 0.5336 (0.5549)  labels_encoder_unscaled: 0.5336 (0.5549)  time: 0.1316  data: 0.0001  max mem: 1206
Epoch: [3]  [ 400/1510]  eta: 0:02:30  lr: 0.000001  loss: 0.5320 (0.5494)  labels_encoder: 0.5320 (0.5494)  labels_encoder_unscaled: 0.5320 (0.5494)  time: 0.1277  data: 0.0002  max mem: 1206
Epoch: [3]  [ 450/1510]  eta: 0:02:22  lr: 0.000001  loss: 0.5020 (0.5470)  labels_encoder: 0.5020 (0.5470)  labels_encoder_unscaled: 0.5020 (0.5470)  time: 0.1233  data: 0.0002  max mem: 1206
Epoch: [3]  [ 500/1510]  eta: 0:02:14  lr: 0.000001  loss: 0.5027 (0.5457)  labels_encoder: 0.5027 (0.5457)  labels_encoder_unscaled: 0.5027 (0.5457)  time: 0.1292  data: 0.0002  max mem: 1206
Epoch: [3]  [ 550/1510]  eta: 0:02:07  lr: 0.000001  loss: 0.5105 (0.5456)  labels_encoder: 0.5105 (0.5456)  labels_encoder_unscaled: 0.5105 (0.5456)  time: 0.1229  data: 0.0002  max mem: 1206
Epoch: [3]  [ 600/1510]  eta: 0:02:00  lr: 0.000001  loss: 0.5064 (0.5446)  labels_encoder: 0.5064 (0.5446)  labels_encoder_unscaled: 0.5064 (0.5446)  time: 0.1318  data: 0.0001  max mem: 1206
Epoch: [3]  [ 650/1510]  eta: 0:01:53  lr: 0.000001  loss: 0.5511 (0.5442)  labels_encoder: 0.5511 (0.5442)  labels_encoder_unscaled: 0.5511 (0.5442)  time: 0.1321  data: 0.0001  max mem: 1206
Epoch: [3]  [ 700/1510]  eta: 0:01:47  lr: 0.000001  loss: 0.5180 (0.5422)  labels_encoder: 0.5180 (0.5422)  labels_encoder_unscaled: 0.5180 (0.5422)  time: 0.1309  data: 0.0002  max mem: 1206
Epoch: [3]  [ 750/1510]  eta: 0:01:40  lr: 0.000001  loss: 0.5271 (0.5408)  labels_encoder: 0.5271 (0.5408)  labels_encoder_unscaled: 0.5271 (0.5408)  time: 0.1239  data: 0.0002  max mem: 1206
Epoch: [3]  [ 800/1510]  eta: 0:01:33  lr: 0.000001  loss: 0.5369 (0.5405)  labels_encoder: 0.5369 (0.5405)  labels_encoder_unscaled: 0.5369 (0.5405)  time: 0.1201  data: 0.0002  max mem: 1206
Epoch: [3]  [ 850/1510]  eta: 0:01:26  lr: 0.000001  loss: 0.5847 (0.5418)  labels_encoder: 0.5847 (0.5418)  labels_encoder_unscaled: 0.5847 (0.5418)  time: 0.1219  data: 0.0002  max mem: 1206
Epoch: [3]  [ 900/1510]  eta: 0:01:19  lr: 0.000001  loss: 0.5241 (0.5411)  labels_encoder: 0.5241 (0.5411)  labels_encoder_unscaled: 0.5241 (0.5411)  time: 0.1287  data: 0.0002  max mem: 1206
Epoch: [3]  [ 950/1510]  eta: 0:01:13  lr: 0.000001  loss: 0.5340 (0.5412)  labels_encoder: 0.5340 (0.5412)  labels_encoder_unscaled: 0.5340 (0.5412)  time: 0.1306  data: 0.0001  max mem: 1206
Epoch: [3]  [1000/1510]  eta: 0:01:06  lr: 0.000001  loss: 0.5222 (0.5414)  labels_encoder: 0.5222 (0.5414)  labels_encoder_unscaled: 0.5222 (0.5414)  time: 0.1310  data: 0.0002  max mem: 1206
Epoch: [3]  [1050/1510]  eta: 0:01:00  lr: 0.000001  loss: 0.5150 (0.5411)  labels_encoder: 0.5150 (0.5411)  labels_encoder_unscaled: 0.5150 (0.5411)  time: 0.1277  data: 0.0002  max mem: 1206
Epoch: [3]  [1100/1510]  eta: 0:00:53  lr: 0.000001  loss: 0.5209 (0.5409)  labels_encoder: 0.5209 (0.5409)  labels_encoder_unscaled: 0.5209 (0.5409)  time: 0.1312  data: 0.0002  max mem: 1206
Epoch: [3]  [1150/1510]  eta: 0:00:46  lr: 0.000001  loss: 0.4990 (0.5398)  labels_encoder: 0.4990 (0.5398)  labels_encoder_unscaled: 0.4990 (0.5398)  time: 0.1199  data: 0.0002  max mem: 1206
Epoch: [3]  [1200/1510]  eta: 0:00:40  lr: 0.000001  loss: 0.5088 (0.5392)  labels_encoder: 0.5088 (0.5392)  labels_encoder_unscaled: 0.5088 (0.5392)  time: 0.1242  data: 0.0002  max mem: 1206
Epoch: [3]  [1250/1510]  eta: 0:00:33  lr: 0.000001  loss: 0.5227 (0.5391)  labels_encoder: 0.5227 (0.5391)  labels_encoder_unscaled: 0.5227 (0.5391)  time: 0.1278  data: 0.0002  max mem: 1206
Epoch: [3]  [1300/1510]  eta: 0:00:27  lr: 0.000001  loss: 0.5103 (0.5391)  labels_encoder: 0.5103 (0.5391)  labels_encoder_unscaled: 0.5103 (0.5391)  time: 0.1215  data: 0.0002  max mem: 1206
Epoch: [3]  [1350/1510]  eta: 0:00:20  lr: 0.000001  loss: 0.5263 (0.5391)  labels_encoder: 0.5263 (0.5391)  labels_encoder_unscaled: 0.5263 (0.5391)  time: 0.1271  data: 0.0002  max mem: 1206
Epoch: [3]  [1400/1510]  eta: 0:00:14  lr: 0.000001  loss: 0.5387 (0.5387)  labels_encoder: 0.5387 (0.5387)  labels_encoder_unscaled: 0.5387 (0.5387)  time: 0.1260  data: 0.0002  max mem: 1206
Epoch: [3]  [1450/1510]  eta: 0:00:07  lr: 0.000001  loss: 0.5620 (0.5385)  labels_encoder: 0.5620 (0.5385)  labels_encoder_unscaled: 0.5620 (0.5385)  time: 0.1287  data: 0.0002  max mem: 1206
Epoch: [3]  [1500/1510]  eta: 0:00:01  lr: 0.000001  loss: 0.5114 (0.5380)  labels_encoder: 0.5114 (0.5380)  labels_encoder_unscaled: 0.5114 (0.5380)  time: 0.1229  data: 0.0003  max mem: 1206
Epoch: [3]  [1509/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5232 (0.5380)  labels_encoder: 0.5232 (0.5380)  labels_encoder_unscaled: 0.5232 (0.5380)  time: 0.1129  data: 0.0002  max mem: 1206
Epoch: [3] Total time: 0:03:15 (0.1292 s / it)
Averaged stats: lr: 0.000001  loss: 0.5232 (0.5380)  labels_encoder: 0.5232 (0.5380)  labels_encoder_unscaled: 0.5232 (0.5380)
Test:  [  0/559]  eta: 0:18:42  loss: 0.6514 (0.6514)  labels_encoder: 0.6514 (0.6514)  labels_encoder_unscaled: 0.6514 (0.6514)  time: 2.0076  data: 1.9425  max mem: 1206
Test:  [ 50/559]  eta: 0:00:52  loss: 0.9721 (0.9537)  labels_encoder: 0.9721 (0.9537)  labels_encoder_unscaled: 0.9721 (0.9537)  time: 0.0579  data: 0.0002  max mem: 1206
Test:  [100/559]  eta: 0:00:35  loss: 0.5189 (0.8673)  labels_encoder: 0.5189 (0.8673)  labels_encoder_unscaled: 0.5189 (0.8673)  time: 0.0501  data: 0.0001  max mem: 1206
Test:  [150/559]  eta: 0:00:27  loss: 0.4798 (0.8803)  labels_encoder: 0.4798 (0.8803)  labels_encoder_unscaled: 0.4798 (0.8803)  time: 0.0474  data: 0.0001  max mem: 1206
Test:  [200/559]  eta: 0:00:22  loss: 0.5340 (0.8196)  labels_encoder: 0.5340 (0.8196)  labels_encoder_unscaled: 0.5340 (0.8196)  time: 0.0480  data: 0.0001  max mem: 1206
Test:  [250/559]  eta: 0:00:18  loss: 0.7303 (0.9329)  labels_encoder: 0.7303 (0.9329)  labels_encoder_unscaled: 0.7303 (0.9329)  time: 0.0485  data: 0.0001  max mem: 1206
Test:  [300/559]  eta: 0:00:15  loss: 0.9940 (0.9817)  labels_encoder: 0.9940 (0.9817)  labels_encoder_unscaled: 0.9940 (0.9817)  time: 0.0525  data: 0.0001  max mem: 1206
Test:  [350/559]  eta: 0:00:11  loss: 0.7589 (1.0035)  labels_encoder: 0.7589 (1.0035)  labels_encoder_unscaled: 0.7589 (1.0035)  time: 0.0469  data: 0.0001  max mem: 1206
Test:  [400/559]  eta: 0:00:09  loss: 0.3014 (0.9765)  labels_encoder: 0.3014 (0.9765)  labels_encoder_unscaled: 0.3014 (0.9765)  time: 0.0619  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.4332 (0.9533)  labels_encoder: 0.4332 (0.9533)  labels_encoder_unscaled: 0.4332 (0.9533)  time: 0.0598  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.5580 (0.9341)  labels_encoder: 0.5580 (0.9341)  labels_encoder_unscaled: 0.5580 (0.9341)  time: 0.0526  data: 0.0001  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.8465 (0.9079)  labels_encoder: 0.8465 (0.9079)  labels_encoder_unscaled: 0.8465 (0.9079)  time: 0.0472  data: 0.0001  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3682 (0.9016)  labels_encoder: 0.3682 (0.9016)  labels_encoder_unscaled: 0.3682 (0.9016)  time: 0.0381  data: 0.0001  max mem: 1206
Test: Total time: 0:00:31 (0.0566 s / it)
Averaged stats: loss: 0.3682 (0.9016)  labels_encoder: 0.3682 (0.9016)  labels_encoder_unscaled: 0.3682 (0.9016)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1311, mcAP: 0.8819

BaseballPitch: 0.0512
BasketballDunk: 0.1050
Billiards: 0.0043
CleanAndJerk: 0.4046
CliffDiving: 0.4088
CricketBowling: 0.0503
CricketShot: 0.0841
Diving: 0.0042
FrisbeeCatch: 0.1517
GolfSwing: 0.0682
HammerThrow: 0.1231
HighJump: 0.0524
JavelinThrow: 0.0882
LongJump: 0.3422
PoleVault: 0.1041
Shotput: 0.1385
SoccerPenalty: 0.0505
TennisSwing: 0.1880
ThrowDiscus: 0.0469
VolleyballSpiking: 0.1546
Epoch: [4]  [   0/1510]  eta: 0:47:23  lr: 0.000000  loss: 0.4921 (0.4921)  labels_encoder: 0.4921 (0.4921)  labels_encoder_unscaled: 0.4921 (0.4921)  time: 1.8831  data: 1.7177  max mem: 1206
Epoch: [4]  [  50/1510]  eta: 0:04:22  lr: 0.000000  loss: 0.5250 (0.5248)  labels_encoder: 0.5250 (0.5248)  labels_encoder_unscaled: 0.5250 (0.5248)  time: 0.1453  data: 0.0002  max mem: 1206
Epoch: [4]  [ 100/1510]  eta: 0:03:48  lr: 0.000000  loss: 0.5055 (0.5263)  labels_encoder: 0.5055 (0.5263)  labels_encoder_unscaled: 0.5055 (0.5263)  time: 0.1473  data: 0.0002  max mem: 1206
Epoch: [4]  [ 150/1510]  eta: 0:03:32  lr: 0.000000  loss: 0.5659 (0.5290)  labels_encoder: 0.5659 (0.5290)  labels_encoder_unscaled: 0.5659 (0.5290)  time: 0.1451  data: 0.0002  max mem: 1206
Epoch: [4]  [ 200/1510]  eta: 0:03:20  lr: 0.000000  loss: 0.5546 (0.5292)  labels_encoder: 0.5546 (0.5292)  labels_encoder_unscaled: 0.5546 (0.5292)  time: 0.1435  data: 0.0002  max mem: 1206
Epoch: [4]  [ 250/1510]  eta: 0:03:11  lr: 0.000000  loss: 0.5095 (0.5279)  labels_encoder: 0.5095 (0.5279)  labels_encoder_unscaled: 0.5095 (0.5279)  time: 0.1462  data: 0.0002  max mem: 1206
Epoch: [4]  [ 300/1510]  eta: 0:03:01  lr: 0.000000  loss: 0.4932 (0.5255)  labels_encoder: 0.4932 (0.5255)  labels_encoder_unscaled: 0.4932 (0.5255)  time: 0.1427  data: 0.0002  max mem: 1206
Epoch: [4]  [ 350/1510]  eta: 0:02:53  lr: 0.000000  loss: 0.5123 (0.5268)  labels_encoder: 0.5123 (0.5268)  labels_encoder_unscaled: 0.5123 (0.5268)  time: 0.1413  data: 0.0002  max mem: 1206
Epoch: [4]  [ 400/1510]  eta: 0:02:45  lr: 0.000000  loss: 0.5039 (0.5258)  labels_encoder: 0.5039 (0.5258)  labels_encoder_unscaled: 0.5039 (0.5258)  time: 0.1443  data: 0.0002  max mem: 1206
Epoch: [4]  [ 450/1510]  eta: 0:02:36  lr: 0.000000  loss: 0.5364 (0.5270)  labels_encoder: 0.5364 (0.5270)  labels_encoder_unscaled: 0.5364 (0.5270)  time: 0.1388  data: 0.0002  max mem: 1206
Epoch: [4]  [ 500/1510]  eta: 0:02:28  lr: 0.000000  loss: 0.5319 (0.5294)  labels_encoder: 0.5319 (0.5294)  labels_encoder_unscaled: 0.5319 (0.5294)  time: 0.1416  data: 0.0002  max mem: 1206
Epoch: [4]  [ 550/1510]  eta: 0:02:20  lr: 0.000000  loss: 0.5178 (0.5287)  labels_encoder: 0.5178 (0.5287)  labels_encoder_unscaled: 0.5178 (0.5287)  time: 0.1444  data: 0.0002  max mem: 1206
Epoch: [4]  [ 600/1510]  eta: 0:02:13  lr: 0.000000  loss: 0.4309 (0.5274)  labels_encoder: 0.4309 (0.5274)  labels_encoder_unscaled: 0.4309 (0.5274)  time: 0.1443  data: 0.0002  max mem: 1206
Epoch: [4]  [ 650/1510]  eta: 0:02:05  lr: 0.000000  loss: 0.4959 (0.5265)  labels_encoder: 0.4959 (0.5265)  labels_encoder_unscaled: 0.4959 (0.5265)  time: 0.1435  data: 0.0002  max mem: 1206
Epoch: [4]  [ 700/1510]  eta: 0:01:57  lr: 0.000000  loss: 0.5269 (0.5270)  labels_encoder: 0.5269 (0.5270)  labels_encoder_unscaled: 0.5269 (0.5270)  time: 0.1393  data: 0.0002  max mem: 1206
Epoch: [4]  [ 750/1510]  eta: 0:01:50  lr: 0.000000  loss: 0.5114 (0.5264)  labels_encoder: 0.5114 (0.5264)  labels_encoder_unscaled: 0.5114 (0.5264)  time: 0.1357  data: 0.0002  max mem: 1206
Epoch: [4]  [ 800/1510]  eta: 0:01:42  lr: 0.000000  loss: 0.5137 (0.5265)  labels_encoder: 0.5137 (0.5265)  labels_encoder_unscaled: 0.5137 (0.5265)  time: 0.1318  data: 0.0001  max mem: 1206
Epoch: [4]  [ 850/1510]  eta: 0:01:34  lr: 0.000000  loss: 0.5331 (0.5267)  labels_encoder: 0.5331 (0.5267)  labels_encoder_unscaled: 0.5331 (0.5267)  time: 0.1319  data: 0.0002  max mem: 1206
Epoch: [4]  [ 900/1510]  eta: 0:01:27  lr: 0.000000  loss: 0.5064 (0.5267)  labels_encoder: 0.5064 (0.5267)  labels_encoder_unscaled: 0.5064 (0.5267)  time: 0.1328  data: 0.0002  max mem: 1206
Epoch: [4]  [ 950/1510]  eta: 0:01:19  lr: 0.000000  loss: 0.5806 (0.5270)  labels_encoder: 0.5806 (0.5270)  labels_encoder_unscaled: 0.5806 (0.5270)  time: 0.1338  data: 0.0002  max mem: 1206
Epoch: [4]  [1000/1510]  eta: 0:01:12  lr: 0.000000  loss: 0.4914 (0.5270)  labels_encoder: 0.4914 (0.5270)  labels_encoder_unscaled: 0.4914 (0.5270)  time: 0.1309  data: 0.0001  max mem: 1206
Epoch: [4]  [1050/1510]  eta: 0:01:04  lr: 0.000000  loss: 0.5029 (0.5271)  labels_encoder: 0.5029 (0.5271)  labels_encoder_unscaled: 0.5029 (0.5271)  time: 0.1288  data: 0.0001  max mem: 1206
Epoch: [4]  [1100/1510]  eta: 0:00:57  lr: 0.000000  loss: 0.5420 (0.5281)  labels_encoder: 0.5420 (0.5281)  labels_encoder_unscaled: 0.5420 (0.5281)  time: 0.1290  data: 0.0002  max mem: 1206
Epoch: [4]  [1150/1510]  eta: 0:00:50  lr: 0.000000  loss: 0.4304 (0.5270)  labels_encoder: 0.4304 (0.5270)  labels_encoder_unscaled: 0.4304 (0.5270)  time: 0.1253  data: 0.0001  max mem: 1206
Epoch: [4]  [1200/1510]  eta: 0:00:43  lr: 0.000000  loss: 0.4468 (0.5265)  labels_encoder: 0.4468 (0.5265)  labels_encoder_unscaled: 0.4468 (0.5265)  time: 0.1253  data: 0.0001  max mem: 1206
Epoch: [4]  [1250/1510]  eta: 0:00:36  lr: 0.000000  loss: 0.5193 (0.5272)  labels_encoder: 0.5193 (0.5272)  labels_encoder_unscaled: 0.5193 (0.5272)  time: 0.1271  data: 0.0001  max mem: 1206
Epoch: [4]  [1300/1510]  eta: 0:00:29  lr: 0.000000  loss: 0.5209 (0.5273)  labels_encoder: 0.5209 (0.5273)  labels_encoder_unscaled: 0.5209 (0.5273)  time: 0.1261  data: 0.0002  max mem: 1206
Epoch: [4]  [1350/1510]  eta: 0:00:22  lr: 0.000000  loss: 0.4574 (0.5265)  labels_encoder: 0.4574 (0.5265)  labels_encoder_unscaled: 0.4574 (0.5265)  time: 0.1235  data: 0.0001  max mem: 1206
Epoch: [4]  [1400/1510]  eta: 0:00:15  lr: 0.000000  loss: 0.5047 (0.5263)  labels_encoder: 0.5047 (0.5263)  labels_encoder_unscaled: 0.5047 (0.5263)  time: 0.1223  data: 0.0002  max mem: 1206
Epoch: [4]  [1450/1510]  eta: 0:00:08  lr: 0.000000  loss: 0.5108 (0.5261)  labels_encoder: 0.5108 (0.5261)  labels_encoder_unscaled: 0.5108 (0.5261)  time: 0.1224  data: 0.0002  max mem: 1206
Epoch: [4]  [1500/1510]  eta: 0:00:01  lr: 0.000000  loss: 0.5035 (0.5262)  labels_encoder: 0.5035 (0.5262)  labels_encoder_unscaled: 0.5035 (0.5262)  time: 0.1212  data: 0.0003  max mem: 1206
Epoch: [4]  [1509/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5035 (0.5262)  labels_encoder: 0.5035 (0.5262)  labels_encoder_unscaled: 0.5035 (0.5262)  time: 0.1118  data: 0.0002  max mem: 1206
Epoch: [4] Total time: 0:03:26 (0.1366 s / it)
Averaged stats: lr: 0.000000  loss: 0.5035 (0.5262)  labels_encoder: 0.5035 (0.5262)  labels_encoder_unscaled: 0.5035 (0.5262)
Test:  [  0/559]  eta: 0:16:30  loss: 0.6647 (0.6647)  labels_encoder: 0.6647 (0.6647)  labels_encoder_unscaled: 0.6647 (0.6647)  time: 1.7723  data: 1.7053  max mem: 1206
Test:  [ 50/559]  eta: 0:00:46  loss: 0.9398 (0.9171)  labels_encoder: 0.9398 (0.9171)  labels_encoder_unscaled: 0.9398 (0.9171)  time: 0.0531  data: 0.0001  max mem: 1206
Test:  [100/559]  eta: 0:00:32  loss: 0.5151 (0.8608)  labels_encoder: 0.5151 (0.8608)  labels_encoder_unscaled: 0.5151 (0.8608)  time: 0.0500  data: 0.0001  max mem: 1206
Test:  [150/559]  eta: 0:00:25  loss: 0.4588 (0.8811)  labels_encoder: 0.4588 (0.8811)  labels_encoder_unscaled: 0.4588 (0.8811)  time: 0.0486  data: 0.0002  max mem: 1206
Test:  [200/559]  eta: 0:00:21  loss: 0.6417 (0.8171)  labels_encoder: 0.6417 (0.8171)  labels_encoder_unscaled: 0.6417 (0.8171)  time: 0.0485  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:18  loss: 0.6801 (0.9438)  labels_encoder: 0.6801 (0.9438)  labels_encoder_unscaled: 0.6801 (0.9438)  time: 0.0712  data: 0.0002  max mem: 1206
Test:  [300/559]  eta: 0:00:15  loss: 1.1021 (0.9924)  labels_encoder: 1.1021 (0.9924)  labels_encoder_unscaled: 1.1021 (0.9924)  time: 0.0530  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:12  loss: 0.7605 (1.0148)  labels_encoder: 0.7605 (1.0148)  labels_encoder_unscaled: 0.7605 (1.0148)  time: 0.0555  data: 0.0002  max mem: 1206
Test:  [400/559]  eta: 0:00:09  loss: 0.3304 (0.9879)  labels_encoder: 0.3304 (0.9879)  labels_encoder_unscaled: 0.3304 (0.9879)  time: 0.0472  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.4263 (0.9623)  labels_encoder: 0.4263 (0.9623)  labels_encoder_unscaled: 0.4263 (0.9623)  time: 0.0644  data: 0.0038  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.6192 (0.9429)  labels_encoder: 0.6192 (0.9429)  labels_encoder_unscaled: 0.6192 (0.9429)  time: 0.0628  data: 0.0002  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.8231 (0.9155)  labels_encoder: 0.8231 (0.9155)  labels_encoder_unscaled: 0.8231 (0.9155)  time: 0.0527  data: 0.0002  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3621 (0.9090)  labels_encoder: 0.3621 (0.9090)  labels_encoder_unscaled: 0.3621 (0.9090)  time: 0.0425  data: 0.0001  max mem: 1206
Test: Total time: 0:00:32 (0.0581 s / it)
Averaged stats: loss: 0.3621 (0.9090)  labels_encoder: 0.3621 (0.9090)  labels_encoder_unscaled: 0.3621 (0.9090)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1252, mcAP: 0.8766

BaseballPitch: 0.0570
BasketballDunk: 0.1210
Billiards: 0.0041
CleanAndJerk: 0.3926
CliffDiving: 0.4033
CricketBowling: 0.0558
CricketShot: 0.0931
Diving: 0.0047
FrisbeeCatch: 0.1330
GolfSwing: 0.0649
HammerThrow: 0.0813
HighJump: 0.0327
JavelinThrow: 0.0792
LongJump: 0.3045
PoleVault: 0.1065
Shotput: 0.1458
SoccerPenalty: 0.0539
TennisSwing: 0.1939
ThrowDiscus: 0.0413
VolleyballSpiking: 0.1359
Training time 0:15:55
