Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:3
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1510]  eta: 1:02:32  lr: 0.000100  loss: 3.9666 (3.9666)  labels_encoder: 3.9666 (3.9666)  labels_encoder_unscaled: 3.9666 (3.9666)  time: 2.4854  data: 2.3603  max mem: 483
Epoch: [1]  [  50/1510]  eta: 0:02:20  lr: 0.000100  loss: 0.9842 (1.1519)  labels_encoder: 0.9842 (1.1519)  labels_encoder_unscaled: 0.9842 (1.1519)  time: 0.0530  data: 0.0150  max mem: 593
Epoch: [1]  [ 100/1510]  eta: 0:01:43  lr: 0.000100  loss: 0.9976 (1.0720)  labels_encoder: 0.9976 (1.0720)  labels_encoder_unscaled: 0.9976 (1.0720)  time: 0.0463  data: 0.0144  max mem: 593
Epoch: [1]  [ 150/1510]  eta: 0:01:29  lr: 0.000100  loss: 1.0443 (1.0394)  labels_encoder: 1.0443 (1.0394)  labels_encoder_unscaled: 1.0443 (1.0394)  time: 0.0493  data: 0.0218  max mem: 593
Epoch: [1]  [ 200/1510]  eta: 0:01:20  lr: 0.000100  loss: 0.9026 (1.0061)  labels_encoder: 0.9026 (1.0061)  labels_encoder_unscaled: 0.9026 (1.0061)  time: 0.0464  data: 0.0195  max mem: 593
Epoch: [1]  [ 250/1510]  eta: 0:01:14  lr: 0.000100  loss: 0.8322 (0.9827)  labels_encoder: 0.8322 (0.9827)  labels_encoder_unscaled: 0.8322 (0.9827)  time: 0.0474  data: 0.0210  max mem: 593
Epoch: [1]  [ 300/1510]  eta: 0:01:09  lr: 0.000100  loss: 0.8441 (0.9692)  labels_encoder: 0.8441 (0.9692)  labels_encoder_unscaled: 0.8441 (0.9692)  time: 0.0530  data: 0.0268  max mem: 593
Epoch: [1]  [ 350/1510]  eta: 0:01:06  lr: 0.000100  loss: 0.8043 (0.9514)  labels_encoder: 0.8043 (0.9514)  labels_encoder_unscaled: 0.8043 (0.9514)  time: 0.0493  data: 0.0232  max mem: 593
Epoch: [1]  [ 400/1510]  eta: 0:01:02  lr: 0.000100  loss: 0.8652 (0.9410)  labels_encoder: 0.8652 (0.9410)  labels_encoder_unscaled: 0.8652 (0.9410)  time: 0.0595  data: 0.0316  max mem: 593
Epoch: [1]  [ 450/1510]  eta: 0:00:59  lr: 0.000100  loss: 0.7948 (0.9286)  labels_encoder: 0.7948 (0.9286)  labels_encoder_unscaled: 0.7948 (0.9286)  time: 0.0566  data: 0.0294  max mem: 593
Epoch: [1]  [ 500/1510]  eta: 0:00:56  lr: 0.000100  loss: 0.8899 (0.9196)  labels_encoder: 0.8899 (0.9196)  labels_encoder_unscaled: 0.8899 (0.9196)  time: 0.0516  data: 0.0245  max mem: 593
Epoch: [1]  [ 550/1510]  eta: 0:00:53  lr: 0.000100  loss: 0.7339 (0.9093)  labels_encoder: 0.7339 (0.9093)  labels_encoder_unscaled: 0.7339 (0.9093)  time: 0.0499  data: 0.0223  max mem: 593
Epoch: [1]  [ 600/1510]  eta: 0:00:50  lr: 0.000100  loss: 0.7260 (0.8973)  labels_encoder: 0.7260 (0.8973)  labels_encoder_unscaled: 0.7260 (0.8973)  time: 0.0467  data: 0.0179  max mem: 593
Epoch: [1]  [ 650/1510]  eta: 0:00:46  lr: 0.000100  loss: 0.7628 (0.8895)  labels_encoder: 0.7628 (0.8895)  labels_encoder_unscaled: 0.7628 (0.8895)  time: 0.0489  data: 0.0214  max mem: 593
Epoch: [1]  [ 700/1510]  eta: 0:00:44  lr: 0.000100  loss: 0.7688 (0.8816)  labels_encoder: 0.7688 (0.8816)  labels_encoder_unscaled: 0.7688 (0.8816)  time: 0.0521  data: 0.0229  max mem: 593
Epoch: [1]  [ 750/1510]  eta: 0:00:41  lr: 0.000100  loss: 0.7498 (0.8748)  labels_encoder: 0.7498 (0.8748)  labels_encoder_unscaled: 0.7498 (0.8748)  time: 0.0493  data: 0.0224  max mem: 593
Epoch: [1]  [ 800/1510]  eta: 0:00:38  lr: 0.000100  loss: 0.7747 (0.8674)  labels_encoder: 0.7747 (0.8674)  labels_encoder_unscaled: 0.7747 (0.8674)  time: 0.0502  data: 0.0229  max mem: 593
Epoch: [1]  [ 850/1510]  eta: 0:00:35  lr: 0.000100  loss: 0.7556 (0.8596)  labels_encoder: 0.7556 (0.8596)  labels_encoder_unscaled: 0.7556 (0.8596)  time: 0.0503  data: 0.0231  max mem: 593
Epoch: [1]  [ 900/1510]  eta: 0:00:32  lr: 0.000100  loss: 0.7575 (0.8536)  labels_encoder: 0.7575 (0.8536)  labels_encoder_unscaled: 0.7575 (0.8536)  time: 0.0481  data: 0.0195  max mem: 593
Epoch: [1]  [ 950/1510]  eta: 0:00:29  lr: 0.000100  loss: 0.6661 (0.8448)  labels_encoder: 0.6661 (0.8448)  labels_encoder_unscaled: 0.6661 (0.8448)  time: 0.0486  data: 0.0204  max mem: 593
Epoch: [1]  [1000/1510]  eta: 0:00:26  lr: 0.000100  loss: 0.7612 (0.8384)  labels_encoder: 0.7612 (0.8384)  labels_encoder_unscaled: 0.7612 (0.8384)  time: 0.0492  data: 0.0207  max mem: 593
Epoch: [1]  [1050/1510]  eta: 0:00:24  lr: 0.000100  loss: 0.6606 (0.8331)  labels_encoder: 0.6606 (0.8331)  labels_encoder_unscaled: 0.6606 (0.8331)  time: 0.0481  data: 0.0197  max mem: 593
Epoch: [1]  [1100/1510]  eta: 0:00:21  lr: 0.000100  loss: 0.7509 (0.8290)  labels_encoder: 0.7509 (0.8290)  labels_encoder_unscaled: 0.7509 (0.8290)  time: 0.0491  data: 0.0207  max mem: 593
Epoch: [1]  [1150/1510]  eta: 0:00:18  lr: 0.000100  loss: 0.7254 (0.8229)  labels_encoder: 0.7254 (0.8229)  labels_encoder_unscaled: 0.7254 (0.8229)  time: 0.0498  data: 0.0216  max mem: 593
Epoch: [1]  [1200/1510]  eta: 0:00:16  lr: 0.000100  loss: 0.6720 (0.8189)  labels_encoder: 0.6720 (0.8189)  labels_encoder_unscaled: 0.6720 (0.8189)  time: 0.0485  data: 0.0209  max mem: 593
Epoch: [1]  [1250/1510]  eta: 0:00:13  lr: 0.000100  loss: 0.6886 (0.8138)  labels_encoder: 0.6886 (0.8138)  labels_encoder_unscaled: 0.6886 (0.8138)  time: 0.0477  data: 0.0195  max mem: 593
Epoch: [1]  [1300/1510]  eta: 0:00:10  lr: 0.000100  loss: 0.6738 (0.8094)  labels_encoder: 0.6738 (0.8094)  labels_encoder_unscaled: 0.6738 (0.8094)  time: 0.0459  data: 0.0153  max mem: 593
Epoch: [1]  [1350/1510]  eta: 0:00:08  lr: 0.000100  loss: 0.7902 (0.8068)  labels_encoder: 0.7902 (0.8068)  labels_encoder_unscaled: 0.7902 (0.8068)  time: 0.0516  data: 0.0202  max mem: 593
Epoch: [1]  [1400/1510]  eta: 0:00:05  lr: 0.000100  loss: 0.6749 (0.8025)  labels_encoder: 0.6749 (0.8025)  labels_encoder_unscaled: 0.6749 (0.8025)  time: 0.0490  data: 0.0204  max mem: 593
Epoch: [1]  [1450/1510]  eta: 0:00:03  lr: 0.000100  loss: 0.6457 (0.7988)  labels_encoder: 0.6457 (0.7988)  labels_encoder_unscaled: 0.6457 (0.7988)  time: 0.0502  data: 0.0220  max mem: 593
Epoch: [1]  [1500/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6772 (0.7944)  labels_encoder: 0.6772 (0.7944)  labels_encoder_unscaled: 0.6772 (0.7944)  time: 0.0469  data: 0.0168  max mem: 593
Epoch: [1]  [1509/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6853 (0.7938)  labels_encoder: 0.6853 (0.7938)  labels_encoder_unscaled: 0.6853 (0.7938)  time: 0.0451  data: 0.0166  max mem: 593
Epoch: [1] Total time: 0:01:18 (0.0517 s / it)
Averaged stats: lr: 0.000100  loss: 0.6853 (0.7938)  labels_encoder: 0.6853 (0.7938)  labels_encoder_unscaled: 0.6853 (0.7938)
Test:  [  0/559]  eta: 0:14:23  loss: 0.6066 (0.6066)  labels_encoder: 0.6066 (0.6066)  labels_encoder_unscaled: 0.6066 (0.6066)  time: 1.5451  data: 1.5264  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 0.8530 (1.0138)  labels_encoder: 0.8530 (1.0138)  labels_encoder_unscaled: 0.8530 (1.0138)  time: 0.0454  data: 0.0269  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.9098 (1.0311)  labels_encoder: 0.9098 (1.0311)  labels_encoder_unscaled: 0.9098 (1.0311)  time: 0.0492  data: 0.0288  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.9982 (1.0767)  labels_encoder: 0.9982 (1.0767)  labels_encoder_unscaled: 0.9982 (1.0767)  time: 0.0481  data: 0.0322  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6669 (0.9938)  labels_encoder: 0.6669 (0.9938)  labels_encoder_unscaled: 0.6669 (0.9938)  time: 0.0520  data: 0.0367  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.9754 (1.0842)  labels_encoder: 0.9754 (1.0842)  labels_encoder_unscaled: 0.9754 (1.0842)  time: 0.0501  data: 0.0338  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.2144 (1.1310)  labels_encoder: 1.2144 (1.1310)  labels_encoder_unscaled: 1.2144 (1.1310)  time: 0.0509  data: 0.0356  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8019 (1.1368)  labels_encoder: 0.8019 (1.1368)  labels_encoder_unscaled: 0.8019 (1.1368)  time: 0.0494  data: 0.0337  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.5953 (1.1105)  labels_encoder: 0.5953 (1.1105)  labels_encoder_unscaled: 0.5953 (1.1105)  time: 0.0483  data: 0.0316  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.5656 (1.0817)  labels_encoder: 0.5656 (1.0817)  labels_encoder_unscaled: 0.5656 (1.0817)  time: 0.0487  data: 0.0320  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6941 (1.0536)  labels_encoder: 0.6941 (1.0536)  labels_encoder_unscaled: 0.6941 (1.0536)  time: 0.0557  data: 0.0406  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7222 (1.0228)  labels_encoder: 0.7222 (1.0228)  labels_encoder_unscaled: 0.7222 (1.0228)  time: 0.0492  data: 0.0342  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4991 (1.0163)  labels_encoder: 0.4991 (1.0163)  labels_encoder_unscaled: 0.4991 (1.0163)  time: 0.0464  data: 0.0318  max mem: 593
Test: Total time: 0:00:29 (0.0531 s / it)
Averaged stats: loss: 0.4991 (1.0163)  labels_encoder: 0.4991 (1.0163)  labels_encoder_unscaled: 0.4991 (1.0163)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1115, mcAP: 0.8587

BaseballPitch: 0.0315
BasketballDunk: 0.0877
Billiards: 0.0039
CleanAndJerk: 0.3785
CliffDiving: 0.2822
CricketBowling: 0.0869
CricketShot: 0.0912
Diving: 0.0058
FrisbeeCatch: 0.0865
GolfSwing: 0.0374
HammerThrow: 0.0989
HighJump: 0.0155
JavelinThrow: 0.0616
LongJump: 0.3274
PoleVault: 0.0709
Shotput: 0.1389
SoccerPenalty: 0.0372
TennisSwing: 0.1974
ThrowDiscus: 0.0653
VolleyballSpiking: 0.1241
Epoch: [2]  [   0/1510]  eta: 0:48:11  lr: 0.000010  loss: 0.7563 (0.7563)  labels_encoder: 0.7563 (0.7563)  labels_encoder_unscaled: 0.7563 (0.7563)  time: 1.9147  data: 1.8838  max mem: 593
Epoch: [2]  [  50/1510]  eta: 0:02:12  lr: 0.000010  loss: 0.6706 (0.6849)  labels_encoder: 0.6706 (0.6849)  labels_encoder_unscaled: 0.6706 (0.6849)  time: 0.0588  data: 0.0257  max mem: 593
Epoch: [2]  [ 100/1510]  eta: 0:01:37  lr: 0.000010  loss: 0.6064 (0.6657)  labels_encoder: 0.6064 (0.6657)  labels_encoder_unscaled: 0.6064 (0.6657)  time: 0.0504  data: 0.0228  max mem: 593
Epoch: [2]  [ 150/1510]  eta: 0:01:25  lr: 0.000010  loss: 0.6272 (0.6673)  labels_encoder: 0.6272 (0.6673)  labels_encoder_unscaled: 0.6272 (0.6673)  time: 0.0500  data: 0.0216  max mem: 593
Epoch: [2]  [ 200/1510]  eta: 0:01:19  lr: 0.000010  loss: 0.6387 (0.6654)  labels_encoder: 0.6387 (0.6654)  labels_encoder_unscaled: 0.6387 (0.6654)  time: 0.0511  data: 0.0231  max mem: 593
Epoch: [2]  [ 250/1510]  eta: 0:01:14  lr: 0.000010  loss: 0.6512 (0.6613)  labels_encoder: 0.6512 (0.6613)  labels_encoder_unscaled: 0.6512 (0.6613)  time: 0.0519  data: 0.0171  max mem: 593
Epoch: [2]  [ 300/1510]  eta: 0:01:08  lr: 0.000010  loss: 0.6385 (0.6562)  labels_encoder: 0.6385 (0.6562)  labels_encoder_unscaled: 0.6385 (0.6562)  time: 0.0473  data: 0.0144  max mem: 593
Epoch: [2]  [ 350/1510]  eta: 0:01:05  lr: 0.000010  loss: 0.5829 (0.6511)  labels_encoder: 0.5829 (0.6511)  labels_encoder_unscaled: 0.5829 (0.6511)  time: 0.0523  data: 0.0241  max mem: 593
Epoch: [2]  [ 400/1510]  eta: 0:01:01  lr: 0.000010  loss: 0.6327 (0.6498)  labels_encoder: 0.6327 (0.6498)  labels_encoder_unscaled: 0.6327 (0.6498)  time: 0.0495  data: 0.0219  max mem: 593
Epoch: [2]  [ 450/1510]  eta: 0:00:58  lr: 0.000010  loss: 0.6722 (0.6471)  labels_encoder: 0.6722 (0.6471)  labels_encoder_unscaled: 0.6722 (0.6471)  time: 0.0487  data: 0.0125  max mem: 593
Epoch: [2]  [ 500/1510]  eta: 0:00:55  lr: 0.000010  loss: 0.5996 (0.6477)  labels_encoder: 0.5996 (0.6477)  labels_encoder_unscaled: 0.5996 (0.6477)  time: 0.0479  data: 0.0198  max mem: 593
Epoch: [2]  [ 550/1510]  eta: 0:00:52  lr: 0.000010  loss: 0.6106 (0.6445)  labels_encoder: 0.6106 (0.6445)  labels_encoder_unscaled: 0.6106 (0.6445)  time: 0.0491  data: 0.0194  max mem: 593
Epoch: [2]  [ 600/1510]  eta: 0:00:49  lr: 0.000010  loss: 0.5468 (0.6399)  labels_encoder: 0.5468 (0.6399)  labels_encoder_unscaled: 0.5468 (0.6399)  time: 0.0494  data: 0.0204  max mem: 593
Epoch: [2]  [ 650/1510]  eta: 0:00:46  lr: 0.000010  loss: 0.5946 (0.6398)  labels_encoder: 0.5946 (0.6398)  labels_encoder_unscaled: 0.5946 (0.6398)  time: 0.0485  data: 0.0206  max mem: 593
Epoch: [2]  [ 700/1510]  eta: 0:00:43  lr: 0.000010  loss: 0.6044 (0.6375)  labels_encoder: 0.6044 (0.6375)  labels_encoder_unscaled: 0.6044 (0.6375)  time: 0.0511  data: 0.0226  max mem: 593
Epoch: [2]  [ 750/1510]  eta: 0:00:40  lr: 0.000010  loss: 0.6028 (0.6337)  labels_encoder: 0.6028 (0.6337)  labels_encoder_unscaled: 0.6028 (0.6337)  time: 0.0511  data: 0.0238  max mem: 593
Epoch: [2]  [ 800/1510]  eta: 0:00:37  lr: 0.000010  loss: 0.6403 (0.6335)  labels_encoder: 0.6403 (0.6335)  labels_encoder_unscaled: 0.6403 (0.6335)  time: 0.0533  data: 0.0270  max mem: 593
Epoch: [2]  [ 850/1510]  eta: 0:00:34  lr: 0.000010  loss: 0.5540 (0.6304)  labels_encoder: 0.5540 (0.6304)  labels_encoder_unscaled: 0.5540 (0.6304)  time: 0.0479  data: 0.0199  max mem: 593
Epoch: [2]  [ 900/1510]  eta: 0:00:32  lr: 0.000010  loss: 0.5188 (0.6282)  labels_encoder: 0.5188 (0.6282)  labels_encoder_unscaled: 0.5188 (0.6282)  time: 0.0540  data: 0.0260  max mem: 593
Epoch: [2]  [ 950/1510]  eta: 0:00:29  lr: 0.000010  loss: 0.5947 (0.6274)  labels_encoder: 0.5947 (0.6274)  labels_encoder_unscaled: 0.5947 (0.6274)  time: 0.0476  data: 0.0201  max mem: 593
Epoch: [2]  [1000/1510]  eta: 0:00:26  lr: 0.000010  loss: 0.6054 (0.6257)  labels_encoder: 0.6054 (0.6257)  labels_encoder_unscaled: 0.6054 (0.6257)  time: 0.0480  data: 0.0204  max mem: 593
Epoch: [2]  [1050/1510]  eta: 0:00:23  lr: 0.000010  loss: 0.6068 (0.6248)  labels_encoder: 0.6068 (0.6248)  labels_encoder_unscaled: 0.6068 (0.6248)  time: 0.0492  data: 0.0163  max mem: 593
Epoch: [2]  [1100/1510]  eta: 0:00:21  lr: 0.000010  loss: 0.6049 (0.6235)  labels_encoder: 0.6049 (0.6235)  labels_encoder_unscaled: 0.6049 (0.6235)  time: 0.0494  data: 0.0215  max mem: 593
Epoch: [2]  [1150/1510]  eta: 0:00:18  lr: 0.000010  loss: 0.6413 (0.6220)  labels_encoder: 0.6413 (0.6220)  labels_encoder_unscaled: 0.6413 (0.6220)  time: 0.0473  data: 0.0189  max mem: 593
Epoch: [2]  [1200/1510]  eta: 0:00:15  lr: 0.000010  loss: 0.6025 (0.6209)  labels_encoder: 0.6025 (0.6209)  labels_encoder_unscaled: 0.6025 (0.6209)  time: 0.0474  data: 0.0192  max mem: 593
Epoch: [2]  [1250/1510]  eta: 0:00:13  lr: 0.000010  loss: 0.5510 (0.6196)  labels_encoder: 0.5510 (0.6196)  labels_encoder_unscaled: 0.5510 (0.6196)  time: 0.0467  data: 0.0193  max mem: 593
Epoch: [2]  [1300/1510]  eta: 0:00:10  lr: 0.000010  loss: 0.5784 (0.6191)  labels_encoder: 0.5784 (0.6191)  labels_encoder_unscaled: 0.5784 (0.6191)  time: 0.0478  data: 0.0204  max mem: 593
Epoch: [2]  [1350/1510]  eta: 0:00:08  lr: 0.000010  loss: 0.5267 (0.6169)  labels_encoder: 0.5267 (0.6169)  labels_encoder_unscaled: 0.5267 (0.6169)  time: 0.0471  data: 0.0201  max mem: 593
Epoch: [2]  [1400/1510]  eta: 0:00:05  lr: 0.000010  loss: 0.5774 (0.6160)  labels_encoder: 0.5774 (0.6160)  labels_encoder_unscaled: 0.5774 (0.6160)  time: 0.0561  data: 0.0280  max mem: 593
Epoch: [2]  [1450/1510]  eta: 0:00:03  lr: 0.000010  loss: 0.5292 (0.6151)  labels_encoder: 0.5292 (0.6151)  labels_encoder_unscaled: 0.5292 (0.6151)  time: 0.0487  data: 0.0202  max mem: 593
Epoch: [2]  [1500/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.6126 (0.6153)  labels_encoder: 0.6126 (0.6153)  labels_encoder_unscaled: 0.6126 (0.6153)  time: 0.0479  data: 0.0206  max mem: 593
Epoch: [2]  [1509/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5457 (0.6151)  labels_encoder: 0.5457 (0.6151)  labels_encoder_unscaled: 0.5457 (0.6151)  time: 0.0461  data: 0.0186  max mem: 593
Epoch: [2] Total time: 0:01:17 (0.0510 s / it)
Averaged stats: lr: 0.000010  loss: 0.5457 (0.6151)  labels_encoder: 0.5457 (0.6151)  labels_encoder_unscaled: 0.5457 (0.6151)
Test:  [  0/559]  eta: 0:17:00  loss: 0.6290 (0.6290)  labels_encoder: 0.6290 (0.6290)  labels_encoder_unscaled: 0.6290 (0.6290)  time: 1.8261  data: 1.8069  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 0.8488 (0.9076)  labels_encoder: 0.8488 (0.9076)  labels_encoder_unscaled: 0.8488 (0.9076)  time: 0.0527  data: 0.0352  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.6911 (0.8598)  labels_encoder: 0.6911 (0.8598)  labels_encoder_unscaled: 0.6911 (0.8598)  time: 0.0493  data: 0.0330  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.4832 (0.8751)  labels_encoder: 0.4832 (0.8751)  labels_encoder_unscaled: 0.4832 (0.8751)  time: 0.0498  data: 0.0338  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.7285 (0.8208)  labels_encoder: 0.7285 (0.8208)  labels_encoder_unscaled: 0.7285 (0.8208)  time: 0.0494  data: 0.0338  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.6744 (0.9184)  labels_encoder: 0.6744 (0.9184)  labels_encoder_unscaled: 0.6744 (0.9184)  time: 0.0476  data: 0.0317  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1927 (0.9710)  labels_encoder: 1.1927 (0.9710)  labels_encoder_unscaled: 1.1927 (0.9710)  time: 0.0524  data: 0.0363  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7168 (0.9884)  labels_encoder: 0.7168 (0.9884)  labels_encoder_unscaled: 0.7168 (0.9884)  time: 0.0492  data: 0.0324  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3554 (0.9634)  labels_encoder: 0.3554 (0.9634)  labels_encoder_unscaled: 0.3554 (0.9634)  time: 0.0478  data: 0.0328  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3704 (0.9399)  labels_encoder: 0.3704 (0.9399)  labels_encoder_unscaled: 0.3704 (0.9399)  time: 0.0482  data: 0.0321  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5244 (0.9227)  labels_encoder: 0.5244 (0.9227)  labels_encoder_unscaled: 0.5244 (0.9227)  time: 0.0494  data: 0.0332  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7620 (0.8995)  labels_encoder: 0.7620 (0.8995)  labels_encoder_unscaled: 0.7620 (0.8995)  time: 0.0463  data: 0.0305  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3563 (0.8933)  labels_encoder: 0.3563 (0.8933)  labels_encoder_unscaled: 0.3563 (0.8933)  time: 0.0448  data: 0.0295  max mem: 593
Test: Total time: 0:00:29 (0.0527 s / it)
Averaged stats: loss: 0.3563 (0.8933)  labels_encoder: 0.3563 (0.8933)  labels_encoder_unscaled: 0.3563 (0.8933)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1292, mcAP: 0.8806

BaseballPitch: 0.0492
BasketballDunk: 0.0833
Billiards: 0.0046
CleanAndJerk: 0.4041
CliffDiving: 0.3959
CricketBowling: 0.0838
CricketShot: 0.0950
Diving: 0.0063
FrisbeeCatch: 0.1524
GolfSwing: 0.0594
HammerThrow: 0.0861
HighJump: 0.0590
JavelinThrow: 0.0759
LongJump: 0.3345
PoleVault: 0.0897
Shotput: 0.1351
SoccerPenalty: 0.0530
TennisSwing: 0.2161
ThrowDiscus: 0.0383
VolleyballSpiking: 0.1615
Epoch: [3]  [   0/1510]  eta: 0:44:30  lr: 0.000001  loss: 0.6244 (0.6244)  labels_encoder: 0.6244 (0.6244)  labels_encoder_unscaled: 0.6244 (0.6244)  time: 1.7685  data: 1.7358  max mem: 593
Epoch: [3]  [  50/1510]  eta: 0:02:08  lr: 0.000001  loss: 0.5432 (0.5895)  labels_encoder: 0.5432 (0.5895)  labels_encoder_unscaled: 0.5432 (0.5895)  time: 0.0565  data: 0.0220  max mem: 593
Epoch: [3]  [ 100/1510]  eta: 0:01:36  lr: 0.000001  loss: 0.5154 (0.5732)  labels_encoder: 0.5154 (0.5732)  labels_encoder_unscaled: 0.5154 (0.5732)  time: 0.0520  data: 0.0178  max mem: 593
Epoch: [3]  [ 150/1510]  eta: 0:01:23  lr: 0.000001  loss: 0.5753 (0.5844)  labels_encoder: 0.5753 (0.5844)  labels_encoder_unscaled: 0.5753 (0.5844)  time: 0.0482  data: 0.0197  max mem: 593
Epoch: [3]  [ 200/1510]  eta: 0:01:17  lr: 0.000001  loss: 0.5509 (0.5795)  labels_encoder: 0.5509 (0.5795)  labels_encoder_unscaled: 0.5509 (0.5795)  time: 0.0524  data: 0.0203  max mem: 593
Epoch: [3]  [ 250/1510]  eta: 0:01:11  lr: 0.000001  loss: 0.5595 (0.5778)  labels_encoder: 0.5595 (0.5778)  labels_encoder_unscaled: 0.5595 (0.5778)  time: 0.0504  data: 0.0127  max mem: 593
Epoch: [3]  [ 300/1510]  eta: 0:01:07  lr: 0.000001  loss: 0.6134 (0.5803)  labels_encoder: 0.6134 (0.5803)  labels_encoder_unscaled: 0.6134 (0.5803)  time: 0.0541  data: 0.0224  max mem: 593
Epoch: [3]  [ 350/1510]  eta: 0:01:03  lr: 0.000001  loss: 0.5463 (0.5766)  labels_encoder: 0.5463 (0.5766)  labels_encoder_unscaled: 0.5463 (0.5766)  time: 0.0506  data: 0.0186  max mem: 593
Epoch: [3]  [ 400/1510]  eta: 0:01:00  lr: 0.000001  loss: 0.6039 (0.5770)  labels_encoder: 0.6039 (0.5770)  labels_encoder_unscaled: 0.6039 (0.5770)  time: 0.0487  data: 0.0206  max mem: 593
Epoch: [3]  [ 450/1510]  eta: 0:00:56  lr: 0.000001  loss: 0.5580 (0.5773)  labels_encoder: 0.5580 (0.5773)  labels_encoder_unscaled: 0.5580 (0.5773)  time: 0.0469  data: 0.0188  max mem: 593
Epoch: [3]  [ 500/1510]  eta: 0:00:53  lr: 0.000001  loss: 0.6186 (0.5795)  labels_encoder: 0.6186 (0.5795)  labels_encoder_unscaled: 0.6186 (0.5795)  time: 0.0470  data: 0.0164  max mem: 593
Epoch: [3]  [ 550/1510]  eta: 0:00:50  lr: 0.000001  loss: 0.5611 (0.5791)  labels_encoder: 0.5611 (0.5791)  labels_encoder_unscaled: 0.5611 (0.5791)  time: 0.0531  data: 0.0220  max mem: 593
Epoch: [3]  [ 600/1510]  eta: 0:00:47  lr: 0.000001  loss: 0.6033 (0.5803)  labels_encoder: 0.6033 (0.5803)  labels_encoder_unscaled: 0.6033 (0.5803)  time: 0.0485  data: 0.0210  max mem: 593
Epoch: [3]  [ 650/1510]  eta: 0:00:44  lr: 0.000001  loss: 0.5577 (0.5800)  labels_encoder: 0.5577 (0.5800)  labels_encoder_unscaled: 0.5577 (0.5800)  time: 0.0499  data: 0.0224  max mem: 593
Epoch: [3]  [ 700/1510]  eta: 0:00:42  lr: 0.000001  loss: 0.5693 (0.5808)  labels_encoder: 0.5693 (0.5808)  labels_encoder_unscaled: 0.5693 (0.5808)  time: 0.0503  data: 0.0227  max mem: 593
Epoch: [3]  [ 750/1510]  eta: 0:00:39  lr: 0.000001  loss: 0.5424 (0.5797)  labels_encoder: 0.5424 (0.5797)  labels_encoder_unscaled: 0.5424 (0.5797)  time: 0.0475  data: 0.0204  max mem: 593
Epoch: [3]  [ 800/1510]  eta: 0:00:36  lr: 0.000001  loss: 0.5561 (0.5783)  labels_encoder: 0.5561 (0.5783)  labels_encoder_unscaled: 0.5561 (0.5783)  time: 0.0486  data: 0.0211  max mem: 593
Epoch: [3]  [ 850/1510]  eta: 0:00:33  lr: 0.000001  loss: 0.6053 (0.5776)  labels_encoder: 0.6053 (0.5776)  labels_encoder_unscaled: 0.6053 (0.5776)  time: 0.0491  data: 0.0196  max mem: 593
Epoch: [3]  [ 900/1510]  eta: 0:00:31  lr: 0.000001  loss: 0.5475 (0.5779)  labels_encoder: 0.5475 (0.5779)  labels_encoder_unscaled: 0.5475 (0.5779)  time: 0.0482  data: 0.0116  max mem: 593
Epoch: [3]  [ 950/1510]  eta: 0:00:28  lr: 0.000001  loss: 0.6063 (0.5791)  labels_encoder: 0.6063 (0.5791)  labels_encoder_unscaled: 0.6063 (0.5791)  time: 0.0489  data: 0.0155  max mem: 593
Epoch: [3]  [1000/1510]  eta: 0:00:26  lr: 0.000001  loss: 0.5512 (0.5790)  labels_encoder: 0.5512 (0.5790)  labels_encoder_unscaled: 0.5512 (0.5790)  time: 0.0476  data: 0.0190  max mem: 593
Epoch: [3]  [1050/1510]  eta: 0:00:23  lr: 0.000001  loss: 0.5302 (0.5789)  labels_encoder: 0.5302 (0.5789)  labels_encoder_unscaled: 0.5302 (0.5789)  time: 0.0492  data: 0.0203  max mem: 593
Epoch: [3]  [1100/1510]  eta: 0:00:20  lr: 0.000001  loss: 0.5974 (0.5792)  labels_encoder: 0.5974 (0.5792)  labels_encoder_unscaled: 0.5974 (0.5792)  time: 0.0478  data: 0.0201  max mem: 593
Epoch: [3]  [1150/1510]  eta: 0:00:18  lr: 0.000001  loss: 0.5480 (0.5784)  labels_encoder: 0.5480 (0.5784)  labels_encoder_unscaled: 0.5480 (0.5784)  time: 0.0507  data: 0.0226  max mem: 593
Epoch: [3]  [1200/1510]  eta: 0:00:15  lr: 0.000001  loss: 0.5956 (0.5789)  labels_encoder: 0.5956 (0.5789)  labels_encoder_unscaled: 0.5956 (0.5789)  time: 0.0486  data: 0.0203  max mem: 593
Epoch: [3]  [1250/1510]  eta: 0:00:13  lr: 0.000001  loss: 0.5530 (0.5774)  labels_encoder: 0.5530 (0.5774)  labels_encoder_unscaled: 0.5530 (0.5774)  time: 0.0487  data: 0.0205  max mem: 593
Epoch: [3]  [1300/1510]  eta: 0:00:10  lr: 0.000001  loss: 0.5631 (0.5772)  labels_encoder: 0.5631 (0.5772)  labels_encoder_unscaled: 0.5631 (0.5772)  time: 0.0489  data: 0.0207  max mem: 593
Epoch: [3]  [1350/1510]  eta: 0:00:08  lr: 0.000001  loss: 0.6284 (0.5771)  labels_encoder: 0.6284 (0.5771)  labels_encoder_unscaled: 0.6284 (0.5771)  time: 0.0486  data: 0.0203  max mem: 593
Epoch: [3]  [1400/1510]  eta: 0:00:05  lr: 0.000001  loss: 0.5701 (0.5765)  labels_encoder: 0.5701 (0.5765)  labels_encoder_unscaled: 0.5701 (0.5765)  time: 0.0458  data: 0.0153  max mem: 593
Epoch: [3]  [1450/1510]  eta: 0:00:03  lr: 0.000001  loss: 0.5842 (0.5769)  labels_encoder: 0.5842 (0.5769)  labels_encoder_unscaled: 0.5842 (0.5769)  time: 0.0490  data: 0.0205  max mem: 593
Epoch: [3]  [1500/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5365 (0.5771)  labels_encoder: 0.5365 (0.5771)  labels_encoder_unscaled: 0.5365 (0.5771)  time: 0.0479  data: 0.0199  max mem: 593
Epoch: [3]  [1509/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5458 (0.5770)  labels_encoder: 0.5458 (0.5770)  labels_encoder_unscaled: 0.5458 (0.5770)  time: 0.0463  data: 0.0187  max mem: 593
Epoch: [3] Total time: 0:01:16 (0.0505 s / it)
Averaged stats: lr: 0.000001  loss: 0.5458 (0.5770)  labels_encoder: 0.5458 (0.5770)  labels_encoder_unscaled: 0.5458 (0.5770)
Test:  [  0/559]  eta: 0:16:27  loss: 0.6219 (0.6219)  labels_encoder: 0.6219 (0.6219)  labels_encoder_unscaled: 0.6219 (0.6219)  time: 1.7670  data: 1.7514  max mem: 593
Test:  [ 50/559]  eta: 0:00:40  loss: 0.7246 (0.8871)  labels_encoder: 0.7246 (0.8871)  labels_encoder_unscaled: 0.7246 (0.8871)  time: 0.0446  data: 0.0277  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.4594 (0.8338)  labels_encoder: 0.4594 (0.8338)  labels_encoder_unscaled: 0.4594 (0.8338)  time: 0.0480  data: 0.0322  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.4885 (0.8638)  labels_encoder: 0.4885 (0.8638)  labels_encoder_unscaled: 0.4885 (0.8638)  time: 0.0447  data: 0.0279  max mem: 593
Test:  [200/559]  eta: 0:00:19  loss: 0.6902 (0.8143)  labels_encoder: 0.6902 (0.8143)  labels_encoder_unscaled: 0.6902 (0.8143)  time: 0.0472  data: 0.0313  max mem: 593
Test:  [250/559]  eta: 0:00:16  loss: 0.7291 (0.9177)  labels_encoder: 0.7291 (0.9177)  labels_encoder_unscaled: 0.7291 (0.9177)  time: 0.0499  data: 0.0339  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1524 (0.9727)  labels_encoder: 1.1524 (0.9727)  labels_encoder_unscaled: 1.1524 (0.9727)  time: 0.0472  data: 0.0305  max mem: 593
Test:  [350/559]  eta: 0:00:10  loss: 0.7624 (0.9873)  labels_encoder: 0.7624 (0.9873)  labels_encoder_unscaled: 0.7624 (0.9873)  time: 0.0486  data: 0.0319  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3615 (0.9619)  labels_encoder: 0.3615 (0.9619)  labels_encoder_unscaled: 0.3615 (0.9619)  time: 0.0471  data: 0.0319  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4218 (0.9391)  labels_encoder: 0.4218 (0.9391)  labels_encoder_unscaled: 0.4218 (0.9391)  time: 0.0484  data: 0.0333  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5473 (0.9199)  labels_encoder: 0.5473 (0.9199)  labels_encoder_unscaled: 0.5473 (0.9199)  time: 0.0482  data: 0.0333  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7572 (0.8956)  labels_encoder: 0.7572 (0.8956)  labels_encoder_unscaled: 0.7572 (0.8956)  time: 0.0476  data: 0.0328  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3508 (0.8896)  labels_encoder: 0.3508 (0.8896)  labels_encoder_unscaled: 0.3508 (0.8896)  time: 0.0467  data: 0.0321  max mem: 593
Test: Total time: 0:00:28 (0.0514 s / it)
Averaged stats: loss: 0.3508 (0.8896)  labels_encoder: 0.3508 (0.8896)  labels_encoder_unscaled: 0.3508 (0.8896)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1331, mcAP: 0.8822

BaseballPitch: 0.0423
BasketballDunk: 0.0902
Billiards: 0.0049
CleanAndJerk: 0.4222
CliffDiving: 0.4030
CricketBowling: 0.0817
CricketShot: 0.1068
Diving: 0.0178
FrisbeeCatch: 0.1661
GolfSwing: 0.0601
HammerThrow: 0.0896
HighJump: 0.0345
JavelinThrow: 0.0606
LongJump: 0.3927
PoleVault: 0.1052
Shotput: 0.1418
SoccerPenalty: 0.0541
TennisSwing: 0.1778
ThrowDiscus: 0.0476
VolleyballSpiking: 0.1625
Epoch: [4]  [   0/1510]  eta: 0:43:25  lr: 0.000000  loss: 0.5073 (0.5073)  labels_encoder: 0.5073 (0.5073)  labels_encoder_unscaled: 0.5073 (0.5073)  time: 1.7255  data: 1.6945  max mem: 593
Epoch: [4]  [  50/1510]  eta: 0:02:02  lr: 0.000000  loss: 0.5480 (0.5596)  labels_encoder: 0.5480 (0.5596)  labels_encoder_unscaled: 0.5480 (0.5596)  time: 0.0503  data: 0.0141  max mem: 593
Epoch: [4]  [ 100/1510]  eta: 0:01:35  lr: 0.000000  loss: 0.5693 (0.5704)  labels_encoder: 0.5693 (0.5704)  labels_encoder_unscaled: 0.5693 (0.5704)  time: 0.0470  data: 0.0164  max mem: 593
Epoch: [4]  [ 150/1510]  eta: 0:01:22  lr: 0.000000  loss: 0.5871 (0.5715)  labels_encoder: 0.5871 (0.5715)  labels_encoder_unscaled: 0.5871 (0.5715)  time: 0.0494  data: 0.0222  max mem: 593
Epoch: [4]  [ 200/1510]  eta: 0:01:15  lr: 0.000000  loss: 0.5629 (0.5711)  labels_encoder: 0.5629 (0.5711)  labels_encoder_unscaled: 0.5629 (0.5711)  time: 0.0473  data: 0.0191  max mem: 593
Epoch: [4]  [ 250/1510]  eta: 0:01:10  lr: 0.000000  loss: 0.5456 (0.5722)  labels_encoder: 0.5456 (0.5722)  labels_encoder_unscaled: 0.5456 (0.5722)  time: 0.0500  data: 0.0216  max mem: 593
Epoch: [4]  [ 300/1510]  eta: 0:01:06  lr: 0.000000  loss: 0.5263 (0.5711)  labels_encoder: 0.5263 (0.5711)  labels_encoder_unscaled: 0.5263 (0.5711)  time: 0.0497  data: 0.0220  max mem: 593
Epoch: [4]  [ 350/1510]  eta: 0:01:02  lr: 0.000000  loss: 0.5745 (0.5723)  labels_encoder: 0.5745 (0.5723)  labels_encoder_unscaled: 0.5745 (0.5723)  time: 0.0499  data: 0.0199  max mem: 593
Epoch: [4]  [ 400/1510]  eta: 0:00:59  lr: 0.000000  loss: 0.5834 (0.5711)  labels_encoder: 0.5834 (0.5711)  labels_encoder_unscaled: 0.5834 (0.5711)  time: 0.0514  data: 0.0234  max mem: 593
Epoch: [4]  [ 450/1510]  eta: 0:00:55  lr: 0.000000  loss: 0.5239 (0.5719)  labels_encoder: 0.5239 (0.5719)  labels_encoder_unscaled: 0.5239 (0.5719)  time: 0.0471  data: 0.0188  max mem: 593
Epoch: [4]  [ 500/1510]  eta: 0:00:52  lr: 0.000000  loss: 0.5438 (0.5718)  labels_encoder: 0.5438 (0.5718)  labels_encoder_unscaled: 0.5438 (0.5718)  time: 0.0475  data: 0.0192  max mem: 593
Epoch: [4]  [ 550/1510]  eta: 0:00:49  lr: 0.000000  loss: 0.4756 (0.5702)  labels_encoder: 0.4756 (0.5702)  labels_encoder_unscaled: 0.4756 (0.5702)  time: 0.0479  data: 0.0175  max mem: 593
Epoch: [4]  [ 600/1510]  eta: 0:00:46  lr: 0.000000  loss: 0.5187 (0.5686)  labels_encoder: 0.5187 (0.5686)  labels_encoder_unscaled: 0.5187 (0.5686)  time: 0.0487  data: 0.0206  max mem: 593
Epoch: [4]  [ 650/1510]  eta: 0:00:44  lr: 0.000000  loss: 0.6170 (0.5691)  labels_encoder: 0.6170 (0.5691)  labels_encoder_unscaled: 0.6170 (0.5691)  time: 0.0479  data: 0.0182  max mem: 593
Epoch: [4]  [ 700/1510]  eta: 0:00:41  lr: 0.000000  loss: 0.4895 (0.5667)  labels_encoder: 0.4895 (0.5667)  labels_encoder_unscaled: 0.4895 (0.5667)  time: 0.0535  data: 0.0248  max mem: 593
Epoch: [4]  [ 750/1510]  eta: 0:00:38  lr: 0.000000  loss: 0.5348 (0.5667)  labels_encoder: 0.5348 (0.5667)  labels_encoder_unscaled: 0.5348 (0.5667)  time: 0.0526  data: 0.0250  max mem: 593
Epoch: [4]  [ 800/1510]  eta: 0:00:36  lr: 0.000000  loss: 0.5496 (0.5678)  labels_encoder: 0.5496 (0.5678)  labels_encoder_unscaled: 0.5496 (0.5678)  time: 0.0473  data: 0.0200  max mem: 593
Epoch: [4]  [ 850/1510]  eta: 0:00:33  lr: 0.000000  loss: 0.6005 (0.5689)  labels_encoder: 0.6005 (0.5689)  labels_encoder_unscaled: 0.6005 (0.5689)  time: 0.0480  data: 0.0197  max mem: 593
Epoch: [4]  [ 900/1510]  eta: 0:00:30  lr: 0.000000  loss: 0.5721 (0.5695)  labels_encoder: 0.5721 (0.5695)  labels_encoder_unscaled: 0.5721 (0.5695)  time: 0.0510  data: 0.0197  max mem: 593
Epoch: [4]  [ 950/1510]  eta: 0:00:28  lr: 0.000000  loss: 0.5244 (0.5703)  labels_encoder: 0.5244 (0.5703)  labels_encoder_unscaled: 0.5244 (0.5703)  time: 0.0487  data: 0.0178  max mem: 593
Epoch: [4]  [1000/1510]  eta: 0:00:25  lr: 0.000000  loss: 0.5610 (0.5701)  labels_encoder: 0.5610 (0.5701)  labels_encoder_unscaled: 0.5610 (0.5701)  time: 0.0494  data: 0.0214  max mem: 593
Epoch: [4]  [1050/1510]  eta: 0:00:23  lr: 0.000000  loss: 0.5288 (0.5695)  labels_encoder: 0.5288 (0.5695)  labels_encoder_unscaled: 0.5288 (0.5695)  time: 0.0516  data: 0.0235  max mem: 593
Epoch: [4]  [1100/1510]  eta: 0:00:20  lr: 0.000000  loss: 0.5354 (0.5698)  labels_encoder: 0.5354 (0.5698)  labels_encoder_unscaled: 0.5354 (0.5698)  time: 0.0481  data: 0.0207  max mem: 593
Epoch: [4]  [1150/1510]  eta: 0:00:18  lr: 0.000000  loss: 0.5718 (0.5697)  labels_encoder: 0.5718 (0.5697)  labels_encoder_unscaled: 0.5718 (0.5697)  time: 0.0474  data: 0.0210  max mem: 593
Epoch: [4]  [1200/1510]  eta: 0:00:15  lr: 0.000000  loss: 0.5361 (0.5703)  labels_encoder: 0.5361 (0.5703)  labels_encoder_unscaled: 0.5361 (0.5703)  time: 0.0476  data: 0.0214  max mem: 593
Epoch: [4]  [1250/1510]  eta: 0:00:13  lr: 0.000000  loss: 0.5592 (0.5704)  labels_encoder: 0.5592 (0.5704)  labels_encoder_unscaled: 0.5592 (0.5704)  time: 0.0457  data: 0.0155  max mem: 593
Epoch: [4]  [1300/1510]  eta: 0:00:10  lr: 0.000000  loss: 0.5684 (0.5700)  labels_encoder: 0.5684 (0.5700)  labels_encoder_unscaled: 0.5684 (0.5700)  time: 0.0481  data: 0.0219  max mem: 593
Epoch: [4]  [1350/1510]  eta: 0:00:08  lr: 0.000000  loss: 0.6036 (0.5708)  labels_encoder: 0.6036 (0.5708)  labels_encoder_unscaled: 0.6036 (0.5708)  time: 0.0492  data: 0.0230  max mem: 593
Epoch: [4]  [1400/1510]  eta: 0:00:05  lr: 0.000000  loss: 0.5212 (0.5701)  labels_encoder: 0.5212 (0.5701)  labels_encoder_unscaled: 0.5212 (0.5701)  time: 0.0482  data: 0.0219  max mem: 593
Epoch: [4]  [1450/1510]  eta: 0:00:02  lr: 0.000000  loss: 0.5865 (0.5702)  labels_encoder: 0.5865 (0.5702)  labels_encoder_unscaled: 0.5865 (0.5702)  time: 0.0472  data: 0.0212  max mem: 593
Epoch: [4]  [1500/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5601 (0.5694)  labels_encoder: 0.5601 (0.5694)  labels_encoder_unscaled: 0.5601 (0.5694)  time: 0.0463  data: 0.0194  max mem: 593
Epoch: [4]  [1509/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5601 (0.5694)  labels_encoder: 0.5601 (0.5694)  labels_encoder_unscaled: 0.5601 (0.5694)  time: 0.0449  data: 0.0183  max mem: 593
Epoch: [4] Total time: 0:01:15 (0.0500 s / it)
Averaged stats: lr: 0.000000  loss: 0.5601 (0.5694)  labels_encoder: 0.5601 (0.5694)  labels_encoder_unscaled: 0.5601 (0.5694)
Test:  [  0/559]  eta: 0:14:34  loss: 0.6336 (0.6336)  labels_encoder: 0.6336 (0.6336)  labels_encoder_unscaled: 0.6336 (0.6336)  time: 1.5645  data: 1.5456  max mem: 593
Test:  [ 50/559]  eta: 0:00:44  loss: 0.8546 (0.8870)  labels_encoder: 0.8546 (0.8870)  labels_encoder_unscaled: 0.8546 (0.8870)  time: 0.0528  data: 0.0357  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.6361 (0.8478)  labels_encoder: 0.6361 (0.8478)  labels_encoder_unscaled: 0.6361 (0.8478)  time: 0.0483  data: 0.0330  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.4455 (0.8758)  labels_encoder: 0.4455 (0.8758)  labels_encoder_unscaled: 0.4455 (0.8758)  time: 0.0498  data: 0.0340  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6828 (0.8202)  labels_encoder: 0.6828 (0.8202)  labels_encoder_unscaled: 0.6828 (0.8202)  time: 0.0474  data: 0.0292  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.6679 (0.9244)  labels_encoder: 0.6679 (0.9244)  labels_encoder_unscaled: 0.6679 (0.9244)  time: 0.0474  data: 0.0312  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1428 (0.9781)  labels_encoder: 1.1428 (0.9781)  labels_encoder_unscaled: 1.1428 (0.9781)  time: 0.0523  data: 0.0365  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7547 (0.9923)  labels_encoder: 0.7547 (0.9923)  labels_encoder_unscaled: 0.7547 (0.9923)  time: 0.0486  data: 0.0320  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3597 (0.9667)  labels_encoder: 0.3597 (0.9667)  labels_encoder_unscaled: 0.3597 (0.9667)  time: 0.0464  data: 0.0306  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4147 (0.9415)  labels_encoder: 0.4147 (0.9415)  labels_encoder_unscaled: 0.4147 (0.9415)  time: 0.0485  data: 0.0312  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5703 (0.9222)  labels_encoder: 0.5703 (0.9222)  labels_encoder_unscaled: 0.5703 (0.9222)  time: 0.0496  data: 0.0344  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7288 (0.8975)  labels_encoder: 0.7288 (0.8975)  labels_encoder_unscaled: 0.7288 (0.8975)  time: 0.0463  data: 0.0314  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3715 (0.8912)  labels_encoder: 0.3715 (0.8912)  labels_encoder_unscaled: 0.3715 (0.8912)  time: 0.0449  data: 0.0304  max mem: 593
Test: Total time: 0:00:29 (0.0523 s / it)
Averaged stats: loss: 0.3715 (0.8912)  labels_encoder: 0.3715 (0.8912)  labels_encoder_unscaled: 0.3715 (0.8912)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1317, mcAP: 0.8776

BaseballPitch: 0.0417
BasketballDunk: 0.1055
Billiards: 0.0044
CleanAndJerk: 0.4240
CliffDiving: 0.4432
CricketBowling: 0.0752
CricketShot: 0.0947
Diving: 0.0204
FrisbeeCatch: 0.1371
GolfSwing: 0.0621
HammerThrow: 0.0728
HighJump: 0.0351
JavelinThrow: 0.0683
LongJump: 0.3752
PoleVault: 0.1054
Shotput: 0.1411
SoccerPenalty: 0.0523
TennisSwing: 0.1874
ThrowDiscus: 0.0247
VolleyballSpiking: 0.1635
Training time 0:07:13
