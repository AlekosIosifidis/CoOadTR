Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_anet_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:5
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_anet_features.pickle
Loaded tvseries_anet_features.pickle
Start training
Epoch: [1]  [   0/1510]  eta: 0:50:01  lr: 0.000100  loss: 3.6606 (3.6606)  labels_encoder: 3.6606 (3.6606)  labels_encoder_unscaled: 3.6606 (3.6606)  time: 1.9880  data: 1.8776  max mem: 483
Epoch: [1]  [  50/1510]  eta: 0:02:08  lr: 0.000100  loss: 1.0390 (1.2237)  labels_encoder: 1.0390 (1.2237)  labels_encoder_unscaled: 1.0390 (1.2237)  time: 0.0444  data: 0.0046  max mem: 593
Epoch: [1]  [ 100/1510]  eta: 0:01:36  lr: 0.000100  loss: 1.0258 (1.1173)  labels_encoder: 1.0258 (1.1173)  labels_encoder_unscaled: 1.0258 (1.1173)  time: 0.0500  data: 0.0142  max mem: 593
Epoch: [1]  [ 150/1510]  eta: 0:01:23  lr: 0.000100  loss: 0.9402 (1.0581)  labels_encoder: 0.9402 (1.0581)  labels_encoder_unscaled: 0.9402 (1.0581)  time: 0.0474  data: 0.0054  max mem: 593
Epoch: [1]  [ 200/1510]  eta: 0:01:15  lr: 0.000100  loss: 0.8837 (1.0188)  labels_encoder: 0.8837 (1.0188)  labels_encoder_unscaled: 0.8837 (1.0188)  time: 0.0476  data: 0.0172  max mem: 593
Epoch: [1]  [ 250/1510]  eta: 0:01:09  lr: 0.000100  loss: 0.9256 (0.9959)  labels_encoder: 0.9256 (0.9959)  labels_encoder_unscaled: 0.9256 (0.9959)  time: 0.0475  data: 0.0215  max mem: 593
Epoch: [1]  [ 300/1510]  eta: 0:01:06  lr: 0.000100  loss: 0.8162 (0.9748)  labels_encoder: 0.8162 (0.9748)  labels_encoder_unscaled: 0.8162 (0.9748)  time: 0.0490  data: 0.0204  max mem: 593
Epoch: [1]  [ 350/1510]  eta: 0:01:02  lr: 0.000100  loss: 0.7896 (0.9545)  labels_encoder: 0.7896 (0.9545)  labels_encoder_unscaled: 0.7896 (0.9545)  time: 0.0486  data: 0.0226  max mem: 593
Epoch: [1]  [ 400/1510]  eta: 0:00:58  lr: 0.000100  loss: 0.7428 (0.9413)  labels_encoder: 0.7428 (0.9413)  labels_encoder_unscaled: 0.7428 (0.9413)  time: 0.0492  data: 0.0146  max mem: 593
Epoch: [1]  [ 450/1510]  eta: 0:00:55  lr: 0.000100  loss: 0.8233 (0.9294)  labels_encoder: 0.8233 (0.9294)  labels_encoder_unscaled: 0.8233 (0.9294)  time: 0.0490  data: 0.0220  max mem: 593
Epoch: [1]  [ 500/1510]  eta: 0:00:52  lr: 0.000100  loss: 0.8058 (0.9184)  labels_encoder: 0.8058 (0.9184)  labels_encoder_unscaled: 0.8058 (0.9184)  time: 0.0480  data: 0.0213  max mem: 593
Epoch: [1]  [ 550/1510]  eta: 0:00:49  lr: 0.000100  loss: 0.7931 (0.9087)  labels_encoder: 0.7931 (0.9087)  labels_encoder_unscaled: 0.7931 (0.9087)  time: 0.0485  data: 0.0155  max mem: 593
Epoch: [1]  [ 600/1510]  eta: 0:00:46  lr: 0.000100  loss: 0.8513 (0.9020)  labels_encoder: 0.8513 (0.9020)  labels_encoder_unscaled: 0.8513 (0.9020)  time: 0.0474  data: 0.0200  max mem: 593
Epoch: [1]  [ 650/1510]  eta: 0:00:44  lr: 0.000100  loss: 0.8265 (0.8938)  labels_encoder: 0.8265 (0.8938)  labels_encoder_unscaled: 0.8265 (0.8938)  time: 0.0475  data: 0.0172  max mem: 593
Epoch: [1]  [ 700/1510]  eta: 0:00:41  lr: 0.000100  loss: 0.7138 (0.8841)  labels_encoder: 0.7138 (0.8841)  labels_encoder_unscaled: 0.7138 (0.8841)  time: 0.0474  data: 0.0201  max mem: 593
Epoch: [1]  [ 750/1510]  eta: 0:00:38  lr: 0.000100  loss: 0.7444 (0.8765)  labels_encoder: 0.7444 (0.8765)  labels_encoder_unscaled: 0.7444 (0.8765)  time: 0.0504  data: 0.0228  max mem: 593
Epoch: [1]  [ 800/1510]  eta: 0:00:36  lr: 0.000100  loss: 0.6594 (0.8692)  labels_encoder: 0.6594 (0.8692)  labels_encoder_unscaled: 0.6594 (0.8692)  time: 0.0483  data: 0.0209  max mem: 593
Epoch: [1]  [ 850/1510]  eta: 0:00:33  lr: 0.000100  loss: 0.7230 (0.8608)  labels_encoder: 0.7230 (0.8608)  labels_encoder_unscaled: 0.7230 (0.8608)  time: 0.0523  data: 0.0251  max mem: 593
Epoch: [1]  [ 900/1510]  eta: 0:00:30  lr: 0.000100  loss: 0.7983 (0.8540)  labels_encoder: 0.7983 (0.8540)  labels_encoder_unscaled: 0.7983 (0.8540)  time: 0.0478  data: 0.0177  max mem: 593
Epoch: [1]  [ 950/1510]  eta: 0:00:28  lr: 0.000100  loss: 0.7521 (0.8497)  labels_encoder: 0.7521 (0.8497)  labels_encoder_unscaled: 0.7521 (0.8497)  time: 0.0483  data: 0.0178  max mem: 593
Epoch: [1]  [1000/1510]  eta: 0:00:25  lr: 0.000100  loss: 0.7069 (0.8431)  labels_encoder: 0.7069 (0.8431)  labels_encoder_unscaled: 0.7069 (0.8431)  time: 0.0480  data: 0.0212  max mem: 593
Epoch: [1]  [1050/1510]  eta: 0:00:23  lr: 0.000100  loss: 0.7933 (0.8400)  labels_encoder: 0.7933 (0.8400)  labels_encoder_unscaled: 0.7933 (0.8400)  time: 0.0523  data: 0.0212  max mem: 593
Epoch: [1]  [1100/1510]  eta: 0:00:20  lr: 0.000100  loss: 0.7093 (0.8339)  labels_encoder: 0.7093 (0.8339)  labels_encoder_unscaled: 0.7093 (0.8339)  time: 0.0502  data: 0.0196  max mem: 593
Epoch: [1]  [1150/1510]  eta: 0:00:18  lr: 0.000100  loss: 0.6736 (0.8286)  labels_encoder: 0.6736 (0.8286)  labels_encoder_unscaled: 0.6736 (0.8286)  time: 0.0484  data: 0.0212  max mem: 593
Epoch: [1]  [1200/1510]  eta: 0:00:15  lr: 0.000100  loss: 0.7440 (0.8235)  labels_encoder: 0.7440 (0.8235)  labels_encoder_unscaled: 0.7440 (0.8235)  time: 0.0481  data: 0.0206  max mem: 593
Epoch: [1]  [1250/1510]  eta: 0:00:13  lr: 0.000100  loss: 0.7312 (0.8203)  labels_encoder: 0.7312 (0.8203)  labels_encoder_unscaled: 0.7312 (0.8203)  time: 0.0491  data: 0.0194  max mem: 593
Epoch: [1]  [1300/1510]  eta: 0:00:10  lr: 0.000100  loss: 0.7001 (0.8157)  labels_encoder: 0.7001 (0.8157)  labels_encoder_unscaled: 0.7001 (0.8157)  time: 0.0477  data: 0.0203  max mem: 593
Epoch: [1]  [1350/1510]  eta: 0:00:08  lr: 0.000100  loss: 0.6624 (0.8106)  labels_encoder: 0.6624 (0.8106)  labels_encoder_unscaled: 0.6624 (0.8106)  time: 0.0502  data: 0.0221  max mem: 593
Epoch: [1]  [1400/1510]  eta: 0:00:05  lr: 0.000100  loss: 0.7043 (0.8067)  labels_encoder: 0.7043 (0.8067)  labels_encoder_unscaled: 0.7043 (0.8067)  time: 0.0489  data: 0.0218  max mem: 593
Epoch: [1]  [1450/1510]  eta: 0:00:03  lr: 0.000100  loss: 0.6510 (0.8019)  labels_encoder: 0.6510 (0.8019)  labels_encoder_unscaled: 0.6510 (0.8019)  time: 0.0482  data: 0.0200  max mem: 593
Epoch: [1]  [1500/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6678 (0.7979)  labels_encoder: 0.6678 (0.7979)  labels_encoder_unscaled: 0.6678 (0.7979)  time: 0.0523  data: 0.0241  max mem: 593
Epoch: [1]  [1509/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6185 (0.7973)  labels_encoder: 0.6185 (0.7973)  labels_encoder_unscaled: 0.6185 (0.7973)  time: 0.0491  data: 0.0179  max mem: 593
Epoch: [1] Total time: 0:01:16 (0.0504 s / it)
Averaged stats: lr: 0.000100  loss: 0.6185 (0.7973)  labels_encoder: 0.6185 (0.7973)  labels_encoder_unscaled: 0.6185 (0.7973)
Test:  [  0/559]  eta: 0:17:38  loss: 0.5539 (0.5539)  labels_encoder: 0.5539 (0.5539)  labels_encoder_unscaled: 0.5539 (0.5539)  time: 1.8929  data: 1.8468  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.6846 (0.9393)  labels_encoder: 0.6846 (0.9393)  labels_encoder_unscaled: 0.6846 (0.9393)  time: 0.0476  data: 0.0306  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.5135 (0.8654)  labels_encoder: 0.5135 (0.8654)  labels_encoder_unscaled: 0.5135 (0.8654)  time: 0.0471  data: 0.0309  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.7835 (0.9040)  labels_encoder: 0.7835 (0.9040)  labels_encoder_unscaled: 0.7835 (0.9040)  time: 0.0489  data: 0.0333  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6519 (0.8475)  labels_encoder: 0.6519 (0.8475)  labels_encoder_unscaled: 0.6519 (0.8475)  time: 0.0486  data: 0.0316  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7434 (0.9536)  labels_encoder: 0.7434 (0.9536)  labels_encoder_unscaled: 0.7434 (0.9536)  time: 0.0466  data: 0.0302  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1546 (1.0061)  labels_encoder: 1.1546 (1.0061)  labels_encoder_unscaled: 1.1546 (1.0061)  time: 0.0473  data: 0.0308  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7483 (1.0163)  labels_encoder: 0.7483 (1.0163)  labels_encoder_unscaled: 0.7483 (1.0163)  time: 0.0485  data: 0.0333  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.4260 (0.9972)  labels_encoder: 0.4260 (0.9972)  labels_encoder_unscaled: 0.4260 (0.9972)  time: 0.0487  data: 0.0326  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4950 (0.9783)  labels_encoder: 0.4950 (0.9783)  labels_encoder_unscaled: 0.4950 (0.9783)  time: 0.0478  data: 0.0319  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6859 (0.9567)  labels_encoder: 0.6859 (0.9567)  labels_encoder_unscaled: 0.6859 (0.9567)  time: 0.0487  data: 0.0325  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6898 (0.9325)  labels_encoder: 0.6898 (0.9325)  labels_encoder_unscaled: 0.6898 (0.9325)  time: 0.0472  data: 0.0290  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4755 (0.9264)  labels_encoder: 0.4755 (0.9264)  labels_encoder_unscaled: 0.4755 (0.9264)  time: 0.0441  data: 0.0291  max mem: 593
Test: Total time: 0:00:29 (0.0524 s / it)
Averaged stats: loss: 0.4755 (0.9264)  labels_encoder: 0.4755 (0.9264)  labels_encoder_unscaled: 0.4755 (0.9264)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_anet_features.pickle] mAP: 0.1213, mcAP: 0.8603

BaseballPitch: 0.0864
BasketballDunk: 0.0631
Billiards: 0.0043
CleanAndJerk: 0.3532
CliffDiving: 0.5686
CricketBowling: 0.0688
CricketShot: 0.0696
Diving: 0.0125
FrisbeeCatch: 0.0854
GolfSwing: 0.0577
HammerThrow: 0.0661
HighJump: 0.0207
JavelinThrow: 0.0253
LongJump: 0.3478
PoleVault: 0.0774
Shotput: 0.1255
SoccerPenalty: 0.0410
TennisSwing: 0.1801
ThrowDiscus: 0.0341
VolleyballSpiking: 0.1390
Epoch: [2]  [   0/1510]  eta: 0:42:20  lr: 0.000010  loss: 0.5389 (0.5389)  labels_encoder: 0.5389 (0.5389)  labels_encoder_unscaled: 0.5389 (0.5389)  time: 1.6823  data: 1.6226  max mem: 593
Epoch: [2]  [  50/1510]  eta: 0:02:04  lr: 0.000010  loss: 0.6401 (0.6337)  labels_encoder: 0.6401 (0.6337)  labels_encoder_unscaled: 0.6401 (0.6337)  time: 0.0421  data: 0.0002  max mem: 593
Epoch: [2]  [ 100/1510]  eta: 0:01:34  lr: 0.000010  loss: 0.5825 (0.6331)  labels_encoder: 0.5825 (0.6331)  labels_encoder_unscaled: 0.5825 (0.6331)  time: 0.0498  data: 0.0224  max mem: 593
Epoch: [2]  [ 150/1510]  eta: 0:01:24  lr: 0.000010  loss: 0.6130 (0.6340)  labels_encoder: 0.6130 (0.6340)  labels_encoder_unscaled: 0.6130 (0.6340)  time: 0.0504  data: 0.0199  max mem: 593
Epoch: [2]  [ 200/1510]  eta: 0:01:16  lr: 0.000010  loss: 0.6427 (0.6399)  labels_encoder: 0.6427 (0.6399)  labels_encoder_unscaled: 0.6427 (0.6399)  time: 0.0496  data: 0.0219  max mem: 593
Epoch: [2]  [ 250/1510]  eta: 0:01:11  lr: 0.000010  loss: 0.5954 (0.6395)  labels_encoder: 0.5954 (0.6395)  labels_encoder_unscaled: 0.5954 (0.6395)  time: 0.0470  data: 0.0074  max mem: 593
Epoch: [2]  [ 300/1510]  eta: 0:01:08  lr: 0.000010  loss: 0.6213 (0.6381)  labels_encoder: 0.6213 (0.6381)  labels_encoder_unscaled: 0.6213 (0.6381)  time: 0.0551  data: 0.0199  max mem: 593
Epoch: [2]  [ 350/1510]  eta: 0:01:04  lr: 0.000010  loss: 0.6507 (0.6362)  labels_encoder: 0.6507 (0.6362)  labels_encoder_unscaled: 0.6507 (0.6362)  time: 0.0513  data: 0.0234  max mem: 593
Epoch: [2]  [ 400/1510]  eta: 0:01:00  lr: 0.000010  loss: 0.6010 (0.6346)  labels_encoder: 0.6010 (0.6346)  labels_encoder_unscaled: 0.6010 (0.6346)  time: 0.0525  data: 0.0242  max mem: 593
Epoch: [2]  [ 450/1510]  eta: 0:00:57  lr: 0.000010  loss: 0.6503 (0.6350)  labels_encoder: 0.6503 (0.6350)  labels_encoder_unscaled: 0.6503 (0.6350)  time: 0.0497  data: 0.0138  max mem: 593
Epoch: [2]  [ 500/1510]  eta: 0:00:54  lr: 0.000010  loss: 0.5790 (0.6310)  labels_encoder: 0.5790 (0.6310)  labels_encoder_unscaled: 0.5790 (0.6310)  time: 0.0489  data: 0.0206  max mem: 593
Epoch: [2]  [ 550/1510]  eta: 0:00:51  lr: 0.000010  loss: 0.5945 (0.6298)  labels_encoder: 0.5945 (0.6298)  labels_encoder_unscaled: 0.5945 (0.6298)  time: 0.0495  data: 0.0211  max mem: 593
Epoch: [2]  [ 600/1510]  eta: 0:00:48  lr: 0.000010  loss: 0.6158 (0.6304)  labels_encoder: 0.6158 (0.6304)  labels_encoder_unscaled: 0.6158 (0.6304)  time: 0.0527  data: 0.0249  max mem: 593
Epoch: [2]  [ 650/1510]  eta: 0:00:45  lr: 0.000010  loss: 0.5775 (0.6304)  labels_encoder: 0.5775 (0.6304)  labels_encoder_unscaled: 0.5775 (0.6304)  time: 0.0489  data: 0.0210  max mem: 593
Epoch: [2]  [ 700/1510]  eta: 0:00:42  lr: 0.000010  loss: 0.6094 (0.6281)  labels_encoder: 0.6094 (0.6281)  labels_encoder_unscaled: 0.6094 (0.6281)  time: 0.0491  data: 0.0213  max mem: 593
Epoch: [2]  [ 750/1510]  eta: 0:00:40  lr: 0.000010  loss: 0.6027 (0.6275)  labels_encoder: 0.6027 (0.6275)  labels_encoder_unscaled: 0.6027 (0.6275)  time: 0.0703  data: 0.0412  max mem: 593
Epoch: [2]  [ 800/1510]  eta: 0:00:37  lr: 0.000010  loss: 0.6606 (0.6279)  labels_encoder: 0.6606 (0.6279)  labels_encoder_unscaled: 0.6606 (0.6279)  time: 0.0521  data: 0.0246  max mem: 593
Epoch: [2]  [ 850/1510]  eta: 0:00:34  lr: 0.000010  loss: 0.5927 (0.6268)  labels_encoder: 0.5927 (0.6268)  labels_encoder_unscaled: 0.5927 (0.6268)  time: 0.0512  data: 0.0229  max mem: 593
Epoch: [2]  [ 900/1510]  eta: 0:00:32  lr: 0.000010  loss: 0.6055 (0.6276)  labels_encoder: 0.6055 (0.6276)  labels_encoder_unscaled: 0.6055 (0.6276)  time: 0.0498  data: 0.0217  max mem: 593
Epoch: [2]  [ 950/1510]  eta: 0:00:29  lr: 0.000010  loss: 0.5749 (0.6264)  labels_encoder: 0.5749 (0.6264)  labels_encoder_unscaled: 0.5749 (0.6264)  time: 0.0496  data: 0.0164  max mem: 593
Epoch: [2]  [1000/1510]  eta: 0:00:26  lr: 0.000010  loss: 0.5706 (0.6247)  labels_encoder: 0.5706 (0.6247)  labels_encoder_unscaled: 0.5706 (0.6247)  time: 0.0544  data: 0.0167  max mem: 593
Epoch: [2]  [1050/1510]  eta: 0:00:24  lr: 0.000010  loss: 0.6044 (0.6227)  labels_encoder: 0.6044 (0.6227)  labels_encoder_unscaled: 0.6044 (0.6227)  time: 0.0490  data: 0.0205  max mem: 593
Epoch: [2]  [1100/1510]  eta: 0:00:21  lr: 0.000010  loss: 0.5944 (0.6215)  labels_encoder: 0.5944 (0.6215)  labels_encoder_unscaled: 0.5944 (0.6215)  time: 0.0488  data: 0.0206  max mem: 593
Epoch: [2]  [1150/1510]  eta: 0:00:18  lr: 0.000010  loss: 0.6166 (0.6213)  labels_encoder: 0.6166 (0.6213)  labels_encoder_unscaled: 0.6166 (0.6213)  time: 0.0576  data: 0.0253  max mem: 593
Epoch: [2]  [1200/1510]  eta: 0:00:16  lr: 0.000010  loss: 0.6251 (0.6214)  labels_encoder: 0.6251 (0.6214)  labels_encoder_unscaled: 0.6251 (0.6214)  time: 0.0520  data: 0.0214  max mem: 593
Epoch: [2]  [1250/1510]  eta: 0:00:13  lr: 0.000010  loss: 0.5890 (0.6197)  labels_encoder: 0.5890 (0.6197)  labels_encoder_unscaled: 0.5890 (0.6197)  time: 0.0501  data: 0.0229  max mem: 593
Epoch: [2]  [1300/1510]  eta: 0:00:10  lr: 0.000010  loss: 0.5637 (0.6195)  labels_encoder: 0.5637 (0.6195)  labels_encoder_unscaled: 0.5637 (0.6195)  time: 0.0506  data: 0.0236  max mem: 593
Epoch: [2]  [1350/1510]  eta: 0:00:08  lr: 0.000010  loss: 0.5825 (0.6179)  labels_encoder: 0.5825 (0.6179)  labels_encoder_unscaled: 0.5825 (0.6179)  time: 0.0525  data: 0.0256  max mem: 593
Epoch: [2]  [1400/1510]  eta: 0:00:05  lr: 0.000010  loss: 0.5770 (0.6175)  labels_encoder: 0.5770 (0.6175)  labels_encoder_unscaled: 0.5770 (0.6175)  time: 0.0616  data: 0.0331  max mem: 593
Epoch: [2]  [1450/1510]  eta: 0:00:03  lr: 0.000010  loss: 0.6263 (0.6172)  labels_encoder: 0.6263 (0.6172)  labels_encoder_unscaled: 0.6263 (0.6172)  time: 0.0502  data: 0.0191  max mem: 593
Epoch: [2]  [1500/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5986 (0.6157)  labels_encoder: 0.5986 (0.6157)  labels_encoder_unscaled: 0.5986 (0.6157)  time: 0.0532  data: 0.0229  max mem: 593
Epoch: [2]  [1509/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5959 (0.6155)  labels_encoder: 0.5959 (0.6155)  labels_encoder_unscaled: 0.5959 (0.6155)  time: 0.0485  data: 0.0183  max mem: 593
Epoch: [2] Total time: 0:01:18 (0.0522 s / it)
Averaged stats: lr: 0.000010  loss: 0.5959 (0.6155)  labels_encoder: 0.5959 (0.6155)  labels_encoder_unscaled: 0.5959 (0.6155)
Test:  [  0/559]  eta: 0:14:25  loss: 0.5550 (0.5550)  labels_encoder: 0.5550 (0.5550)  labels_encoder_unscaled: 0.5550 (0.5550)  time: 1.5491  data: 1.5305  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 0.7878 (0.8552)  labels_encoder: 0.7878 (0.8552)  labels_encoder_unscaled: 0.7878 (0.8552)  time: 0.0471  data: 0.0314  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.8657 (0.8667)  labels_encoder: 0.8657 (0.8667)  labels_encoder_unscaled: 0.8657 (0.8667)  time: 0.0476  data: 0.0310  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.7516 (0.9008)  labels_encoder: 0.7516 (0.9008)  labels_encoder_unscaled: 0.7516 (0.9008)  time: 0.0473  data: 0.0323  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.5827 (0.8499)  labels_encoder: 0.5827 (0.8499)  labels_encoder_unscaled: 0.5827 (0.8499)  time: 0.0527  data: 0.0367  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7451 (0.9564)  labels_encoder: 0.7451 (0.9564)  labels_encoder_unscaled: 0.7451 (0.9564)  time: 0.0478  data: 0.0318  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.0406 (0.9931)  labels_encoder: 1.0406 (0.9931)  labels_encoder_unscaled: 1.0406 (0.9931)  time: 0.0483  data: 0.0312  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7942 (1.0127)  labels_encoder: 0.7942 (1.0127)  labels_encoder_unscaled: 0.7942 (1.0127)  time: 0.0504  data: 0.0345  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.4500 (0.9935)  labels_encoder: 0.4500 (0.9935)  labels_encoder_unscaled: 0.4500 (0.9935)  time: 0.0577  data: 0.0424  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.5349 (0.9748)  labels_encoder: 0.5349 (0.9748)  labels_encoder_unscaled: 0.5349 (0.9748)  time: 0.0483  data: 0.0328  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6504 (0.9565)  labels_encoder: 0.6504 (0.9565)  labels_encoder_unscaled: 0.6504 (0.9565)  time: 0.0509  data: 0.0328  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7168 (0.9292)  labels_encoder: 0.7168 (0.9292)  labels_encoder_unscaled: 0.7168 (0.9292)  time: 0.0481  data: 0.0322  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4109 (0.9232)  labels_encoder: 0.4109 (0.9232)  labels_encoder_unscaled: 0.4109 (0.9232)  time: 0.0477  data: 0.0322  max mem: 593
Test: Total time: 0:00:29 (0.0529 s / it)
Averaged stats: loss: 0.4109 (0.9232)  labels_encoder: 0.4109 (0.9232)  labels_encoder_unscaled: 0.4109 (0.9232)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_anet_features.pickle] mAP: 0.1200, mcAP: 0.8748

BaseballPitch: 0.0675
BasketballDunk: 0.0842
Billiards: 0.0045
CleanAndJerk: 0.3791
CliffDiving: 0.3539
CricketBowling: 0.0639
CricketShot: 0.0948
Diving: 0.0101
FrisbeeCatch: 0.1169
GolfSwing: 0.0697
HammerThrow: 0.0998
HighJump: 0.0263
JavelinThrow: 0.0727
LongJump: 0.2986
PoleVault: 0.1006
Shotput: 0.1449
SoccerPenalty: 0.0439
TennisSwing: 0.2018
ThrowDiscus: 0.0248
VolleyballSpiking: 0.1411
Epoch: [3]  [   0/1510]  eta: 0:52:31  lr: 0.000001  loss: 0.5466 (0.5466)  labels_encoder: 0.5466 (0.5466)  labels_encoder_unscaled: 0.5466 (0.5466)  time: 2.0869  data: 2.0533  max mem: 593
Epoch: [3]  [  50/1510]  eta: 0:02:28  lr: 0.000001  loss: 0.5714 (0.5986)  labels_encoder: 0.5714 (0.5986)  labels_encoder_unscaled: 0.5714 (0.5986)  time: 0.0506  data: 0.0061  max mem: 593
Epoch: [3]  [ 100/1510]  eta: 0:01:47  lr: 0.000001  loss: 0.6276 (0.5948)  labels_encoder: 0.6276 (0.5948)  labels_encoder_unscaled: 0.6276 (0.5948)  time: 0.0488  data: 0.0197  max mem: 593
Epoch: [3]  [ 150/1510]  eta: 0:01:32  lr: 0.000001  loss: 0.5365 (0.5937)  labels_encoder: 0.5365 (0.5937)  labels_encoder_unscaled: 0.5365 (0.5937)  time: 0.0470  data: 0.0149  max mem: 593
Epoch: [3]  [ 200/1510]  eta: 0:01:23  lr: 0.000001  loss: 0.6054 (0.5932)  labels_encoder: 0.6054 (0.5932)  labels_encoder_unscaled: 0.6054 (0.5932)  time: 0.0518  data: 0.0231  max mem: 593
Epoch: [3]  [ 250/1510]  eta: 0:01:17  lr: 0.000001  loss: 0.5677 (0.5930)  labels_encoder: 0.5677 (0.5930)  labels_encoder_unscaled: 0.5677 (0.5930)  time: 0.0565  data: 0.0174  max mem: 593
Epoch: [3]  [ 300/1510]  eta: 0:01:12  lr: 0.000001  loss: 0.5071 (0.5881)  labels_encoder: 0.5071 (0.5881)  labels_encoder_unscaled: 0.5071 (0.5881)  time: 0.0511  data: 0.0225  max mem: 593
Epoch: [3]  [ 350/1510]  eta: 0:01:08  lr: 0.000001  loss: 0.6109 (0.5890)  labels_encoder: 0.6109 (0.5890)  labels_encoder_unscaled: 0.6109 (0.5890)  time: 0.0521  data: 0.0222  max mem: 593
Epoch: [3]  [ 400/1510]  eta: 0:01:04  lr: 0.000001  loss: 0.5883 (0.5853)  labels_encoder: 0.5883 (0.5853)  labels_encoder_unscaled: 0.5883 (0.5853)  time: 0.0498  data: 0.0209  max mem: 593
Epoch: [3]  [ 450/1510]  eta: 0:01:00  lr: 0.000001  loss: 0.5545 (0.5849)  labels_encoder: 0.5545 (0.5849)  labels_encoder_unscaled: 0.5545 (0.5849)  time: 0.0489  data: 0.0119  max mem: 593
Epoch: [3]  [ 500/1510]  eta: 0:00:56  lr: 0.000001  loss: 0.5919 (0.5864)  labels_encoder: 0.5919 (0.5864)  labels_encoder_unscaled: 0.5919 (0.5864)  time: 0.0533  data: 0.0258  max mem: 593
Epoch: [3]  [ 550/1510]  eta: 0:00:53  lr: 0.000001  loss: 0.5578 (0.5855)  labels_encoder: 0.5578 (0.5855)  labels_encoder_unscaled: 0.5578 (0.5855)  time: 0.0507  data: 0.0223  max mem: 593
Epoch: [3]  [ 600/1510]  eta: 0:00:50  lr: 0.000001  loss: 0.5500 (0.5851)  labels_encoder: 0.5500 (0.5851)  labels_encoder_unscaled: 0.5500 (0.5851)  time: 0.0526  data: 0.0131  max mem: 593
Epoch: [3]  [ 650/1510]  eta: 0:00:47  lr: 0.000001  loss: 0.5535 (0.5853)  labels_encoder: 0.5535 (0.5853)  labels_encoder_unscaled: 0.5535 (0.5853)  time: 0.0510  data: 0.0224  max mem: 593
Epoch: [3]  [ 700/1510]  eta: 0:00:44  lr: 0.000001  loss: 0.5742 (0.5855)  labels_encoder: 0.5742 (0.5855)  labels_encoder_unscaled: 0.5742 (0.5855)  time: 0.0501  data: 0.0238  max mem: 593
Epoch: [3]  [ 750/1510]  eta: 0:00:41  lr: 0.000001  loss: 0.6138 (0.5865)  labels_encoder: 0.6138 (0.5865)  labels_encoder_unscaled: 0.6138 (0.5865)  time: 0.0481  data: 0.0173  max mem: 593
Epoch: [3]  [ 800/1510]  eta: 0:00:38  lr: 0.000001  loss: 0.5743 (0.5850)  labels_encoder: 0.5743 (0.5850)  labels_encoder_unscaled: 0.5743 (0.5850)  time: 0.0503  data: 0.0177  max mem: 593
Epoch: [3]  [ 850/1510]  eta: 0:00:35  lr: 0.000001  loss: 0.5824 (0.5848)  labels_encoder: 0.5824 (0.5848)  labels_encoder_unscaled: 0.5824 (0.5848)  time: 0.0505  data: 0.0228  max mem: 593
Epoch: [3]  [ 900/1510]  eta: 0:00:33  lr: 0.000001  loss: 0.5851 (0.5862)  labels_encoder: 0.5851 (0.5862)  labels_encoder_unscaled: 0.5851 (0.5862)  time: 0.0502  data: 0.0216  max mem: 593
Epoch: [3]  [ 950/1510]  eta: 0:00:30  lr: 0.000001  loss: 0.6184 (0.5860)  labels_encoder: 0.6184 (0.5860)  labels_encoder_unscaled: 0.6184 (0.5860)  time: 0.0508  data: 0.0228  max mem: 593
Epoch: [3]  [1000/1510]  eta: 0:00:27  lr: 0.000001  loss: 0.5858 (0.5858)  labels_encoder: 0.5858 (0.5858)  labels_encoder_unscaled: 0.5858 (0.5858)  time: 0.0510  data: 0.0227  max mem: 593
Epoch: [3]  [1050/1510]  eta: 0:00:24  lr: 0.000001  loss: 0.5558 (0.5847)  labels_encoder: 0.5558 (0.5847)  labels_encoder_unscaled: 0.5558 (0.5847)  time: 0.0510  data: 0.0226  max mem: 593
Epoch: [3]  [1100/1510]  eta: 0:00:21  lr: 0.000001  loss: 0.5895 (0.5845)  labels_encoder: 0.5895 (0.5845)  labels_encoder_unscaled: 0.5895 (0.5845)  time: 0.0505  data: 0.0224  max mem: 593
Epoch: [3]  [1150/1510]  eta: 0:00:19  lr: 0.000001  loss: 0.5624 (0.5842)  labels_encoder: 0.5624 (0.5842)  labels_encoder_unscaled: 0.5624 (0.5842)  time: 0.0512  data: 0.0229  max mem: 593
Epoch: [3]  [1200/1510]  eta: 0:00:16  lr: 0.000001  loss: 0.5422 (0.5844)  labels_encoder: 0.5422 (0.5844)  labels_encoder_unscaled: 0.5422 (0.5844)  time: 0.0507  data: 0.0213  max mem: 593
Epoch: [3]  [1250/1510]  eta: 0:00:13  lr: 0.000001  loss: 0.5693 (0.5844)  labels_encoder: 0.5693 (0.5844)  labels_encoder_unscaled: 0.5693 (0.5844)  time: 0.0498  data: 0.0222  max mem: 593
Epoch: [3]  [1300/1510]  eta: 0:00:11  lr: 0.000001  loss: 0.5578 (0.5853)  labels_encoder: 0.5578 (0.5853)  labels_encoder_unscaled: 0.5578 (0.5853)  time: 0.0498  data: 0.0225  max mem: 593
Epoch: [3]  [1350/1510]  eta: 0:00:08  lr: 0.000001  loss: 0.6027 (0.5852)  labels_encoder: 0.6027 (0.5852)  labels_encoder_unscaled: 0.6027 (0.5852)  time: 0.0497  data: 0.0210  max mem: 593
Epoch: [3]  [1400/1510]  eta: 0:00:05  lr: 0.000001  loss: 0.6269 (0.5856)  labels_encoder: 0.6269 (0.5856)  labels_encoder_unscaled: 0.6269 (0.5856)  time: 0.0500  data: 0.0190  max mem: 593
Epoch: [3]  [1450/1510]  eta: 0:00:03  lr: 0.000001  loss: 0.5438 (0.5855)  labels_encoder: 0.5438 (0.5855)  labels_encoder_unscaled: 0.5438 (0.5855)  time: 0.0502  data: 0.0215  max mem: 593
Epoch: [3]  [1500/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5202 (0.5844)  labels_encoder: 0.5202 (0.5844)  labels_encoder_unscaled: 0.5202 (0.5844)  time: 0.0495  data: 0.0223  max mem: 593
Epoch: [3]  [1509/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5074 (0.5839)  labels_encoder: 0.5074 (0.5839)  labels_encoder_unscaled: 0.5074 (0.5839)  time: 0.0483  data: 0.0206  max mem: 593
Epoch: [3] Total time: 0:01:20 (0.0530 s / it)
Averaged stats: lr: 0.000001  loss: 0.5074 (0.5839)  labels_encoder: 0.5074 (0.5839)  labels_encoder_unscaled: 0.5074 (0.5839)
Test:  [  0/559]  eta: 0:15:05  loss: 0.6179 (0.6179)  labels_encoder: 0.6179 (0.6179)  labels_encoder_unscaled: 0.6179 (0.6179)  time: 1.6207  data: 1.6038  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 0.7622 (0.8664)  labels_encoder: 0.7622 (0.8664)  labels_encoder_unscaled: 0.7622 (0.8664)  time: 0.0486  data: 0.0302  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.4913 (0.8276)  labels_encoder: 0.4913 (0.8276)  labels_encoder_unscaled: 0.4913 (0.8276)  time: 0.0497  data: 0.0340  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.4300 (0.8544)  labels_encoder: 0.4300 (0.8544)  labels_encoder_unscaled: 0.4300 (0.8544)  time: 0.0543  data: 0.0365  max mem: 593
Test:  [200/559]  eta: 0:00:21  loss: 0.6408 (0.8014)  labels_encoder: 0.6408 (0.8014)  labels_encoder_unscaled: 0.6408 (0.8014)  time: 0.0476  data: 0.0314  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.6717 (0.9154)  labels_encoder: 0.6717 (0.9154)  labels_encoder_unscaled: 0.6717 (0.9154)  time: 0.0538  data: 0.0372  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1580 (0.9700)  labels_encoder: 1.1580 (0.9700)  labels_encoder_unscaled: 1.1580 (0.9700)  time: 0.0502  data: 0.0345  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7539 (0.9911)  labels_encoder: 0.7539 (0.9911)  labels_encoder_unscaled: 0.7539 (0.9911)  time: 0.0506  data: 0.0318  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3429 (0.9653)  labels_encoder: 0.3429 (0.9653)  labels_encoder_unscaled: 0.3429 (0.9653)  time: 0.0491  data: 0.0322  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4199 (0.9413)  labels_encoder: 0.4199 (0.9413)  labels_encoder_unscaled: 0.4199 (0.9413)  time: 0.0487  data: 0.0329  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5874 (0.9225)  labels_encoder: 0.5874 (0.9225)  labels_encoder_unscaled: 0.5874 (0.9225)  time: 0.0560  data: 0.0399  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6600 (0.8967)  labels_encoder: 0.6600 (0.8967)  labels_encoder_unscaled: 0.6600 (0.8967)  time: 0.0550  data: 0.0360  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3808 (0.8907)  labels_encoder: 0.3808 (0.8907)  labels_encoder_unscaled: 0.3808 (0.8907)  time: 0.0490  data: 0.0296  max mem: 593
Test: Total time: 0:00:31 (0.0556 s / it)
Averaged stats: loss: 0.3808 (0.8907)  labels_encoder: 0.3808 (0.8907)  labels_encoder_unscaled: 0.3808 (0.8907)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_anet_features.pickle] mAP: 0.1280, mcAP: 0.8788

BaseballPitch: 0.0420
BasketballDunk: 0.0709
Billiards: 0.0049
CleanAndJerk: 0.3980
CliffDiving: 0.4002
CricketBowling: 0.0788
CricketShot: 0.0909
Diving: 0.0109
FrisbeeCatch: 0.1092
GolfSwing: 0.0792
HammerThrow: 0.0831
HighJump: 0.0342
JavelinThrow: 0.0722
LongJump: 0.3744
PoleVault: 0.0923
Shotput: 0.1372
SoccerPenalty: 0.0487
TennisSwing: 0.2080
ThrowDiscus: 0.0592
VolleyballSpiking: 0.1649
Epoch: [4]  [   0/1510]  eta: 0:52:01  lr: 0.000000  loss: 0.4942 (0.4942)  labels_encoder: 0.4942 (0.4942)  labels_encoder_unscaled: 0.4942 (0.4942)  time: 2.0671  data: 2.0365  max mem: 593
Epoch: [4]  [  50/1510]  eta: 0:02:11  lr: 0.000000  loss: 0.5471 (0.5743)  labels_encoder: 0.5471 (0.5743)  labels_encoder_unscaled: 0.5471 (0.5743)  time: 0.0434  data: 0.0042  max mem: 593
Epoch: [4]  [ 100/1510]  eta: 0:01:41  lr: 0.000000  loss: 0.5021 (0.5744)  labels_encoder: 0.5021 (0.5744)  labels_encoder_unscaled: 0.5021 (0.5744)  time: 0.0524  data: 0.0221  max mem: 593
Epoch: [4]  [ 150/1510]  eta: 0:01:27  lr: 0.000000  loss: 0.6241 (0.5833)  labels_encoder: 0.6241 (0.5833)  labels_encoder_unscaled: 0.6241 (0.5833)  time: 0.0483  data: 0.0198  max mem: 593
Epoch: [4]  [ 200/1510]  eta: 0:01:19  lr: 0.000000  loss: 0.6039 (0.5810)  labels_encoder: 0.6039 (0.5810)  labels_encoder_unscaled: 0.6039 (0.5810)  time: 0.0489  data: 0.0169  max mem: 593
Epoch: [4]  [ 250/1510]  eta: 0:01:12  lr: 0.000000  loss: 0.5706 (0.5808)  labels_encoder: 0.5706 (0.5808)  labels_encoder_unscaled: 0.5706 (0.5808)  time: 0.0463  data: 0.0176  max mem: 593
Epoch: [4]  [ 300/1510]  eta: 0:01:09  lr: 0.000000  loss: 0.5340 (0.5807)  labels_encoder: 0.5340 (0.5807)  labels_encoder_unscaled: 0.5340 (0.5807)  time: 0.0524  data: 0.0171  max mem: 593
Epoch: [4]  [ 350/1510]  eta: 0:01:04  lr: 0.000000  loss: 0.5670 (0.5806)  labels_encoder: 0.5670 (0.5806)  labels_encoder_unscaled: 0.5670 (0.5806)  time: 0.0498  data: 0.0224  max mem: 593
Epoch: [4]  [ 400/1510]  eta: 0:01:01  lr: 0.000000  loss: 0.5222 (0.5793)  labels_encoder: 0.5222 (0.5793)  labels_encoder_unscaled: 0.5222 (0.5793)  time: 0.0512  data: 0.0216  max mem: 593
Epoch: [4]  [ 450/1510]  eta: 0:00:57  lr: 0.000000  loss: 0.5614 (0.5782)  labels_encoder: 0.5614 (0.5782)  labels_encoder_unscaled: 0.5614 (0.5782)  time: 0.0498  data: 0.0225  max mem: 593
Epoch: [4]  [ 500/1510]  eta: 0:00:54  lr: 0.000000  loss: 0.6087 (0.5791)  labels_encoder: 0.6087 (0.5791)  labels_encoder_unscaled: 0.6087 (0.5791)  time: 0.0499  data: 0.0228  max mem: 593
Epoch: [4]  [ 550/1510]  eta: 0:00:51  lr: 0.000000  loss: 0.5606 (0.5796)  labels_encoder: 0.5606 (0.5796)  labels_encoder_unscaled: 0.5606 (0.5796)  time: 0.0502  data: 0.0222  max mem: 593
Epoch: [4]  [ 600/1510]  eta: 0:00:48  lr: 0.000000  loss: 0.5350 (0.5783)  labels_encoder: 0.5350 (0.5783)  labels_encoder_unscaled: 0.5350 (0.5783)  time: 0.0478  data: 0.0137  max mem: 593
Epoch: [4]  [ 650/1510]  eta: 0:00:45  lr: 0.000000  loss: 0.5992 (0.5781)  labels_encoder: 0.5992 (0.5781)  labels_encoder_unscaled: 0.5992 (0.5781)  time: 0.0500  data: 0.0217  max mem: 593
Epoch: [4]  [ 700/1510]  eta: 0:00:42  lr: 0.000000  loss: 0.5654 (0.5783)  labels_encoder: 0.5654 (0.5783)  labels_encoder_unscaled: 0.5654 (0.5783)  time: 0.0489  data: 0.0177  max mem: 593
Epoch: [4]  [ 750/1510]  eta: 0:00:39  lr: 0.000000  loss: 0.5686 (0.5775)  labels_encoder: 0.5686 (0.5775)  labels_encoder_unscaled: 0.5686 (0.5775)  time: 0.0485  data: 0.0223  max mem: 593
Epoch: [4]  [ 800/1510]  eta: 0:00:37  lr: 0.000000  loss: 0.5685 (0.5785)  labels_encoder: 0.5685 (0.5785)  labels_encoder_unscaled: 0.5685 (0.5785)  time: 0.0498  data: 0.0233  max mem: 593
Epoch: [4]  [ 850/1510]  eta: 0:00:34  lr: 0.000000  loss: 0.5418 (0.5776)  labels_encoder: 0.5418 (0.5776)  labels_encoder_unscaled: 0.5418 (0.5776)  time: 0.0495  data: 0.0223  max mem: 593
Epoch: [4]  [ 900/1510]  eta: 0:00:31  lr: 0.000000  loss: 0.5198 (0.5767)  labels_encoder: 0.5198 (0.5767)  labels_encoder_unscaled: 0.5198 (0.5767)  time: 0.0525  data: 0.0211  max mem: 593
Epoch: [4]  [ 950/1510]  eta: 0:00:29  lr: 0.000000  loss: 0.5383 (0.5758)  labels_encoder: 0.5383 (0.5758)  labels_encoder_unscaled: 0.5383 (0.5758)  time: 0.0517  data: 0.0200  max mem: 593
Epoch: [4]  [1000/1510]  eta: 0:00:26  lr: 0.000000  loss: 0.5750 (0.5760)  labels_encoder: 0.5750 (0.5760)  labels_encoder_unscaled: 0.5750 (0.5760)  time: 0.0490  data: 0.0213  max mem: 593
Epoch: [4]  [1050/1510]  eta: 0:00:23  lr: 0.000000  loss: 0.5536 (0.5760)  labels_encoder: 0.5536 (0.5760)  labels_encoder_unscaled: 0.5536 (0.5760)  time: 0.0520  data: 0.0226  max mem: 593
Epoch: [4]  [1100/1510]  eta: 0:00:21  lr: 0.000000  loss: 0.5685 (0.5756)  labels_encoder: 0.5685 (0.5756)  labels_encoder_unscaled: 0.5685 (0.5756)  time: 0.0490  data: 0.0217  max mem: 593
Epoch: [4]  [1150/1510]  eta: 0:00:18  lr: 0.000000  loss: 0.5802 (0.5764)  labels_encoder: 0.5802 (0.5764)  labels_encoder_unscaled: 0.5802 (0.5764)  time: 0.0484  data: 0.0201  max mem: 593
Epoch: [4]  [1200/1510]  eta: 0:00:16  lr: 0.000000  loss: 0.5480 (0.5763)  labels_encoder: 0.5480 (0.5763)  labels_encoder_unscaled: 0.5480 (0.5763)  time: 0.0506  data: 0.0225  max mem: 593
Epoch: [4]  [1250/1510]  eta: 0:00:13  lr: 0.000000  loss: 0.5493 (0.5764)  labels_encoder: 0.5493 (0.5764)  labels_encoder_unscaled: 0.5493 (0.5764)  time: 0.0493  data: 0.0150  max mem: 593
Epoch: [4]  [1300/1510]  eta: 0:00:10  lr: 0.000000  loss: 0.5481 (0.5766)  labels_encoder: 0.5481 (0.5766)  labels_encoder_unscaled: 0.5481 (0.5766)  time: 0.0488  data: 0.0213  max mem: 593
Epoch: [4]  [1350/1510]  eta: 0:00:08  lr: 0.000000  loss: 0.5412 (0.5769)  labels_encoder: 0.5412 (0.5769)  labels_encoder_unscaled: 0.5412 (0.5769)  time: 0.0488  data: 0.0214  max mem: 593
Epoch: [4]  [1400/1510]  eta: 0:00:05  lr: 0.000000  loss: 0.5842 (0.5768)  labels_encoder: 0.5842 (0.5768)  labels_encoder_unscaled: 0.5842 (0.5768)  time: 0.0554  data: 0.0286  max mem: 593
Epoch: [4]  [1450/1510]  eta: 0:00:03  lr: 0.000000  loss: 0.5382 (0.5758)  labels_encoder: 0.5382 (0.5758)  labels_encoder_unscaled: 0.5382 (0.5758)  time: 0.0490  data: 0.0227  max mem: 593
Epoch: [4]  [1500/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5753 (0.5760)  labels_encoder: 0.5753 (0.5760)  labels_encoder_unscaled: 0.5753 (0.5760)  time: 0.0476  data: 0.0210  max mem: 593
Epoch: [4]  [1509/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.5453 (0.5760)  labels_encoder: 0.5453 (0.5760)  labels_encoder_unscaled: 0.5453 (0.5760)  time: 0.0468  data: 0.0199  max mem: 593
Epoch: [4] Total time: 0:01:17 (0.0514 s / it)
Averaged stats: lr: 0.000000  loss: 0.5453 (0.5760)  labels_encoder: 0.5453 (0.5760)  labels_encoder_unscaled: 0.5453 (0.5760)
Test:  [  0/559]  eta: 0:15:01  loss: 0.5693 (0.5693)  labels_encoder: 0.5693 (0.5693)  labels_encoder_unscaled: 0.5693 (0.5693)  time: 1.6124  data: 1.5936  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.7330 (0.8485)  labels_encoder: 0.7330 (0.8485)  labels_encoder_unscaled: 0.7330 (0.8485)  time: 0.0327  data: 0.0113  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.5494 (0.8193)  labels_encoder: 0.5494 (0.8193)  labels_encoder_unscaled: 0.5494 (0.8193)  time: 0.0570  data: 0.0413  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.4783 (0.8456)  labels_encoder: 0.4783 (0.8456)  labels_encoder_unscaled: 0.4783 (0.8456)  time: 0.0533  data: 0.0374  max mem: 593
Test:  [200/559]  eta: 0:00:21  loss: 0.7463 (0.7985)  labels_encoder: 0.7463 (0.7985)  labels_encoder_unscaled: 0.7463 (0.7985)  time: 0.0492  data: 0.0334  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.6715 (0.9064)  labels_encoder: 0.6715 (0.9064)  labels_encoder_unscaled: 0.6715 (0.9064)  time: 0.0480  data: 0.0322  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1537 (0.9589)  labels_encoder: 1.1537 (0.9589)  labels_encoder_unscaled: 1.1537 (0.9589)  time: 0.0475  data: 0.0315  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7618 (0.9777)  labels_encoder: 0.7618 (0.9777)  labels_encoder_unscaled: 0.7618 (0.9777)  time: 0.0534  data: 0.0377  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3507 (0.9536)  labels_encoder: 0.3507 (0.9536)  labels_encoder_unscaled: 0.3507 (0.9536)  time: 0.0497  data: 0.0331  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3950 (0.9305)  labels_encoder: 0.3950 (0.9305)  labels_encoder_unscaled: 0.3950 (0.9305)  time: 0.0482  data: 0.0324  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5810 (0.9137)  labels_encoder: 0.5810 (0.9137)  labels_encoder_unscaled: 0.5810 (0.9137)  time: 0.0475  data: 0.0317  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6360 (0.8893)  labels_encoder: 0.6360 (0.8893)  labels_encoder_unscaled: 0.6360 (0.8893)  time: 0.0488  data: 0.0323  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4289 (0.8834)  labels_encoder: 0.4289 (0.8834)  labels_encoder_unscaled: 0.4289 (0.8834)  time: 0.0488  data: 0.0326  max mem: 593
Test: Total time: 0:00:29 (0.0531 s / it)
Averaged stats: loss: 0.4289 (0.8834)  labels_encoder: 0.4289 (0.8834)  labels_encoder_unscaled: 0.4289 (0.8834)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_anet_features.pickle] mAP: 0.1290, mcAP: 0.8804

BaseballPitch: 0.0596
BasketballDunk: 0.0681
Billiards: 0.0048
CleanAndJerk: 0.3988
CliffDiving: 0.4314
CricketBowling: 0.0942
CricketShot: 0.0873
Diving: 0.0134
FrisbeeCatch: 0.1164
GolfSwing: 0.0875
HammerThrow: 0.0676
HighJump: 0.0413
JavelinThrow: 0.0724
LongJump: 0.3466
PoleVault: 0.0922
Shotput: 0.1321
SoccerPenalty: 0.0493
TennisSwing: 0.2028
ThrowDiscus: 0.0560
VolleyballSpiking: 0.1584
Training time 0:07:23
