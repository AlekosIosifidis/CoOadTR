Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_anet_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:1
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_anet_features.pickle
Loaded tvseries_anet_features.pickle
Start training
Epoch: [1]  [   0/1511]  eta: 0:46:30  lr: 0.000100  loss: 3.7501 (3.7501)  labels_encoder: 3.7501 (3.7501)  labels_encoder_unscaled: 3.7501 (3.7501)  time: 1.8466  data: 1.6964  max mem: 483
Epoch: [1]  [  50/1511]  eta: 0:02:11  lr: 0.000100  loss: 1.0320 (1.1610)  labels_encoder: 1.0320 (1.1610)  labels_encoder_unscaled: 1.0320 (1.1610)  time: 0.0546  data: 0.0195  max mem: 593
Epoch: [1]  [ 100/1511]  eta: 0:01:40  lr: 0.000100  loss: 0.9797 (1.0776)  labels_encoder: 0.9797 (1.0776)  labels_encoder_unscaled: 0.9797 (1.0776)  time: 0.0506  data: 0.0234  max mem: 593
Epoch: [1]  [ 150/1511]  eta: 0:01:27  lr: 0.000100  loss: 0.8536 (1.0280)  labels_encoder: 0.8536 (1.0280)  labels_encoder_unscaled: 0.8536 (1.0280)  time: 0.0528  data: 0.0216  max mem: 593
Epoch: [1]  [ 200/1511]  eta: 0:01:18  lr: 0.000100  loss: 0.8647 (0.9987)  labels_encoder: 0.8647 (0.9987)  labels_encoder_unscaled: 0.8647 (0.9987)  time: 0.0472  data: 0.0162  max mem: 593
Epoch: [1]  [ 250/1511]  eta: 0:01:12  lr: 0.000100  loss: 0.9059 (0.9797)  labels_encoder: 0.9059 (0.9797)  labels_encoder_unscaled: 0.9059 (0.9797)  time: 0.0500  data: 0.0168  max mem: 593
Epoch: [1]  [ 300/1511]  eta: 0:01:08  lr: 0.000100  loss: 0.8136 (0.9626)  labels_encoder: 0.8136 (0.9626)  labels_encoder_unscaled: 0.8136 (0.9626)  time: 0.0531  data: 0.0190  max mem: 593
Epoch: [1]  [ 350/1511]  eta: 0:01:04  lr: 0.000100  loss: 0.8588 (0.9497)  labels_encoder: 0.8588 (0.9497)  labels_encoder_unscaled: 0.8588 (0.9497)  time: 0.0503  data: 0.0180  max mem: 593
Epoch: [1]  [ 400/1511]  eta: 0:01:00  lr: 0.000100  loss: 0.7733 (0.9383)  labels_encoder: 0.7733 (0.9383)  labels_encoder_unscaled: 0.7733 (0.9383)  time: 0.0501  data: 0.0155  max mem: 593
Epoch: [1]  [ 450/1511]  eta: 0:00:57  lr: 0.000100  loss: 0.7953 (0.9251)  labels_encoder: 0.7953 (0.9251)  labels_encoder_unscaled: 0.7953 (0.9251)  time: 0.0528  data: 0.0174  max mem: 593
Epoch: [1]  [ 500/1511]  eta: 0:00:54  lr: 0.000100  loss: 0.8108 (0.9137)  labels_encoder: 0.8108 (0.9137)  labels_encoder_unscaled: 0.8108 (0.9137)  time: 0.0524  data: 0.0217  max mem: 593
Epoch: [1]  [ 550/1511]  eta: 0:00:51  lr: 0.000100  loss: 0.7799 (0.9026)  labels_encoder: 0.7799 (0.9026)  labels_encoder_unscaled: 0.7799 (0.9026)  time: 0.0541  data: 0.0258  max mem: 593
Epoch: [1]  [ 600/1511]  eta: 0:00:49  lr: 0.000100  loss: 0.7858 (0.8925)  labels_encoder: 0.7858 (0.8925)  labels_encoder_unscaled: 0.7858 (0.8925)  time: 0.0647  data: 0.0363  max mem: 593
Epoch: [1]  [ 650/1511]  eta: 0:00:46  lr: 0.000100  loss: 0.7808 (0.8844)  labels_encoder: 0.7808 (0.8844)  labels_encoder_unscaled: 0.7808 (0.8844)  time: 0.0481  data: 0.0194  max mem: 593
Epoch: [1]  [ 700/1511]  eta: 0:00:43  lr: 0.000100  loss: 0.7789 (0.8764)  labels_encoder: 0.7789 (0.8764)  labels_encoder_unscaled: 0.7789 (0.8764)  time: 0.0537  data: 0.0244  max mem: 593
Epoch: [1]  [ 750/1511]  eta: 0:00:40  lr: 0.000100  loss: 0.7597 (0.8709)  labels_encoder: 0.7597 (0.8709)  labels_encoder_unscaled: 0.7597 (0.8709)  time: 0.0528  data: 0.0205  max mem: 593
Epoch: [1]  [ 800/1511]  eta: 0:00:37  lr: 0.000100  loss: 0.7159 (0.8636)  labels_encoder: 0.7159 (0.8636)  labels_encoder_unscaled: 0.7159 (0.8636)  time: 0.0509  data: 0.0210  max mem: 593
Epoch: [1]  [ 850/1511]  eta: 0:00:35  lr: 0.000100  loss: 0.6816 (0.8557)  labels_encoder: 0.6816 (0.8557)  labels_encoder_unscaled: 0.6816 (0.8557)  time: 0.0485  data: 0.0186  max mem: 593
Epoch: [1]  [ 900/1511]  eta: 0:00:32  lr: 0.000100  loss: 0.6950 (0.8501)  labels_encoder: 0.6950 (0.8501)  labels_encoder_unscaled: 0.6950 (0.8501)  time: 0.0478  data: 0.0186  max mem: 593
Epoch: [1]  [ 950/1511]  eta: 0:00:29  lr: 0.000100  loss: 0.7408 (0.8449)  labels_encoder: 0.7408 (0.8449)  labels_encoder_unscaled: 0.7408 (0.8449)  time: 0.0487  data: 0.0165  max mem: 593
Epoch: [1]  [1000/1511]  eta: 0:00:26  lr: 0.000100  loss: 0.6845 (0.8383)  labels_encoder: 0.6845 (0.8383)  labels_encoder_unscaled: 0.6845 (0.8383)  time: 0.0517  data: 0.0195  max mem: 593
Epoch: [1]  [1050/1511]  eta: 0:00:24  lr: 0.000100  loss: 0.6303 (0.8322)  labels_encoder: 0.6303 (0.8322)  labels_encoder_unscaled: 0.6303 (0.8322)  time: 0.0463  data: 0.0125  max mem: 593
Epoch: [1]  [1100/1511]  eta: 0:00:21  lr: 0.000100  loss: 0.7471 (0.8287)  labels_encoder: 0.7471 (0.8287)  labels_encoder_unscaled: 0.7471 (0.8287)  time: 0.0481  data: 0.0177  max mem: 593
Epoch: [1]  [1150/1511]  eta: 0:00:18  lr: 0.000100  loss: 0.7401 (0.8242)  labels_encoder: 0.7401 (0.8242)  labels_encoder_unscaled: 0.7401 (0.8242)  time: 0.0486  data: 0.0207  max mem: 593
Epoch: [1]  [1200/1511]  eta: 0:00:16  lr: 0.000100  loss: 0.7469 (0.8204)  labels_encoder: 0.7469 (0.8204)  labels_encoder_unscaled: 0.7469 (0.8204)  time: 0.0487  data: 0.0202  max mem: 593
Epoch: [1]  [1250/1511]  eta: 0:00:13  lr: 0.000100  loss: 0.6609 (0.8164)  labels_encoder: 0.6609 (0.8164)  labels_encoder_unscaled: 0.6609 (0.8164)  time: 0.0501  data: 0.0197  max mem: 593
Epoch: [1]  [1300/1511]  eta: 0:00:10  lr: 0.000100  loss: 0.6702 (0.8114)  labels_encoder: 0.6702 (0.8114)  labels_encoder_unscaled: 0.6702 (0.8114)  time: 0.0480  data: 0.0143  max mem: 593
Epoch: [1]  [1350/1511]  eta: 0:00:08  lr: 0.000100  loss: 0.6805 (0.8084)  labels_encoder: 0.6805 (0.8084)  labels_encoder_unscaled: 0.6805 (0.8084)  time: 0.0476  data: 0.0181  max mem: 593
Epoch: [1]  [1400/1511]  eta: 0:00:05  lr: 0.000100  loss: 0.6445 (0.8034)  labels_encoder: 0.6445 (0.8034)  labels_encoder_unscaled: 0.6445 (0.8034)  time: 0.0476  data: 0.0194  max mem: 593
Epoch: [1]  [1450/1511]  eta: 0:00:03  lr: 0.000100  loss: 0.6596 (0.7989)  labels_encoder: 0.6596 (0.7989)  labels_encoder_unscaled: 0.6596 (0.7989)  time: 0.0486  data: 0.0172  max mem: 593
Epoch: [1]  [1500/1511]  eta: 0:00:00  lr: 0.000100  loss: 0.6963 (0.7951)  labels_encoder: 0.6963 (0.7951)  labels_encoder_unscaled: 0.6963 (0.7951)  time: 0.0438  data: 0.0014  max mem: 593
Epoch: [1]  [1510/1511]  eta: 0:00:00  lr: 0.000100  loss: 0.6830 (0.7946)  labels_encoder: 0.6830 (0.7946)  labels_encoder_unscaled: 0.6830 (0.7946)  time: 0.0452  data: 0.0102  max mem: 593
Epoch: [1] Total time: 0:01:17 (0.0514 s / it)
Averaged stats: lr: 0.000100  loss: 0.6830 (0.7946)  labels_encoder: 0.6830 (0.7946)  labels_encoder_unscaled: 0.6830 (0.7946)
Test:  [  0/559]  eta: 0:15:16  loss: 0.6673 (0.6673)  labels_encoder: 0.6673 (0.6673)  labels_encoder_unscaled: 0.6673 (0.6673)  time: 1.6396  data: 1.6209  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 1.0620 (0.9802)  labels_encoder: 1.0620 (0.9802)  labels_encoder_unscaled: 1.0620 (0.9802)  time: 0.0412  data: 0.0207  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.5051 (0.9166)  labels_encoder: 0.5051 (0.9166)  labels_encoder_unscaled: 0.5051 (0.9166)  time: 0.0464  data: 0.0304  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.6614 (0.9311)  labels_encoder: 0.6614 (0.9311)  labels_encoder_unscaled: 0.6614 (0.9311)  time: 0.0475  data: 0.0297  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.5946 (0.8619)  labels_encoder: 0.5946 (0.8619)  labels_encoder_unscaled: 0.5946 (0.8619)  time: 0.0488  data: 0.0338  max mem: 593
Test:  [250/559]  eta: 0:00:16  loss: 0.8234 (0.9860)  labels_encoder: 0.8234 (0.9860)  labels_encoder_unscaled: 0.8234 (0.9860)  time: 0.0471  data: 0.0315  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1457 (1.0407)  labels_encoder: 1.1457 (1.0407)  labels_encoder_unscaled: 1.1457 (1.0407)  time: 0.0484  data: 0.0322  max mem: 593
Test:  [350/559]  eta: 0:00:10  loss: 0.9078 (1.0651)  labels_encoder: 0.9078 (1.0651)  labels_encoder_unscaled: 0.9078 (1.0651)  time: 0.0462  data: 0.0303  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.4914 (1.0440)  labels_encoder: 0.4914 (1.0440)  labels_encoder_unscaled: 0.4914 (1.0440)  time: 0.0496  data: 0.0318  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.5000 (1.0177)  labels_encoder: 0.5000 (1.0177)  labels_encoder_unscaled: 0.5000 (1.0177)  time: 0.0468  data: 0.0307  max mem: 593
Test:  [500/559]  eta: 0:00:02  loss: 0.5688 (0.9926)  labels_encoder: 0.5688 (0.9926)  labels_encoder_unscaled: 0.5688 (0.9926)  time: 0.0470  data: 0.0310  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7077 (0.9660)  labels_encoder: 0.7077 (0.9660)  labels_encoder_unscaled: 0.7077 (0.9660)  time: 0.0469  data: 0.0302  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3887 (0.9591)  labels_encoder: 0.3887 (0.9591)  labels_encoder_unscaled: 0.3887 (0.9591)  time: 0.0450  data: 0.0287  max mem: 593
Test: Total time: 0:00:28 (0.0508 s / it)
Averaged stats: loss: 0.3887 (0.9591)  labels_encoder: 0.3887 (0.9591)  labels_encoder_unscaled: 0.3887 (0.9591)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_anet_features.pickle] mAP: 0.1167, mcAP: 0.8536

BaseballPitch: 0.0238
BasketballDunk: 0.1063
Billiards: 0.0042
CleanAndJerk: 0.3717
CliffDiving: 0.4918
CricketBowling: 0.0759
CricketShot: 0.0889
Diving: 0.0089
FrisbeeCatch: 0.0769
GolfSwing: 0.0530
HammerThrow: 0.0745
HighJump: 0.0284
JavelinThrow: 0.0662
LongJump: 0.3283
PoleVault: 0.0902
Shotput: 0.1142
SoccerPenalty: 0.0470
TennisSwing: 0.1711
ThrowDiscus: 0.0160
VolleyballSpiking: 0.0962
Epoch: [2]  [   0/1511]  eta: 0:39:29  lr: 0.000010  loss: 0.6900 (0.6900)  labels_encoder: 0.6900 (0.6900)  labels_encoder_unscaled: 0.6900 (0.6900)  time: 1.5680  data: 1.5357  max mem: 593
Epoch: [2]  [  50/1511]  eta: 0:01:58  lr: 0.000010  loss: 0.6494 (0.6636)  labels_encoder: 0.6494 (0.6636)  labels_encoder_unscaled: 0.6494 (0.6636)  time: 0.0427  data: 0.0017  max mem: 593
Epoch: [2]  [ 100/1511]  eta: 0:01:29  lr: 0.000010  loss: 0.6423 (0.6615)  labels_encoder: 0.6423 (0.6615)  labels_encoder_unscaled: 0.6423 (0.6615)  time: 0.0468  data: 0.0183  max mem: 593
Epoch: [2]  [ 150/1511]  eta: 0:01:19  lr: 0.000010  loss: 0.6640 (0.6720)  labels_encoder: 0.6640 (0.6720)  labels_encoder_unscaled: 0.6640 (0.6720)  time: 0.0469  data: 0.0176  max mem: 593
Epoch: [2]  [ 200/1511]  eta: 0:01:12  lr: 0.000010  loss: 0.6251 (0.6645)  labels_encoder: 0.6251 (0.6645)  labels_encoder_unscaled: 0.6251 (0.6645)  time: 0.0467  data: 0.0180  max mem: 593
Epoch: [2]  [ 250/1511]  eta: 0:01:08  lr: 0.000010  loss: 0.6883 (0.6669)  labels_encoder: 0.6883 (0.6669)  labels_encoder_unscaled: 0.6883 (0.6669)  time: 0.0474  data: 0.0188  max mem: 593
Epoch: [2]  [ 300/1511]  eta: 0:01:04  lr: 0.000010  loss: 0.6458 (0.6607)  labels_encoder: 0.6458 (0.6607)  labels_encoder_unscaled: 0.6458 (0.6607)  time: 0.0490  data: 0.0193  max mem: 593
Epoch: [2]  [ 350/1511]  eta: 0:01:00  lr: 0.000010  loss: 0.7106 (0.6579)  labels_encoder: 0.7106 (0.6579)  labels_encoder_unscaled: 0.7106 (0.6579)  time: 0.0476  data: 0.0174  max mem: 593
Epoch: [2]  [ 400/1511]  eta: 0:00:58  lr: 0.000010  loss: 0.5966 (0.6536)  labels_encoder: 0.5966 (0.6536)  labels_encoder_unscaled: 0.5966 (0.6536)  time: 0.0483  data: 0.0182  max mem: 593
Epoch: [2]  [ 450/1511]  eta: 0:00:54  lr: 0.000010  loss: 0.6156 (0.6491)  labels_encoder: 0.6156 (0.6491)  labels_encoder_unscaled: 0.6156 (0.6491)  time: 0.0492  data: 0.0206  max mem: 593
Epoch: [2]  [ 500/1511]  eta: 0:00:52  lr: 0.000010  loss: 0.5650 (0.6470)  labels_encoder: 0.5650 (0.6470)  labels_encoder_unscaled: 0.5650 (0.6470)  time: 0.0501  data: 0.0224  max mem: 593
Epoch: [2]  [ 550/1511]  eta: 0:00:49  lr: 0.000010  loss: 0.6012 (0.6429)  labels_encoder: 0.6012 (0.6429)  labels_encoder_unscaled: 0.6012 (0.6429)  time: 0.0477  data: 0.0202  max mem: 593
Epoch: [2]  [ 600/1511]  eta: 0:00:46  lr: 0.000010  loss: 0.5974 (0.6417)  labels_encoder: 0.5974 (0.6417)  labels_encoder_unscaled: 0.5974 (0.6417)  time: 0.0489  data: 0.0212  max mem: 593
Epoch: [2]  [ 650/1511]  eta: 0:00:43  lr: 0.000010  loss: 0.6138 (0.6404)  labels_encoder: 0.6138 (0.6404)  labels_encoder_unscaled: 0.6138 (0.6404)  time: 0.0478  data: 0.0203  max mem: 593
Epoch: [2]  [ 700/1511]  eta: 0:00:41  lr: 0.000010  loss: 0.6299 (0.6400)  labels_encoder: 0.6299 (0.6400)  labels_encoder_unscaled: 0.6299 (0.6400)  time: 0.0517  data: 0.0245  max mem: 593
Epoch: [2]  [ 750/1511]  eta: 0:00:38  lr: 0.000010  loss: 0.6355 (0.6379)  labels_encoder: 0.6355 (0.6379)  labels_encoder_unscaled: 0.6355 (0.6379)  time: 0.0535  data: 0.0237  max mem: 593
Epoch: [2]  [ 800/1511]  eta: 0:00:35  lr: 0.000010  loss: 0.6903 (0.6376)  labels_encoder: 0.6903 (0.6376)  labels_encoder_unscaled: 0.6903 (0.6376)  time: 0.0497  data: 0.0214  max mem: 593
Epoch: [2]  [ 850/1511]  eta: 0:00:33  lr: 0.000010  loss: 0.6254 (0.6367)  labels_encoder: 0.6254 (0.6367)  labels_encoder_unscaled: 0.6254 (0.6367)  time: 0.0494  data: 0.0136  max mem: 593
Epoch: [2]  [ 900/1511]  eta: 0:00:30  lr: 0.000010  loss: 0.6084 (0.6344)  labels_encoder: 0.6084 (0.6344)  labels_encoder_unscaled: 0.6084 (0.6344)  time: 0.0481  data: 0.0199  max mem: 593
Epoch: [2]  [ 950/1511]  eta: 0:00:28  lr: 0.000010  loss: 0.5680 (0.6329)  labels_encoder: 0.5680 (0.6329)  labels_encoder_unscaled: 0.5680 (0.6329)  time: 0.0494  data: 0.0200  max mem: 593
Epoch: [2]  [1000/1511]  eta: 0:00:25  lr: 0.000010  loss: 0.6047 (0.6315)  labels_encoder: 0.6047 (0.6315)  labels_encoder_unscaled: 0.6047 (0.6315)  time: 0.0524  data: 0.0255  max mem: 593
Epoch: [2]  [1050/1511]  eta: 0:00:23  lr: 0.000010  loss: 0.5534 (0.6303)  labels_encoder: 0.5534 (0.6303)  labels_encoder_unscaled: 0.5534 (0.6303)  time: 0.0485  data: 0.0231  max mem: 593
Epoch: [2]  [1100/1511]  eta: 0:00:20  lr: 0.000010  loss: 0.5967 (0.6304)  labels_encoder: 0.5967 (0.6304)  labels_encoder_unscaled: 0.5967 (0.6304)  time: 0.0536  data: 0.0239  max mem: 593
Epoch: [2]  [1150/1511]  eta: 0:00:18  lr: 0.000010  loss: 0.6055 (0.6294)  labels_encoder: 0.6055 (0.6294)  labels_encoder_unscaled: 0.6055 (0.6294)  time: 0.0508  data: 0.0240  max mem: 593
Epoch: [2]  [1200/1511]  eta: 0:00:15  lr: 0.000010  loss: 0.5881 (0.6286)  labels_encoder: 0.5881 (0.6286)  labels_encoder_unscaled: 0.5881 (0.6286)  time: 0.0480  data: 0.0218  max mem: 593
Epoch: [2]  [1250/1511]  eta: 0:00:13  lr: 0.000010  loss: 0.6333 (0.6278)  labels_encoder: 0.6333 (0.6278)  labels_encoder_unscaled: 0.6333 (0.6278)  time: 0.0490  data: 0.0228  max mem: 593
Epoch: [2]  [1300/1511]  eta: 0:00:10  lr: 0.000010  loss: 0.5700 (0.6269)  labels_encoder: 0.5700 (0.6269)  labels_encoder_unscaled: 0.5700 (0.6269)  time: 0.0475  data: 0.0189  max mem: 593
Epoch: [2]  [1350/1511]  eta: 0:00:08  lr: 0.000010  loss: 0.5400 (0.6254)  labels_encoder: 0.5400 (0.6254)  labels_encoder_unscaled: 0.5400 (0.6254)  time: 0.0483  data: 0.0191  max mem: 593
Epoch: [2]  [1400/1511]  eta: 0:00:05  lr: 0.000010  loss: 0.5152 (0.6247)  labels_encoder: 0.5152 (0.6247)  labels_encoder_unscaled: 0.5152 (0.6247)  time: 0.0544  data: 0.0207  max mem: 593
Epoch: [2]  [1450/1511]  eta: 0:00:03  lr: 0.000010  loss: 0.5588 (0.6237)  labels_encoder: 0.5588 (0.6237)  labels_encoder_unscaled: 0.5588 (0.6237)  time: 0.0482  data: 0.0207  max mem: 593
Epoch: [2]  [1500/1511]  eta: 0:00:00  lr: 0.000010  loss: 0.5820 (0.6226)  labels_encoder: 0.5820 (0.6226)  labels_encoder_unscaled: 0.5820 (0.6226)  time: 0.0475  data: 0.0201  max mem: 593
Epoch: [2]  [1510/1511]  eta: 0:00:00  lr: 0.000010  loss: 0.6136 (0.6227)  labels_encoder: 0.6136 (0.6227)  labels_encoder_unscaled: 0.6136 (0.6227)  time: 0.0448  data: 0.0176  max mem: 593
Epoch: [2] Total time: 0:01:15 (0.0499 s / it)
Averaged stats: lr: 0.000010  loss: 0.6136 (0.6227)  labels_encoder: 0.6136 (0.6227)  labels_encoder_unscaled: 0.6136 (0.6227)
Test:  [  0/559]  eta: 0:16:03  loss: 0.5804 (0.5804)  labels_encoder: 0.5804 (0.5804)  labels_encoder_unscaled: 0.5804 (0.5804)  time: 1.7243  data: 1.7062  max mem: 593
Test:  [ 50/559]  eta: 0:00:39  loss: 1.0409 (0.9207)  labels_encoder: 1.0409 (0.9207)  labels_encoder_unscaled: 1.0409 (0.9207)  time: 0.0443  data: 0.0286  max mem: 593
Test:  [100/559]  eta: 0:00:28  loss: 0.4435 (0.8528)  labels_encoder: 0.4435 (0.8528)  labels_encoder_unscaled: 0.4435 (0.8528)  time: 0.0468  data: 0.0301  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.4907 (0.8816)  labels_encoder: 0.4907 (0.8816)  labels_encoder_unscaled: 0.4907 (0.8816)  time: 0.0455  data: 0.0305  max mem: 593
Test:  [200/559]  eta: 0:00:19  loss: 0.8274 (0.8224)  labels_encoder: 0.8274 (0.8224)  labels_encoder_unscaled: 0.8274 (0.8224)  time: 0.0459  data: 0.0308  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7278 (0.9378)  labels_encoder: 0.7278 (0.9378)  labels_encoder_unscaled: 0.7278 (0.9378)  time: 0.0548  data: 0.0396  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.2045 (0.9969)  labels_encoder: 1.2045 (0.9969)  labels_encoder_unscaled: 1.2045 (0.9969)  time: 0.0538  data: 0.0381  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.6998 (1.0378)  labels_encoder: 0.6998 (1.0378)  labels_encoder_unscaled: 0.6998 (1.0378)  time: 0.0466  data: 0.0306  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3237 (1.0072)  labels_encoder: 0.3237 (1.0072)  labels_encoder_unscaled: 0.3237 (1.0072)  time: 0.0511  data: 0.0338  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3747 (0.9798)  labels_encoder: 0.3747 (0.9798)  labels_encoder_unscaled: 0.3747 (0.9798)  time: 0.0487  data: 0.0325  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5343 (0.9618)  labels_encoder: 0.5343 (0.9618)  labels_encoder_unscaled: 0.5343 (0.9618)  time: 0.0469  data: 0.0304  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.8224 (0.9343)  labels_encoder: 0.8224 (0.9343)  labels_encoder_unscaled: 0.8224 (0.9343)  time: 0.0467  data: 0.0309  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4275 (0.9272)  labels_encoder: 0.4275 (0.9272)  labels_encoder_unscaled: 0.4275 (0.9272)  time: 0.0456  data: 0.0302  max mem: 593
Test: Total time: 0:00:29 (0.0529 s / it)
Averaged stats: loss: 0.4275 (0.9272)  labels_encoder: 0.4275 (0.9272)  labels_encoder_unscaled: 0.4275 (0.9272)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_anet_features.pickle] mAP: 0.1249, mcAP: 0.8808

BaseballPitch: 0.0373
BasketballDunk: 0.0853
Billiards: 0.0065
CleanAndJerk: 0.3722
CliffDiving: 0.4643
CricketBowling: 0.0671
CricketShot: 0.1109
Diving: 0.0171
FrisbeeCatch: 0.1148
GolfSwing: 0.0727
HammerThrow: 0.0947
HighJump: 0.0560
JavelinThrow: 0.0500
LongJump: 0.3542
PoleVault: 0.0827
Shotput: 0.1227
SoccerPenalty: 0.0580
TennisSwing: 0.1291
ThrowDiscus: 0.0629
VolleyballSpiking: 0.1400
Epoch: [3]  [   0/1511]  eta: 0:42:38  lr: 0.000001  loss: 0.6563 (0.6563)  labels_encoder: 0.6563 (0.6563)  labels_encoder_unscaled: 0.6563 (0.6563)  time: 1.6932  data: 1.6645  max mem: 593
Epoch: [3]  [  50/1511]  eta: 0:01:57  lr: 0.000001  loss: 0.5563 (0.6182)  labels_encoder: 0.5563 (0.6182)  labels_encoder_unscaled: 0.5563 (0.6182)  time: 0.0450  data: 0.0123  max mem: 593
Epoch: [3]  [ 100/1511]  eta: 0:01:30  lr: 0.000001  loss: 0.5834 (0.6153)  labels_encoder: 0.5834 (0.6153)  labels_encoder_unscaled: 0.5834 (0.6153)  time: 0.0458  data: 0.0184  max mem: 593
Epoch: [3]  [ 150/1511]  eta: 0:01:20  lr: 0.000001  loss: 0.6060 (0.6157)  labels_encoder: 0.6060 (0.6157)  labels_encoder_unscaled: 0.6060 (0.6157)  time: 0.0472  data: 0.0188  max mem: 593
Epoch: [3]  [ 200/1511]  eta: 0:01:13  lr: 0.000001  loss: 0.6408 (0.6228)  labels_encoder: 0.6408 (0.6228)  labels_encoder_unscaled: 0.6408 (0.6228)  time: 0.0464  data: 0.0148  max mem: 593
Epoch: [3]  [ 250/1511]  eta: 0:01:09  lr: 0.000001  loss: 0.5712 (0.6213)  labels_encoder: 0.5712 (0.6213)  labels_encoder_unscaled: 0.5712 (0.6213)  time: 0.0518  data: 0.0234  max mem: 593
Epoch: [3]  [ 300/1511]  eta: 0:01:06  lr: 0.000001  loss: 0.5668 (0.6166)  labels_encoder: 0.5668 (0.6166)  labels_encoder_unscaled: 0.5668 (0.6166)  time: 0.0496  data: 0.0183  max mem: 593
Epoch: [3]  [ 350/1511]  eta: 0:01:03  lr: 0.000001  loss: 0.5481 (0.6121)  labels_encoder: 0.5481 (0.6121)  labels_encoder_unscaled: 0.5481 (0.6121)  time: 0.0521  data: 0.0237  max mem: 593
Epoch: [3]  [ 400/1511]  eta: 0:00:59  lr: 0.000001  loss: 0.6758 (0.6128)  labels_encoder: 0.6758 (0.6128)  labels_encoder_unscaled: 0.6758 (0.6128)  time: 0.0477  data: 0.0192  max mem: 593
Epoch: [3]  [ 450/1511]  eta: 0:00:56  lr: 0.000001  loss: 0.5519 (0.6106)  labels_encoder: 0.5519 (0.6106)  labels_encoder_unscaled: 0.5519 (0.6106)  time: 0.0499  data: 0.0202  max mem: 593
Epoch: [3]  [ 500/1511]  eta: 0:00:53  lr: 0.000001  loss: 0.5784 (0.6098)  labels_encoder: 0.5784 (0.6098)  labels_encoder_unscaled: 0.5784 (0.6098)  time: 0.0487  data: 0.0201  max mem: 593
Epoch: [3]  [ 550/1511]  eta: 0:00:50  lr: 0.000001  loss: 0.5935 (0.6119)  labels_encoder: 0.5935 (0.6119)  labels_encoder_unscaled: 0.5935 (0.6119)  time: 0.0506  data: 0.0223  max mem: 593
Epoch: [3]  [ 600/1511]  eta: 0:00:48  lr: 0.000001  loss: 0.5791 (0.6101)  labels_encoder: 0.5791 (0.6101)  labels_encoder_unscaled: 0.5791 (0.6101)  time: 0.0485  data: 0.0190  max mem: 593
Epoch: [3]  [ 650/1511]  eta: 0:00:45  lr: 0.000001  loss: 0.6018 (0.6087)  labels_encoder: 0.6018 (0.6087)  labels_encoder_unscaled: 0.6018 (0.6087)  time: 0.0513  data: 0.0226  max mem: 593
Epoch: [3]  [ 700/1511]  eta: 0:00:42  lr: 0.000001  loss: 0.5801 (0.6074)  labels_encoder: 0.5801 (0.6074)  labels_encoder_unscaled: 0.5801 (0.6074)  time: 0.0485  data: 0.0178  max mem: 593
Epoch: [3]  [ 750/1511]  eta: 0:00:39  lr: 0.000001  loss: 0.5925 (0.6056)  labels_encoder: 0.5925 (0.6056)  labels_encoder_unscaled: 0.5925 (0.6056)  time: 0.0477  data: 0.0191  max mem: 593
Epoch: [3]  [ 800/1511]  eta: 0:00:36  lr: 0.000001  loss: 0.5489 (0.6034)  labels_encoder: 0.5489 (0.6034)  labels_encoder_unscaled: 0.5489 (0.6034)  time: 0.0501  data: 0.0214  max mem: 593
Epoch: [3]  [ 850/1511]  eta: 0:00:34  lr: 0.000001  loss: 0.6297 (0.6041)  labels_encoder: 0.6297 (0.6041)  labels_encoder_unscaled: 0.6297 (0.6041)  time: 0.0497  data: 0.0211  max mem: 593
Epoch: [3]  [ 900/1511]  eta: 0:00:31  lr: 0.000001  loss: 0.5333 (0.6026)  labels_encoder: 0.5333 (0.6026)  labels_encoder_unscaled: 0.5333 (0.6026)  time: 0.0524  data: 0.0237  max mem: 593
Epoch: [3]  [ 950/1511]  eta: 0:00:28  lr: 0.000001  loss: 0.5850 (0.6016)  labels_encoder: 0.5850 (0.6016)  labels_encoder_unscaled: 0.5850 (0.6016)  time: 0.0518  data: 0.0233  max mem: 593
Epoch: [3]  [1000/1511]  eta: 0:00:26  lr: 0.000001  loss: 0.5976 (0.6006)  labels_encoder: 0.5976 (0.6006)  labels_encoder_unscaled: 0.5976 (0.6006)  time: 0.0500  data: 0.0214  max mem: 593
Epoch: [3]  [1050/1511]  eta: 0:00:23  lr: 0.000001  loss: 0.5772 (0.6000)  labels_encoder: 0.5772 (0.6000)  labels_encoder_unscaled: 0.5772 (0.6000)  time: 0.0483  data: 0.0200  max mem: 593
Epoch: [3]  [1100/1511]  eta: 0:00:21  lr: 0.000001  loss: 0.5250 (0.5984)  labels_encoder: 0.5250 (0.5984)  labels_encoder_unscaled: 0.5250 (0.5984)  time: 0.0505  data: 0.0219  max mem: 593
Epoch: [3]  [1150/1511]  eta: 0:00:18  lr: 0.000001  loss: 0.5430 (0.5971)  labels_encoder: 0.5430 (0.5971)  labels_encoder_unscaled: 0.5430 (0.5971)  time: 0.0496  data: 0.0218  max mem: 593
Epoch: [3]  [1200/1511]  eta: 0:00:15  lr: 0.000001  loss: 0.5287 (0.5953)  labels_encoder: 0.5287 (0.5953)  labels_encoder_unscaled: 0.5287 (0.5953)  time: 0.0458  data: 0.0185  max mem: 593
Epoch: [3]  [1250/1511]  eta: 0:00:13  lr: 0.000001  loss: 0.5598 (0.5943)  labels_encoder: 0.5598 (0.5943)  labels_encoder_unscaled: 0.5598 (0.5943)  time: 0.0473  data: 0.0198  max mem: 593
Epoch: [3]  [1300/1511]  eta: 0:00:10  lr: 0.000001  loss: 0.5577 (0.5944)  labels_encoder: 0.5577 (0.5944)  labels_encoder_unscaled: 0.5577 (0.5944)  time: 0.0475  data: 0.0192  max mem: 593
Epoch: [3]  [1350/1511]  eta: 0:00:08  lr: 0.000001  loss: 0.5636 (0.5940)  labels_encoder: 0.5636 (0.5940)  labels_encoder_unscaled: 0.5636 (0.5940)  time: 0.0479  data: 0.0203  max mem: 593
Epoch: [3]  [1400/1511]  eta: 0:00:05  lr: 0.000001  loss: 0.5498 (0.5935)  labels_encoder: 0.5498 (0.5935)  labels_encoder_unscaled: 0.5498 (0.5935)  time: 0.0469  data: 0.0198  max mem: 593
Epoch: [3]  [1450/1511]  eta: 0:00:03  lr: 0.000001  loss: 0.5377 (0.5931)  labels_encoder: 0.5377 (0.5931)  labels_encoder_unscaled: 0.5377 (0.5931)  time: 0.0473  data: 0.0199  max mem: 593
Epoch: [3]  [1500/1511]  eta: 0:00:00  lr: 0.000001  loss: 0.5511 (0.5931)  labels_encoder: 0.5511 (0.5931)  labels_encoder_unscaled: 0.5511 (0.5931)  time: 0.0474  data: 0.0205  max mem: 593
Epoch: [3]  [1510/1511]  eta: 0:00:00  lr: 0.000001  loss: 0.5172 (0.5928)  labels_encoder: 0.5172 (0.5928)  labels_encoder_unscaled: 0.5172 (0.5928)  time: 0.0456  data: 0.0169  max mem: 593
Epoch: [3] Total time: 0:01:16 (0.0505 s / it)
Averaged stats: lr: 0.000001  loss: 0.5172 (0.5928)  labels_encoder: 0.5172 (0.5928)  labels_encoder_unscaled: 0.5172 (0.5928)
Test:  [  0/559]  eta: 0:17:29  loss: 0.5988 (0.5988)  labels_encoder: 0.5988 (0.5988)  labels_encoder_unscaled: 0.5988 (0.5988)  time: 1.8775  data: 1.8582  max mem: 593
Test:  [ 50/559]  eta: 0:00:40  loss: 0.7463 (0.8664)  labels_encoder: 0.7463 (0.8664)  labels_encoder_unscaled: 0.7463 (0.8664)  time: 0.0434  data: 0.0250  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.4832 (0.8319)  labels_encoder: 0.4832 (0.8319)  labels_encoder_unscaled: 0.4832 (0.8319)  time: 0.0516  data: 0.0359  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.5282 (0.8580)  labels_encoder: 0.5282 (0.8580)  labels_encoder_unscaled: 0.5282 (0.8580)  time: 0.0475  data: 0.0317  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6800 (0.8016)  labels_encoder: 0.6800 (0.8016)  labels_encoder_unscaled: 0.6800 (0.8016)  time: 0.0484  data: 0.0315  max mem: 593
Test:  [250/559]  eta: 0:00:16  loss: 0.7114 (0.9008)  labels_encoder: 0.7114 (0.9008)  labels_encoder_unscaled: 0.7114 (0.9008)  time: 0.0517  data: 0.0357  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1548 (0.9543)  labels_encoder: 1.1548 (0.9543)  labels_encoder_unscaled: 1.1548 (0.9543)  time: 0.0484  data: 0.0317  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8029 (0.9756)  labels_encoder: 0.8029 (0.9756)  labels_encoder_unscaled: 0.8029 (0.9756)  time: 0.0490  data: 0.0322  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3778 (0.9522)  labels_encoder: 0.3778 (0.9522)  labels_encoder_unscaled: 0.3778 (0.9522)  time: 0.0485  data: 0.0315  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3947 (0.9299)  labels_encoder: 0.3947 (0.9299)  labels_encoder_unscaled: 0.3947 (0.9299)  time: 0.0477  data: 0.0317  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5383 (0.9110)  labels_encoder: 0.5383 (0.9110)  labels_encoder_unscaled: 0.5383 (0.9110)  time: 0.0517  data: 0.0358  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7218 (0.8870)  labels_encoder: 0.7218 (0.8870)  labels_encoder_unscaled: 0.7218 (0.8870)  time: 0.0470  data: 0.0311  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3578 (0.8808)  labels_encoder: 0.3578 (0.8808)  labels_encoder_unscaled: 0.3578 (0.8808)  time: 0.0458  data: 0.0303  max mem: 593
Test: Total time: 0:00:28 (0.0515 s / it)
Averaged stats: loss: 0.3578 (0.8808)  labels_encoder: 0.3578 (0.8808)  labels_encoder_unscaled: 0.3578 (0.8808)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_anet_features.pickle] mAP: 0.1369, mcAP: 0.8811

BaseballPitch: 0.0358
BasketballDunk: 0.1141
Billiards: 0.0047
CleanAndJerk: 0.4111
CliffDiving: 0.4508
CricketBowling: 0.0895
CricketShot: 0.1218
Diving: 0.0096
FrisbeeCatch: 0.1504
GolfSwing: 0.0709
HammerThrow: 0.1349
HighJump: 0.0608
JavelinThrow: 0.0957
LongJump: 0.2924
PoleVault: 0.1129
Shotput: 0.1363
SoccerPenalty: 0.0534
TennisSwing: 0.1781
ThrowDiscus: 0.0694
VolleyballSpiking: 0.1454
Epoch: [4]  [   0/1511]  eta: 0:45:48  lr: 0.000000  loss: 0.6558 (0.6558)  labels_encoder: 0.6558 (0.6558)  labels_encoder_unscaled: 0.6558 (0.6558)  time: 1.8193  data: 1.7766  max mem: 593
Epoch: [4]  [  50/1511]  eta: 0:01:52  lr: 0.000000  loss: 0.5711 (0.5856)  labels_encoder: 0.5711 (0.5856)  labels_encoder_unscaled: 0.5711 (0.5856)  time: 0.0419  data: 0.0002  max mem: 593
Epoch: [4]  [ 100/1511]  eta: 0:01:26  lr: 0.000000  loss: 0.5715 (0.5860)  labels_encoder: 0.5715 (0.5860)  labels_encoder_unscaled: 0.5715 (0.5860)  time: 0.0468  data: 0.0176  max mem: 593
Epoch: [4]  [ 150/1511]  eta: 0:01:17  lr: 0.000000  loss: 0.5287 (0.5781)  labels_encoder: 0.5287 (0.5781)  labels_encoder_unscaled: 0.5287 (0.5781)  time: 0.0469  data: 0.0141  max mem: 593
Epoch: [4]  [ 200/1511]  eta: 0:01:11  lr: 0.000000  loss: 0.5669 (0.5807)  labels_encoder: 0.5669 (0.5807)  labels_encoder_unscaled: 0.5669 (0.5807)  time: 0.0467  data: 0.0025  max mem: 593
Epoch: [4]  [ 250/1511]  eta: 0:01:07  lr: 0.000000  loss: 0.5540 (0.5752)  labels_encoder: 0.5540 (0.5752)  labels_encoder_unscaled: 0.5540 (0.5752)  time: 0.0487  data: 0.0128  max mem: 593
Epoch: [4]  [ 300/1511]  eta: 0:01:04  lr: 0.000000  loss: 0.5717 (0.5746)  labels_encoder: 0.5717 (0.5746)  labels_encoder_unscaled: 0.5717 (0.5746)  time: 0.0485  data: 0.0201  max mem: 593
Epoch: [4]  [ 350/1511]  eta: 0:01:00  lr: 0.000000  loss: 0.5679 (0.5726)  labels_encoder: 0.5679 (0.5726)  labels_encoder_unscaled: 0.5679 (0.5726)  time: 0.0470  data: 0.0157  max mem: 593
Epoch: [4]  [ 400/1511]  eta: 0:00:57  lr: 0.000000  loss: 0.5901 (0.5748)  labels_encoder: 0.5901 (0.5748)  labels_encoder_unscaled: 0.5901 (0.5748)  time: 0.0513  data: 0.0227  max mem: 593
Epoch: [4]  [ 450/1511]  eta: 0:00:54  lr: 0.000000  loss: 0.5671 (0.5759)  labels_encoder: 0.5671 (0.5759)  labels_encoder_unscaled: 0.5671 (0.5759)  time: 0.0491  data: 0.0210  max mem: 593
Epoch: [4]  [ 500/1511]  eta: 0:00:52  lr: 0.000000  loss: 0.5501 (0.5742)  labels_encoder: 0.5501 (0.5742)  labels_encoder_unscaled: 0.5501 (0.5742)  time: 0.0499  data: 0.0105  max mem: 593
Epoch: [4]  [ 550/1511]  eta: 0:00:49  lr: 0.000000  loss: 0.5938 (0.5747)  labels_encoder: 0.5938 (0.5747)  labels_encoder_unscaled: 0.5938 (0.5747)  time: 0.0492  data: 0.0212  max mem: 593
Epoch: [4]  [ 600/1511]  eta: 0:00:46  lr: 0.000000  loss: 0.5949 (0.5757)  labels_encoder: 0.5949 (0.5757)  labels_encoder_unscaled: 0.5949 (0.5757)  time: 0.0482  data: 0.0179  max mem: 593
Epoch: [4]  [ 650/1511]  eta: 0:00:43  lr: 0.000000  loss: 0.6269 (0.5782)  labels_encoder: 0.6269 (0.5782)  labels_encoder_unscaled: 0.6269 (0.5782)  time: 0.0478  data: 0.0204  max mem: 593
Epoch: [4]  [ 700/1511]  eta: 0:00:41  lr: 0.000000  loss: 0.6090 (0.5786)  labels_encoder: 0.6090 (0.5786)  labels_encoder_unscaled: 0.6090 (0.5786)  time: 0.0480  data: 0.0202  max mem: 593
Epoch: [4]  [ 750/1511]  eta: 0:00:38  lr: 0.000000  loss: 0.6225 (0.5790)  labels_encoder: 0.6225 (0.5790)  labels_encoder_unscaled: 0.6225 (0.5790)  time: 0.0480  data: 0.0178  max mem: 593
Epoch: [4]  [ 800/1511]  eta: 0:00:35  lr: 0.000000  loss: 0.5905 (0.5798)  labels_encoder: 0.5905 (0.5798)  labels_encoder_unscaled: 0.5905 (0.5798)  time: 0.0478  data: 0.0192  max mem: 593
Epoch: [4]  [ 850/1511]  eta: 0:00:33  lr: 0.000000  loss: 0.5495 (0.5793)  labels_encoder: 0.5495 (0.5793)  labels_encoder_unscaled: 0.5495 (0.5793)  time: 0.0486  data: 0.0199  max mem: 593
Epoch: [4]  [ 900/1511]  eta: 0:00:30  lr: 0.000000  loss: 0.5752 (0.5796)  labels_encoder: 0.5752 (0.5796)  labels_encoder_unscaled: 0.5752 (0.5796)  time: 0.0485  data: 0.0200  max mem: 593
Epoch: [4]  [ 950/1511]  eta: 0:00:28  lr: 0.000000  loss: 0.5737 (0.5799)  labels_encoder: 0.5737 (0.5799)  labels_encoder_unscaled: 0.5737 (0.5799)  time: 0.0499  data: 0.0213  max mem: 593
Epoch: [4]  [1000/1511]  eta: 0:00:25  lr: 0.000000  loss: 0.5911 (0.5801)  labels_encoder: 0.5911 (0.5801)  labels_encoder_unscaled: 0.5911 (0.5801)  time: 0.0483  data: 0.0154  max mem: 593
Epoch: [4]  [1050/1511]  eta: 0:00:23  lr: 0.000000  loss: 0.5315 (0.5794)  labels_encoder: 0.5315 (0.5794)  labels_encoder_unscaled: 0.5315 (0.5794)  time: 0.0473  data: 0.0188  max mem: 593
Epoch: [4]  [1100/1511]  eta: 0:00:20  lr: 0.000000  loss: 0.5517 (0.5797)  labels_encoder: 0.5517 (0.5797)  labels_encoder_unscaled: 0.5517 (0.5797)  time: 0.0486  data: 0.0192  max mem: 593
Epoch: [4]  [1150/1511]  eta: 0:00:18  lr: 0.000000  loss: 0.5813 (0.5802)  labels_encoder: 0.5813 (0.5802)  labels_encoder_unscaled: 0.5813 (0.5802)  time: 0.0457  data: 0.0103  max mem: 593
Epoch: [4]  [1200/1511]  eta: 0:00:15  lr: 0.000000  loss: 0.5698 (0.5805)  labels_encoder: 0.5698 (0.5805)  labels_encoder_unscaled: 0.5698 (0.5805)  time: 0.0475  data: 0.0165  max mem: 593
Epoch: [4]  [1250/1511]  eta: 0:00:13  lr: 0.000000  loss: 0.6114 (0.5799)  labels_encoder: 0.6114 (0.5799)  labels_encoder_unscaled: 0.6114 (0.5799)  time: 0.0473  data: 0.0189  max mem: 593
Epoch: [4]  [1300/1511]  eta: 0:00:10  lr: 0.000000  loss: 0.5399 (0.5799)  labels_encoder: 0.5399 (0.5799)  labels_encoder_unscaled: 0.5399 (0.5799)  time: 0.0472  data: 0.0191  max mem: 593
Epoch: [4]  [1350/1511]  eta: 0:00:08  lr: 0.000000  loss: 0.5498 (0.5794)  labels_encoder: 0.5498 (0.5794)  labels_encoder_unscaled: 0.5498 (0.5794)  time: 0.0467  data: 0.0184  max mem: 593
Epoch: [4]  [1400/1511]  eta: 0:00:05  lr: 0.000000  loss: 0.5640 (0.5794)  labels_encoder: 0.5640 (0.5794)  labels_encoder_unscaled: 0.5640 (0.5794)  time: 0.0536  data: 0.0193  max mem: 593
Epoch: [4]  [1450/1511]  eta: 0:00:03  lr: 0.000000  loss: 0.5377 (0.5797)  labels_encoder: 0.5377 (0.5797)  labels_encoder_unscaled: 0.5377 (0.5797)  time: 0.0520  data: 0.0237  max mem: 593
Epoch: [4]  [1500/1511]  eta: 0:00:00  lr: 0.000000  loss: 0.5261 (0.5791)  labels_encoder: 0.5261 (0.5791)  labels_encoder_unscaled: 0.5261 (0.5791)  time: 0.0469  data: 0.0177  max mem: 593
Epoch: [4]  [1510/1511]  eta: 0:00:00  lr: 0.000000  loss: 0.5272 (0.5793)  labels_encoder: 0.5272 (0.5793)  labels_encoder_unscaled: 0.5272 (0.5793)  time: 0.0457  data: 0.0162  max mem: 593
Epoch: [4] Total time: 0:01:15 (0.0499 s / it)
Averaged stats: lr: 0.000000  loss: 0.5272 (0.5793)  labels_encoder: 0.5272 (0.5793)  labels_encoder_unscaled: 0.5272 (0.5793)
Test:  [  0/559]  eta: 0:12:44  loss: 0.5655 (0.5655)  labels_encoder: 0.5655 (0.5655)  labels_encoder_unscaled: 0.5655 (0.5655)  time: 1.3676  data: 1.3507  max mem: 593
Test:  [ 50/559]  eta: 0:00:40  loss: 0.7633 (0.8600)  labels_encoder: 0.7633 (0.8600)  labels_encoder_unscaled: 0.7633 (0.8600)  time: 0.0361  data: 0.0189  max mem: 593
Test:  [100/559]  eta: 0:00:28  loss: 0.5074 (0.8200)  labels_encoder: 0.5074 (0.8200)  labels_encoder_unscaled: 0.5074 (0.8200)  time: 0.0460  data: 0.0303  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.4549 (0.8513)  labels_encoder: 0.4549 (0.8513)  labels_encoder_unscaled: 0.4549 (0.8513)  time: 0.0461  data: 0.0301  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6402 (0.7937)  labels_encoder: 0.6402 (0.7937)  labels_encoder_unscaled: 0.6402 (0.7937)  time: 0.0491  data: 0.0341  max mem: 593
Test:  [250/559]  eta: 0:00:16  loss: 0.7863 (0.8927)  labels_encoder: 0.7863 (0.8927)  labels_encoder_unscaled: 0.7863 (0.8927)  time: 0.0505  data: 0.0340  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1554 (0.9491)  labels_encoder: 1.1554 (0.9491)  labels_encoder_unscaled: 1.1554 (0.9491)  time: 0.0529  data: 0.0363  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7873 (0.9721)  labels_encoder: 0.7873 (0.9721)  labels_encoder_unscaled: 0.7873 (0.9721)  time: 0.0491  data: 0.0339  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3590 (0.9476)  labels_encoder: 0.3590 (0.9476)  labels_encoder_unscaled: 0.3590 (0.9476)  time: 0.0495  data: 0.0333  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3972 (0.9256)  labels_encoder: 0.3972 (0.9256)  labels_encoder_unscaled: 0.3972 (0.9256)  time: 0.0483  data: 0.0324  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5671 (0.9093)  labels_encoder: 0.5671 (0.9093)  labels_encoder_unscaled: 0.5671 (0.9093)  time: 0.0524  data: 0.0356  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7029 (0.8857)  labels_encoder: 0.7029 (0.8857)  labels_encoder_unscaled: 0.7029 (0.8857)  time: 0.0491  data: 0.0333  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3743 (0.8796)  labels_encoder: 0.3743 (0.8796)  labels_encoder_unscaled: 0.3743 (0.8796)  time: 0.0475  data: 0.0322  max mem: 593
Test: Total time: 0:00:29 (0.0520 s / it)
Averaged stats: loss: 0.3743 (0.8796)  labels_encoder: 0.3743 (0.8796)  labels_encoder_unscaled: 0.3743 (0.8796)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_anet_features.pickle] mAP: 0.1356, mcAP: 0.8808

BaseballPitch: 0.0394
BasketballDunk: 0.1135
Billiards: 0.0047
CleanAndJerk: 0.4045
CliffDiving: 0.4478
CricketBowling: 0.0742
CricketShot: 0.1115
Diving: 0.0150
FrisbeeCatch: 0.1384
GolfSwing: 0.0642
HammerThrow: 0.1351
HighJump: 0.0658
JavelinThrow: 0.0815
LongJump: 0.3315
PoleVault: 0.1124
Shotput: 0.1357
SoccerPenalty: 0.0570
TennisSwing: 0.1862
ThrowDiscus: 0.0336
VolleyballSpiking: 0.1594
Training time 0:07:10
