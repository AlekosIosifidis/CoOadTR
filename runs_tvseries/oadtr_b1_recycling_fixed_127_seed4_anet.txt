Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_anet_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_anet_features.pickle
Loaded tvseries_anet_features.pickle
Start training
Epoch: [1]  [   0/1509]  eta: 1:05:06  lr: 0.000100  loss: 3.2833 (3.2833)  labels_encoder: 3.2833 (3.2833)  labels_encoder_unscaled: 3.2833 (3.2833)  time: 2.5888  data: 2.4594  max mem: 483
Epoch: [1]  [  50/1509]  eta: 0:02:29  lr: 0.000100  loss: 1.0031 (1.1032)  labels_encoder: 1.0031 (1.1032)  labels_encoder_unscaled: 1.0031 (1.1032)  time: 0.0435  data: 0.0002  max mem: 593
Epoch: [1]  [ 100/1509]  eta: 0:01:44  lr: 0.000100  loss: 0.9824 (1.0418)  labels_encoder: 0.9824 (1.0418)  labels_encoder_unscaled: 0.9824 (1.0418)  time: 0.0485  data: 0.0170  max mem: 593
Epoch: [1]  [ 150/1509]  eta: 0:01:29  lr: 0.000100  loss: 0.9712 (1.0202)  labels_encoder: 0.9712 (1.0202)  labels_encoder_unscaled: 0.9712 (1.0202)  time: 0.0500  data: 0.0234  max mem: 593
Epoch: [1]  [ 200/1509]  eta: 0:01:22  lr: 0.000100  loss: 0.8709 (0.9947)  labels_encoder: 0.8709 (0.9947)  labels_encoder_unscaled: 0.8709 (0.9947)  time: 0.0649  data: 0.0363  max mem: 593
Epoch: [1]  [ 250/1509]  eta: 0:01:16  lr: 0.000100  loss: 0.9325 (0.9805)  labels_encoder: 0.9325 (0.9805)  labels_encoder_unscaled: 0.9325 (0.9805)  time: 0.0492  data: 0.0169  max mem: 593
Epoch: [1]  [ 300/1509]  eta: 0:01:12  lr: 0.000100  loss: 0.8685 (0.9593)  labels_encoder: 0.8685 (0.9593)  labels_encoder_unscaled: 0.8685 (0.9593)  time: 0.0517  data: 0.0245  max mem: 593
Epoch: [1]  [ 350/1509]  eta: 0:01:07  lr: 0.000100  loss: 0.7588 (0.9372)  labels_encoder: 0.7588 (0.9372)  labels_encoder_unscaled: 0.7588 (0.9372)  time: 0.0492  data: 0.0217  max mem: 593
Epoch: [1]  [ 400/1509]  eta: 0:01:03  lr: 0.000100  loss: 0.7380 (0.9240)  labels_encoder: 0.7380 (0.9240)  labels_encoder_unscaled: 0.7380 (0.9240)  time: 0.0498  data: 0.0211  max mem: 593
Epoch: [1]  [ 450/1509]  eta: 0:00:59  lr: 0.000100  loss: 0.8469 (0.9163)  labels_encoder: 0.8469 (0.9163)  labels_encoder_unscaled: 0.8469 (0.9163)  time: 0.0505  data: 0.0227  max mem: 593
Epoch: [1]  [ 500/1509]  eta: 0:00:56  lr: 0.000100  loss: 0.8736 (0.9109)  labels_encoder: 0.8736 (0.9109)  labels_encoder_unscaled: 0.8736 (0.9109)  time: 0.0482  data: 0.0157  max mem: 593
Epoch: [1]  [ 550/1509]  eta: 0:00:53  lr: 0.000100  loss: 0.7856 (0.9019)  labels_encoder: 0.7856 (0.9019)  labels_encoder_unscaled: 0.7856 (0.9019)  time: 0.0516  data: 0.0239  max mem: 593
Epoch: [1]  [ 600/1509]  eta: 0:00:50  lr: 0.000100  loss: 0.7794 (0.8940)  labels_encoder: 0.7794 (0.8940)  labels_encoder_unscaled: 0.7794 (0.8940)  time: 0.0504  data: 0.0234  max mem: 593
Epoch: [1]  [ 650/1509]  eta: 0:00:47  lr: 0.000100  loss: 0.7126 (0.8865)  labels_encoder: 0.7126 (0.8865)  labels_encoder_unscaled: 0.7126 (0.8865)  time: 0.0504  data: 0.0234  max mem: 593
Epoch: [1]  [ 700/1509]  eta: 0:00:44  lr: 0.000100  loss: 0.7348 (0.8770)  labels_encoder: 0.7348 (0.8770)  labels_encoder_unscaled: 0.7348 (0.8770)  time: 0.0544  data: 0.0265  max mem: 593
Epoch: [1]  [ 750/1509]  eta: 0:00:41  lr: 0.000100  loss: 0.7322 (0.8713)  labels_encoder: 0.7322 (0.8713)  labels_encoder_unscaled: 0.7322 (0.8713)  time: 0.0516  data: 0.0225  max mem: 593
Epoch: [1]  [ 800/1509]  eta: 0:00:38  lr: 0.000100  loss: 0.6781 (0.8643)  labels_encoder: 0.6781 (0.8643)  labels_encoder_unscaled: 0.6781 (0.8643)  time: 0.0508  data: 0.0237  max mem: 593
Epoch: [1]  [ 850/1509]  eta: 0:00:35  lr: 0.000100  loss: 0.7626 (0.8604)  labels_encoder: 0.7626 (0.8604)  labels_encoder_unscaled: 0.7626 (0.8604)  time: 0.0509  data: 0.0212  max mem: 593
Epoch: [1]  [ 900/1509]  eta: 0:00:32  lr: 0.000100  loss: 0.6792 (0.8547)  labels_encoder: 0.6792 (0.8547)  labels_encoder_unscaled: 0.6792 (0.8547)  time: 0.0516  data: 0.0239  max mem: 593
Epoch: [1]  [ 950/1509]  eta: 0:00:29  lr: 0.000100  loss: 0.7528 (0.8495)  labels_encoder: 0.7528 (0.8495)  labels_encoder_unscaled: 0.7528 (0.8495)  time: 0.0503  data: 0.0227  max mem: 593
Epoch: [1]  [1000/1509]  eta: 0:00:27  lr: 0.000100  loss: 0.7314 (0.8454)  labels_encoder: 0.7314 (0.8454)  labels_encoder_unscaled: 0.7314 (0.8454)  time: 0.0516  data: 0.0233  max mem: 593
Epoch: [1]  [1050/1509]  eta: 0:00:24  lr: 0.000100  loss: 0.7083 (0.8425)  labels_encoder: 0.7083 (0.8425)  labels_encoder_unscaled: 0.7083 (0.8425)  time: 0.0517  data: 0.0206  max mem: 593
Epoch: [1]  [1100/1509]  eta: 0:00:21  lr: 0.000100  loss: 0.7368 (0.8377)  labels_encoder: 0.7368 (0.8377)  labels_encoder_unscaled: 0.7368 (0.8377)  time: 0.0514  data: 0.0243  max mem: 593
Epoch: [1]  [1150/1509]  eta: 0:00:19  lr: 0.000100  loss: 0.6869 (0.8317)  labels_encoder: 0.6869 (0.8317)  labels_encoder_unscaled: 0.6869 (0.8317)  time: 0.0516  data: 0.0207  max mem: 593
Epoch: [1]  [1200/1509]  eta: 0:00:16  lr: 0.000100  loss: 0.6291 (0.8256)  labels_encoder: 0.6291 (0.8256)  labels_encoder_unscaled: 0.6291 (0.8256)  time: 0.0491  data: 0.0216  max mem: 593
Epoch: [1]  [1250/1509]  eta: 0:00:13  lr: 0.000100  loss: 0.6742 (0.8213)  labels_encoder: 0.6742 (0.8213)  labels_encoder_unscaled: 0.6742 (0.8213)  time: 0.0576  data: 0.0290  max mem: 593
Epoch: [1]  [1300/1509]  eta: 0:00:11  lr: 0.000100  loss: 0.7178 (0.8172)  labels_encoder: 0.7178 (0.8172)  labels_encoder_unscaled: 0.7178 (0.8172)  time: 0.0533  data: 0.0247  max mem: 593
Epoch: [1]  [1350/1509]  eta: 0:00:08  lr: 0.000100  loss: 0.6201 (0.8126)  labels_encoder: 0.6201 (0.8126)  labels_encoder_unscaled: 0.6201 (0.8126)  time: 0.0508  data: 0.0238  max mem: 593
Epoch: [1]  [1400/1509]  eta: 0:00:05  lr: 0.000100  loss: 0.6235 (0.8076)  labels_encoder: 0.6235 (0.8076)  labels_encoder_unscaled: 0.6235 (0.8076)  time: 0.0526  data: 0.0250  max mem: 593
Epoch: [1]  [1450/1509]  eta: 0:00:03  lr: 0.000100  loss: 0.6739 (0.8040)  labels_encoder: 0.6739 (0.8040)  labels_encoder_unscaled: 0.6739 (0.8040)  time: 0.0493  data: 0.0215  max mem: 593
Epoch: [1]  [1500/1509]  eta: 0:00:00  lr: 0.000100  loss: 0.6848 (0.8006)  labels_encoder: 0.6848 (0.8006)  labels_encoder_unscaled: 0.6848 (0.8006)  time: 0.0522  data: 0.0225  max mem: 593
Epoch: [1]  [1508/1509]  eta: 0:00:00  lr: 0.000100  loss: 0.6813 (0.7995)  labels_encoder: 0.6813 (0.7995)  labels_encoder_unscaled: 0.6813 (0.7995)  time: 0.0500  data: 0.0215  max mem: 593
Epoch: [1] Total time: 0:01:20 (0.0531 s / it)
Averaged stats: lr: 0.000100  loss: 0.6813 (0.7995)  labels_encoder: 0.6813 (0.7995)  labels_encoder_unscaled: 0.6813 (0.7995)
Test:  [  0/559]  eta: 0:18:09  loss: 0.5280 (0.5280)  labels_encoder: 0.5280 (0.5280)  labels_encoder_unscaled: 0.5280 (0.5280)  time: 1.9482  data: 1.9293  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 1.0210 (0.9262)  labels_encoder: 1.0210 (0.9262)  labels_encoder_unscaled: 1.0210 (0.9262)  time: 0.0419  data: 0.0247  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.4229 (0.8485)  labels_encoder: 0.4229 (0.8485)  labels_encoder_unscaled: 0.4229 (0.8485)  time: 0.0498  data: 0.0339  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.6435 (0.8809)  labels_encoder: 0.6435 (0.8809)  labels_encoder_unscaled: 0.6435 (0.8809)  time: 0.0511  data: 0.0352  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.5926 (0.8144)  labels_encoder: 0.5926 (0.8144)  labels_encoder_unscaled: 0.5926 (0.8144)  time: 0.0483  data: 0.0324  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.9060 (0.9286)  labels_encoder: 0.9060 (0.9286)  labels_encoder_unscaled: 0.9060 (0.9286)  time: 0.0498  data: 0.0330  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.0981 (1.0076)  labels_encoder: 1.0981 (1.0076)  labels_encoder_unscaled: 1.0981 (1.0076)  time: 0.0494  data: 0.0325  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7275 (1.0347)  labels_encoder: 0.7275 (1.0347)  labels_encoder_unscaled: 0.7275 (1.0347)  time: 0.0501  data: 0.0343  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3435 (1.0057)  labels_encoder: 0.3435 (1.0057)  labels_encoder_unscaled: 0.3435 (1.0057)  time: 0.0506  data: 0.0345  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4393 (0.9818)  labels_encoder: 0.4393 (0.9818)  labels_encoder_unscaled: 0.4393 (0.9818)  time: 0.0487  data: 0.0329  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.8177 (0.9657)  labels_encoder: 0.8177 (0.9657)  labels_encoder_unscaled: 0.8177 (0.9657)  time: 0.0513  data: 0.0355  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6789 (0.9394)  labels_encoder: 0.6789 (0.9394)  labels_encoder_unscaled: 0.6789 (0.9394)  time: 0.0498  data: 0.0338  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4024 (0.9331)  labels_encoder: 0.4024 (0.9331)  labels_encoder_unscaled: 0.4024 (0.9331)  time: 0.0482  data: 0.0326  max mem: 593
Test: Total time: 0:00:30 (0.0537 s / it)
Averaged stats: loss: 0.4024 (0.9331)  labels_encoder: 0.4024 (0.9331)  labels_encoder_unscaled: 0.4024 (0.9331)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_anet_features.pickle] mAP: 0.1153, mcAP: 0.8587

BaseballPitch: 0.0273
BasketballDunk: 0.0676
Billiards: 0.0041
CleanAndJerk: 0.3455
CliffDiving: 0.4907
CricketBowling: 0.0505
CricketShot: 0.0570
Diving: 0.0134
FrisbeeCatch: 0.1128
GolfSwing: 0.0404
HammerThrow: 0.0641
HighJump: 0.0232
JavelinThrow: 0.0831
LongJump: 0.3518
PoleVault: 0.1048
Shotput: 0.1215
SoccerPenalty: 0.0368
TennisSwing: 0.1651
ThrowDiscus: 0.0095
VolleyballSpiking: 0.1364
Epoch: [2]  [   0/1509]  eta: 0:52:07  lr: 0.000010  loss: 0.7614 (0.7614)  labels_encoder: 0.7614 (0.7614)  labels_encoder_unscaled: 0.7614 (0.7614)  time: 2.0724  data: 2.0254  max mem: 593
Epoch: [2]  [  50/1509]  eta: 0:02:15  lr: 0.000010  loss: 0.6923 (0.6812)  labels_encoder: 0.6923 (0.6812)  labels_encoder_unscaled: 0.6923 (0.6812)  time: 0.0653  data: 0.0297  max mem: 593
Epoch: [2]  [ 100/1509]  eta: 0:01:40  lr: 0.000010  loss: 0.6293 (0.6659)  labels_encoder: 0.6293 (0.6659)  labels_encoder_unscaled: 0.6293 (0.6659)  time: 0.0495  data: 0.0208  max mem: 593
Epoch: [2]  [ 150/1509]  eta: 0:01:30  lr: 0.000010  loss: 0.6208 (0.6659)  labels_encoder: 0.6208 (0.6659)  labels_encoder_unscaled: 0.6208 (0.6659)  time: 0.0526  data: 0.0210  max mem: 593
Epoch: [2]  [ 200/1509]  eta: 0:01:21  lr: 0.000010  loss: 0.6221 (0.6712)  labels_encoder: 0.6221 (0.6712)  labels_encoder_unscaled: 0.6221 (0.6712)  time: 0.0509  data: 0.0228  max mem: 593
Epoch: [2]  [ 250/1509]  eta: 0:01:15  lr: 0.000010  loss: 0.6275 (0.6705)  labels_encoder: 0.6275 (0.6705)  labels_encoder_unscaled: 0.6275 (0.6705)  time: 0.0515  data: 0.0194  max mem: 593
Epoch: [2]  [ 300/1509]  eta: 0:01:10  lr: 0.000010  loss: 0.6065 (0.6656)  labels_encoder: 0.6065 (0.6656)  labels_encoder_unscaled: 0.6065 (0.6656)  time: 0.0509  data: 0.0230  max mem: 593
Epoch: [2]  [ 350/1509]  eta: 0:01:06  lr: 0.000010  loss: 0.6116 (0.6625)  labels_encoder: 0.6116 (0.6625)  labels_encoder_unscaled: 0.6116 (0.6625)  time: 0.0507  data: 0.0228  max mem: 593
Epoch: [2]  [ 400/1509]  eta: 0:01:02  lr: 0.000010  loss: 0.6029 (0.6581)  labels_encoder: 0.6029 (0.6581)  labels_encoder_unscaled: 0.6029 (0.6581)  time: 0.0516  data: 0.0234  max mem: 593
Epoch: [2]  [ 450/1509]  eta: 0:00:59  lr: 0.000010  loss: 0.6140 (0.6530)  labels_encoder: 0.6140 (0.6530)  labels_encoder_unscaled: 0.6140 (0.6530)  time: 0.0536  data: 0.0225  max mem: 593
Epoch: [2]  [ 500/1509]  eta: 0:00:55  lr: 0.000010  loss: 0.6341 (0.6516)  labels_encoder: 0.6341 (0.6516)  labels_encoder_unscaled: 0.6341 (0.6516)  time: 0.0491  data: 0.0227  max mem: 593
Epoch: [2]  [ 550/1509]  eta: 0:00:52  lr: 0.000010  loss: 0.5702 (0.6485)  labels_encoder: 0.5702 (0.6485)  labels_encoder_unscaled: 0.5702 (0.6485)  time: 0.0483  data: 0.0197  max mem: 593
Epoch: [2]  [ 600/1509]  eta: 0:00:49  lr: 0.000010  loss: 0.6065 (0.6461)  labels_encoder: 0.6065 (0.6461)  labels_encoder_unscaled: 0.6065 (0.6461)  time: 0.0531  data: 0.0185  max mem: 593
Epoch: [2]  [ 650/1509]  eta: 0:00:46  lr: 0.000010  loss: 0.5994 (0.6446)  labels_encoder: 0.5994 (0.6446)  labels_encoder_unscaled: 0.5994 (0.6446)  time: 0.0505  data: 0.0212  max mem: 593
Epoch: [2]  [ 700/1509]  eta: 0:00:43  lr: 0.000010  loss: 0.6119 (0.6431)  labels_encoder: 0.6119 (0.6431)  labels_encoder_unscaled: 0.6119 (0.6431)  time: 0.0482  data: 0.0204  max mem: 593
Epoch: [2]  [ 750/1509]  eta: 0:00:41  lr: 0.000010  loss: 0.5940 (0.6423)  labels_encoder: 0.5940 (0.6423)  labels_encoder_unscaled: 0.5940 (0.6423)  time: 0.0568  data: 0.0140  max mem: 593
Epoch: [2]  [ 800/1509]  eta: 0:00:38  lr: 0.000010  loss: 0.6420 (0.6419)  labels_encoder: 0.6420 (0.6419)  labels_encoder_unscaled: 0.6420 (0.6419)  time: 0.0518  data: 0.0236  max mem: 593
Epoch: [2]  [ 850/1509]  eta: 0:00:35  lr: 0.000010  loss: 0.6621 (0.6414)  labels_encoder: 0.6621 (0.6414)  labels_encoder_unscaled: 0.6621 (0.6414)  time: 0.0626  data: 0.0269  max mem: 593
Epoch: [2]  [ 900/1509]  eta: 0:00:33  lr: 0.000010  loss: 0.6686 (0.6403)  labels_encoder: 0.6686 (0.6403)  labels_encoder_unscaled: 0.6686 (0.6403)  time: 0.0574  data: 0.0246  max mem: 593
Epoch: [2]  [ 950/1509]  eta: 0:00:30  lr: 0.000010  loss: 0.6335 (0.6385)  labels_encoder: 0.6335 (0.6385)  labels_encoder_unscaled: 0.6335 (0.6385)  time: 0.0558  data: 0.0244  max mem: 593
Epoch: [2]  [1000/1509]  eta: 0:00:27  lr: 0.000010  loss: 0.6245 (0.6377)  labels_encoder: 0.6245 (0.6377)  labels_encoder_unscaled: 0.6245 (0.6377)  time: 0.0484  data: 0.0122  max mem: 593
Epoch: [2]  [1050/1509]  eta: 0:00:24  lr: 0.000010  loss: 0.5906 (0.6364)  labels_encoder: 0.5906 (0.6364)  labels_encoder_unscaled: 0.5906 (0.6364)  time: 0.0522  data: 0.0249  max mem: 593
Epoch: [2]  [1100/1509]  eta: 0:00:22  lr: 0.000010  loss: 0.6198 (0.6357)  labels_encoder: 0.6198 (0.6357)  labels_encoder_unscaled: 0.6198 (0.6357)  time: 0.0636  data: 0.0346  max mem: 593
Epoch: [2]  [1150/1509]  eta: 0:00:19  lr: 0.000010  loss: 0.6379 (0.6342)  labels_encoder: 0.6379 (0.6342)  labels_encoder_unscaled: 0.6379 (0.6342)  time: 0.0527  data: 0.0250  max mem: 593
Epoch: [2]  [1200/1509]  eta: 0:00:16  lr: 0.000010  loss: 0.6073 (0.6332)  labels_encoder: 0.6073 (0.6332)  labels_encoder_unscaled: 0.6073 (0.6332)  time: 0.0488  data: 0.0208  max mem: 593
Epoch: [2]  [1250/1509]  eta: 0:00:13  lr: 0.000010  loss: 0.6239 (0.6320)  labels_encoder: 0.6239 (0.6320)  labels_encoder_unscaled: 0.6239 (0.6320)  time: 0.0485  data: 0.0188  max mem: 593
Epoch: [2]  [1300/1509]  eta: 0:00:11  lr: 0.000010  loss: 0.5927 (0.6311)  labels_encoder: 0.5927 (0.6311)  labels_encoder_unscaled: 0.5927 (0.6311)  time: 0.0485  data: 0.0204  max mem: 593
Epoch: [2]  [1350/1509]  eta: 0:00:08  lr: 0.000010  loss: 0.5776 (0.6300)  labels_encoder: 0.5776 (0.6300)  labels_encoder_unscaled: 0.5776 (0.6300)  time: 0.0504  data: 0.0219  max mem: 593
Epoch: [2]  [1400/1509]  eta: 0:00:05  lr: 0.000010  loss: 0.6068 (0.6289)  labels_encoder: 0.6068 (0.6289)  labels_encoder_unscaled: 0.6068 (0.6289)  time: 0.0500  data: 0.0175  max mem: 593
Epoch: [2]  [1450/1509]  eta: 0:00:03  lr: 0.000010  loss: 0.5692 (0.6281)  labels_encoder: 0.5692 (0.6281)  labels_encoder_unscaled: 0.5692 (0.6281)  time: 0.0443  data: 0.0115  max mem: 593
Epoch: [2]  [1500/1509]  eta: 0:00:00  lr: 0.000010  loss: 0.5664 (0.6274)  labels_encoder: 0.5664 (0.6274)  labels_encoder_unscaled: 0.5664 (0.6274)  time: 0.0495  data: 0.0091  max mem: 593
Epoch: [2]  [1508/1509]  eta: 0:00:00  lr: 0.000010  loss: 0.6424 (0.6276)  labels_encoder: 0.6424 (0.6276)  labels_encoder_unscaled: 0.6424 (0.6276)  time: 0.0454  data: 0.0055  max mem: 593
Epoch: [2] Total time: 0:01:20 (0.0533 s / it)
Averaged stats: lr: 0.000010  loss: 0.6424 (0.6276)  labels_encoder: 0.6424 (0.6276)  labels_encoder_unscaled: 0.6424 (0.6276)
Test:  [  0/559]  eta: 0:16:39  loss: 0.6574 (0.6574)  labels_encoder: 0.6574 (0.6574)  labels_encoder_unscaled: 0.6574 (0.6574)  time: 1.7885  data: 1.7710  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 0.7908 (0.9390)  labels_encoder: 0.7908 (0.9390)  labels_encoder_unscaled: 0.7908 (0.9390)  time: 0.0481  data: 0.0318  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.4300 (0.8789)  labels_encoder: 0.4300 (0.8789)  labels_encoder_unscaled: 0.4300 (0.8789)  time: 0.0514  data: 0.0351  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5605 (0.9025)  labels_encoder: 0.5605 (0.9025)  labels_encoder_unscaled: 0.5605 (0.9025)  time: 0.0486  data: 0.0317  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.7682 (0.8468)  labels_encoder: 0.7682 (0.8468)  labels_encoder_unscaled: 0.7682 (0.8468)  time: 0.0478  data: 0.0326  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.8019 (0.9737)  labels_encoder: 0.8019 (0.9737)  labels_encoder_unscaled: 0.8019 (0.9737)  time: 0.0513  data: 0.0348  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.2337 (1.0214)  labels_encoder: 1.2337 (1.0214)  labels_encoder_unscaled: 1.2337 (1.0214)  time: 0.0528  data: 0.0367  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7718 (1.0315)  labels_encoder: 0.7718 (1.0315)  labels_encoder_unscaled: 0.7718 (1.0315)  time: 0.0493  data: 0.0329  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3325 (1.0029)  labels_encoder: 0.3325 (1.0029)  labels_encoder_unscaled: 0.3325 (1.0029)  time: 0.0478  data: 0.0315  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4039 (0.9808)  labels_encoder: 0.4039 (0.9808)  labels_encoder_unscaled: 0.4039 (0.9808)  time: 0.0503  data: 0.0351  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6503 (0.9600)  labels_encoder: 0.6503 (0.9600)  labels_encoder_unscaled: 0.6503 (0.9600)  time: 0.0504  data: 0.0341  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6581 (0.9332)  labels_encoder: 0.6581 (0.9332)  labels_encoder_unscaled: 0.6581 (0.9332)  time: 0.0479  data: 0.0319  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4217 (0.9266)  labels_encoder: 0.4217 (0.9266)  labels_encoder_unscaled: 0.4217 (0.9266)  time: 0.0467  data: 0.0310  max mem: 593
Test: Total time: 0:00:30 (0.0538 s / it)
Averaged stats: loss: 0.4217 (0.9266)  labels_encoder: 0.4217 (0.9266)  labels_encoder_unscaled: 0.4217 (0.9266)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_anet_features.pickle] mAP: 0.1147, mcAP: 0.8644

BaseballPitch: 0.0345
BasketballDunk: 0.1032
Billiards: 0.0045
CleanAndJerk: 0.3989
CliffDiving: 0.2649
CricketBowling: 0.0982
CricketShot: 0.1008
Diving: 0.0033
FrisbeeCatch: 0.1348
GolfSwing: 0.0565
HammerThrow: 0.0719
HighJump: 0.0296
JavelinThrow: 0.0810
LongJump: 0.2886
PoleVault: 0.1140
Shotput: 0.1322
SoccerPenalty: 0.0454
TennisSwing: 0.1783
ThrowDiscus: 0.0245
VolleyballSpiking: 0.1286
Epoch: [3]  [   0/1509]  eta: 0:53:21  lr: 0.000001  loss: 0.9484 (0.9484)  labels_encoder: 0.9484 (0.9484)  labels_encoder_unscaled: 0.9484 (0.9484)  time: 2.1215  data: 2.0753  max mem: 593
Epoch: [3]  [  50/1509]  eta: 0:02:08  lr: 0.000001  loss: 0.5938 (0.6432)  labels_encoder: 0.5938 (0.6432)  labels_encoder_unscaled: 0.5938 (0.6432)  time: 0.0519  data: 0.0132  max mem: 593
Epoch: [3]  [ 100/1509]  eta: 0:01:43  lr: 0.000001  loss: 0.5775 (0.6364)  labels_encoder: 0.5775 (0.6364)  labels_encoder_unscaled: 0.5775 (0.6364)  time: 0.0519  data: 0.0189  max mem: 593
Epoch: [3]  [ 150/1509]  eta: 0:01:28  lr: 0.000001  loss: 0.6211 (0.6258)  labels_encoder: 0.6211 (0.6258)  labels_encoder_unscaled: 0.6211 (0.6258)  time: 0.0493  data: 0.0209  max mem: 593
Epoch: [3]  [ 200/1509]  eta: 0:01:20  lr: 0.000001  loss: 0.6100 (0.6261)  labels_encoder: 0.6100 (0.6261)  labels_encoder_unscaled: 0.6100 (0.6261)  time: 0.0501  data: 0.0208  max mem: 593
Epoch: [3]  [ 250/1509]  eta: 0:01:14  lr: 0.000001  loss: 0.5661 (0.6140)  labels_encoder: 0.5661 (0.6140)  labels_encoder_unscaled: 0.5661 (0.6140)  time: 0.0483  data: 0.0187  max mem: 593
Epoch: [3]  [ 300/1509]  eta: 0:01:09  lr: 0.000001  loss: 0.5435 (0.6107)  labels_encoder: 0.5435 (0.6107)  labels_encoder_unscaled: 0.5435 (0.6107)  time: 0.0510  data: 0.0241  max mem: 593
Epoch: [3]  [ 350/1509]  eta: 0:01:05  lr: 0.000001  loss: 0.5284 (0.6068)  labels_encoder: 0.5284 (0.6068)  labels_encoder_unscaled: 0.5284 (0.6068)  time: 0.0515  data: 0.0242  max mem: 593
Epoch: [3]  [ 400/1509]  eta: 0:01:01  lr: 0.000001  loss: 0.6179 (0.6065)  labels_encoder: 0.6179 (0.6065)  labels_encoder_unscaled: 0.6179 (0.6065)  time: 0.0484  data: 0.0165  max mem: 593
Epoch: [3]  [ 450/1509]  eta: 0:00:58  lr: 0.000001  loss: 0.6487 (0.6078)  labels_encoder: 0.6487 (0.6078)  labels_encoder_unscaled: 0.6487 (0.6078)  time: 0.0503  data: 0.0186  max mem: 593
Epoch: [3]  [ 500/1509]  eta: 0:00:54  lr: 0.000001  loss: 0.6013 (0.6081)  labels_encoder: 0.6013 (0.6081)  labels_encoder_unscaled: 0.6013 (0.6081)  time: 0.0500  data: 0.0177  max mem: 593
Epoch: [3]  [ 550/1509]  eta: 0:00:51  lr: 0.000001  loss: 0.5375 (0.6043)  labels_encoder: 0.5375 (0.6043)  labels_encoder_unscaled: 0.5375 (0.6043)  time: 0.0496  data: 0.0216  max mem: 593
Epoch: [3]  [ 600/1509]  eta: 0:00:48  lr: 0.000001  loss: 0.5929 (0.6044)  labels_encoder: 0.5929 (0.6044)  labels_encoder_unscaled: 0.5929 (0.6044)  time: 0.0488  data: 0.0215  max mem: 593
Epoch: [3]  [ 650/1509]  eta: 0:00:45  lr: 0.000001  loss: 0.5699 (0.6035)  labels_encoder: 0.5699 (0.6035)  labels_encoder_unscaled: 0.5699 (0.6035)  time: 0.0538  data: 0.0270  max mem: 593
Epoch: [3]  [ 700/1509]  eta: 0:00:42  lr: 0.000001  loss: 0.6018 (0.6027)  labels_encoder: 0.6018 (0.6027)  labels_encoder_unscaled: 0.6018 (0.6027)  time: 0.0509  data: 0.0208  max mem: 593
Epoch: [3]  [ 750/1509]  eta: 0:00:40  lr: 0.000001  loss: 0.5570 (0.6012)  labels_encoder: 0.5570 (0.6012)  labels_encoder_unscaled: 0.5570 (0.6012)  time: 0.0499  data: 0.0217  max mem: 593
Epoch: [3]  [ 800/1509]  eta: 0:00:37  lr: 0.000001  loss: 0.5646 (0.6008)  labels_encoder: 0.5646 (0.6008)  labels_encoder_unscaled: 0.5646 (0.6008)  time: 0.0532  data: 0.0241  max mem: 593
Epoch: [3]  [ 850/1509]  eta: 0:00:34  lr: 0.000001  loss: 0.5897 (0.6002)  labels_encoder: 0.5897 (0.6002)  labels_encoder_unscaled: 0.5897 (0.6002)  time: 0.0481  data: 0.0202  max mem: 593
Epoch: [3]  [ 900/1509]  eta: 0:00:31  lr: 0.000001  loss: 0.5467 (0.6001)  labels_encoder: 0.5467 (0.6001)  labels_encoder_unscaled: 0.5467 (0.6001)  time: 0.0501  data: 0.0217  max mem: 593
Epoch: [3]  [ 950/1509]  eta: 0:00:29  lr: 0.000001  loss: 0.6203 (0.6003)  labels_encoder: 0.6203 (0.6003)  labels_encoder_unscaled: 0.6203 (0.6003)  time: 0.0484  data: 0.0202  max mem: 593
Epoch: [3]  [1000/1509]  eta: 0:00:26  lr: 0.000001  loss: 0.5777 (0.6000)  labels_encoder: 0.5777 (0.6000)  labels_encoder_unscaled: 0.5777 (0.6000)  time: 0.0525  data: 0.0227  max mem: 593
Epoch: [3]  [1050/1509]  eta: 0:00:23  lr: 0.000001  loss: 0.6038 (0.6002)  labels_encoder: 0.6038 (0.6002)  labels_encoder_unscaled: 0.6038 (0.6002)  time: 0.0496  data: 0.0214  max mem: 593
Epoch: [3]  [1100/1509]  eta: 0:00:21  lr: 0.000001  loss: 0.5827 (0.5998)  labels_encoder: 0.5827 (0.5998)  labels_encoder_unscaled: 0.5827 (0.5998)  time: 0.0502  data: 0.0227  max mem: 593
Epoch: [3]  [1150/1509]  eta: 0:00:18  lr: 0.000001  loss: 0.5695 (0.5982)  labels_encoder: 0.5695 (0.5982)  labels_encoder_unscaled: 0.5695 (0.5982)  time: 0.0492  data: 0.0190  max mem: 593
Epoch: [3]  [1200/1509]  eta: 0:00:15  lr: 0.000001  loss: 0.5570 (0.5978)  labels_encoder: 0.5570 (0.5978)  labels_encoder_unscaled: 0.5570 (0.5978)  time: 0.0510  data: 0.0217  max mem: 593
Epoch: [3]  [1250/1509]  eta: 0:00:13  lr: 0.000001  loss: 0.5945 (0.5974)  labels_encoder: 0.5945 (0.5974)  labels_encoder_unscaled: 0.5945 (0.5974)  time: 0.0482  data: 0.0210  max mem: 593
Epoch: [3]  [1300/1509]  eta: 0:00:10  lr: 0.000001  loss: 0.5551 (0.5963)  labels_encoder: 0.5551 (0.5963)  labels_encoder_unscaled: 0.5551 (0.5963)  time: 0.0489  data: 0.0222  max mem: 593
Epoch: [3]  [1350/1509]  eta: 0:00:08  lr: 0.000001  loss: 0.5604 (0.5963)  labels_encoder: 0.5604 (0.5963)  labels_encoder_unscaled: 0.5604 (0.5963)  time: 0.0542  data: 0.0262  max mem: 593
Epoch: [3]  [1400/1509]  eta: 0:00:05  lr: 0.000001  loss: 0.5876 (0.5963)  labels_encoder: 0.5876 (0.5963)  labels_encoder_unscaled: 0.5876 (0.5963)  time: 0.0506  data: 0.0223  max mem: 593
Epoch: [3]  [1450/1509]  eta: 0:00:03  lr: 0.000001  loss: 0.6024 (0.5963)  labels_encoder: 0.6024 (0.5963)  labels_encoder_unscaled: 0.6024 (0.5963)  time: 0.0501  data: 0.0215  max mem: 593
Epoch: [3]  [1500/1509]  eta: 0:00:00  lr: 0.000001  loss: 0.5455 (0.5946)  labels_encoder: 0.5455 (0.5946)  labels_encoder_unscaled: 0.5455 (0.5946)  time: 0.0474  data: 0.0181  max mem: 593
Epoch: [3]  [1508/1509]  eta: 0:00:00  lr: 0.000001  loss: 0.5242 (0.5942)  labels_encoder: 0.5242 (0.5942)  labels_encoder_unscaled: 0.5242 (0.5942)  time: 0.0463  data: 0.0200  max mem: 593
Epoch: [3] Total time: 0:01:17 (0.0515 s / it)
Averaged stats: lr: 0.000001  loss: 0.5242 (0.5942)  labels_encoder: 0.5242 (0.5942)  labels_encoder_unscaled: 0.5242 (0.5942)
Test:  [  0/559]  eta: 0:17:46  loss: 0.6048 (0.6048)  labels_encoder: 0.6048 (0.6048)  labels_encoder_unscaled: 0.6048 (0.6048)  time: 1.9074  data: 1.8892  max mem: 593
Test:  [ 50/559]  eta: 0:00:40  loss: 0.8144 (0.9024)  labels_encoder: 0.8144 (0.9024)  labels_encoder_unscaled: 0.8144 (0.9024)  time: 0.0381  data: 0.0187  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.5414 (0.8393)  labels_encoder: 0.5414 (0.8393)  labels_encoder_unscaled: 0.5414 (0.8393)  time: 0.0473  data: 0.0314  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5102 (0.8652)  labels_encoder: 0.5102 (0.8652)  labels_encoder_unscaled: 0.5102 (0.8652)  time: 0.0531  data: 0.0380  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.7533 (0.8072)  labels_encoder: 0.7533 (0.8072)  labels_encoder_unscaled: 0.7533 (0.8072)  time: 0.0517  data: 0.0351  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.8053 (0.9078)  labels_encoder: 0.8053 (0.9078)  labels_encoder_unscaled: 0.8053 (0.9078)  time: 0.0569  data: 0.0413  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.0647 (0.9629)  labels_encoder: 1.0647 (0.9629)  labels_encoder_unscaled: 1.0647 (0.9629)  time: 0.0499  data: 0.0341  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7442 (0.9812)  labels_encoder: 0.7442 (0.9812)  labels_encoder_unscaled: 0.7442 (0.9812)  time: 0.0494  data: 0.0336  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3450 (0.9560)  labels_encoder: 0.3450 (0.9560)  labels_encoder_unscaled: 0.3450 (0.9560)  time: 0.0488  data: 0.0327  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4005 (0.9321)  labels_encoder: 0.4005 (0.9321)  labels_encoder_unscaled: 0.4005 (0.9321)  time: 0.0497  data: 0.0338  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5909 (0.9157)  labels_encoder: 0.5909 (0.9157)  labels_encoder_unscaled: 0.5909 (0.9157)  time: 0.0502  data: 0.0341  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7652 (0.8923)  labels_encoder: 0.7652 (0.8923)  labels_encoder_unscaled: 0.7652 (0.8923)  time: 0.0512  data: 0.0356  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3414 (0.8861)  labels_encoder: 0.3414 (0.8861)  labels_encoder_unscaled: 0.3414 (0.8861)  time: 0.0481  data: 0.0328  max mem: 593
Test: Total time: 0:00:29 (0.0535 s / it)
Averaged stats: loss: 0.3414 (0.8861)  labels_encoder: 0.3414 (0.8861)  labels_encoder_unscaled: 0.3414 (0.8861)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_anet_features.pickle] mAP: 0.1294, mcAP: 0.8776

BaseballPitch: 0.0330
BasketballDunk: 0.1108
Billiards: 0.0050
CleanAndJerk: 0.4121
CliffDiving: 0.3986
CricketBowling: 0.0883
CricketShot: 0.0867
Diving: 0.0061
FrisbeeCatch: 0.1257
GolfSwing: 0.0607
HammerThrow: 0.1014
HighJump: 0.0377
JavelinThrow: 0.0874
LongJump: 0.3280
PoleVault: 0.1088
Shotput: 0.1345
SoccerPenalty: 0.0520
TennisSwing: 0.1918
ThrowDiscus: 0.0632
VolleyballSpiking: 0.1575
Epoch: [4]  [   0/1509]  eta: 0:47:09  lr: 0.000000  loss: 0.5451 (0.5451)  labels_encoder: 0.5451 (0.5451)  labels_encoder_unscaled: 0.5451 (0.5451)  time: 1.8749  data: 1.8444  max mem: 593
Epoch: [4]  [  50/1509]  eta: 0:02:03  lr: 0.000000  loss: 0.5291 (0.5545)  labels_encoder: 0.5291 (0.5545)  labels_encoder_unscaled: 0.5291 (0.5545)  time: 0.0500  data: 0.0149  max mem: 593
Epoch: [4]  [ 100/1509]  eta: 0:01:35  lr: 0.000000  loss: 0.5866 (0.5728)  labels_encoder: 0.5866 (0.5728)  labels_encoder_unscaled: 0.5866 (0.5728)  time: 0.0514  data: 0.0212  max mem: 593
Epoch: [4]  [ 150/1509]  eta: 0:01:23  lr: 0.000000  loss: 0.5969 (0.5770)  labels_encoder: 0.5969 (0.5770)  labels_encoder_unscaled: 0.5969 (0.5770)  time: 0.0456  data: 0.0126  max mem: 593
Epoch: [4]  [ 200/1509]  eta: 0:01:16  lr: 0.000000  loss: 0.5950 (0.5778)  labels_encoder: 0.5950 (0.5778)  labels_encoder_unscaled: 0.5950 (0.5778)  time: 0.0503  data: 0.0226  max mem: 593
Epoch: [4]  [ 250/1509]  eta: 0:01:11  lr: 0.000000  loss: 0.5902 (0.5792)  labels_encoder: 0.5902 (0.5792)  labels_encoder_unscaled: 0.5902 (0.5792)  time: 0.0518  data: 0.0249  max mem: 593
Epoch: [4]  [ 300/1509]  eta: 0:01:07  lr: 0.000000  loss: 0.5830 (0.5795)  labels_encoder: 0.5830 (0.5795)  labels_encoder_unscaled: 0.5830 (0.5795)  time: 0.0514  data: 0.0243  max mem: 593
Epoch: [4]  [ 350/1509]  eta: 0:01:03  lr: 0.000000  loss: 0.6008 (0.5826)  labels_encoder: 0.6008 (0.5826)  labels_encoder_unscaled: 0.6008 (0.5826)  time: 0.0494  data: 0.0233  max mem: 593
Epoch: [4]  [ 400/1509]  eta: 0:00:59  lr: 0.000000  loss: 0.5187 (0.5806)  labels_encoder: 0.5187 (0.5806)  labels_encoder_unscaled: 0.5187 (0.5806)  time: 0.0494  data: 0.0228  max mem: 593
Epoch: [4]  [ 450/1509]  eta: 0:00:56  lr: 0.000000  loss: 0.5206 (0.5805)  labels_encoder: 0.5206 (0.5805)  labels_encoder_unscaled: 0.5206 (0.5805)  time: 0.0536  data: 0.0270  max mem: 593
Epoch: [4]  [ 500/1509]  eta: 0:00:53  lr: 0.000000  loss: 0.6085 (0.5811)  labels_encoder: 0.6085 (0.5811)  labels_encoder_unscaled: 0.6085 (0.5811)  time: 0.0497  data: 0.0213  max mem: 593
Epoch: [4]  [ 550/1509]  eta: 0:00:50  lr: 0.000000  loss: 0.5450 (0.5840)  labels_encoder: 0.5450 (0.5840)  labels_encoder_unscaled: 0.5450 (0.5840)  time: 0.0498  data: 0.0215  max mem: 593
Epoch: [4]  [ 600/1509]  eta: 0:00:47  lr: 0.000000  loss: 0.5795 (0.5817)  labels_encoder: 0.5795 (0.5817)  labels_encoder_unscaled: 0.5795 (0.5817)  time: 0.0501  data: 0.0133  max mem: 593
Epoch: [4]  [ 650/1509]  eta: 0:00:45  lr: 0.000000  loss: 0.6067 (0.5816)  labels_encoder: 0.6067 (0.5816)  labels_encoder_unscaled: 0.6067 (0.5816)  time: 0.0480  data: 0.0157  max mem: 593
Epoch: [4]  [ 700/1509]  eta: 0:00:42  lr: 0.000000  loss: 0.5467 (0.5818)  labels_encoder: 0.5467 (0.5818)  labels_encoder_unscaled: 0.5467 (0.5818)  time: 0.0487  data: 0.0214  max mem: 593
Epoch: [4]  [ 750/1509]  eta: 0:00:39  lr: 0.000000  loss: 0.5725 (0.5830)  labels_encoder: 0.5725 (0.5830)  labels_encoder_unscaled: 0.5725 (0.5830)  time: 0.0498  data: 0.0224  max mem: 593
Epoch: [4]  [ 800/1509]  eta: 0:00:36  lr: 0.000000  loss: 0.5770 (0.5832)  labels_encoder: 0.5770 (0.5832)  labels_encoder_unscaled: 0.5770 (0.5832)  time: 0.0485  data: 0.0209  max mem: 593
Epoch: [4]  [ 850/1509]  eta: 0:00:34  lr: 0.000000  loss: 0.6124 (0.5844)  labels_encoder: 0.6124 (0.5844)  labels_encoder_unscaled: 0.6124 (0.5844)  time: 0.0503  data: 0.0220  max mem: 593
Epoch: [4]  [ 900/1509]  eta: 0:00:31  lr: 0.000000  loss: 0.6083 (0.5842)  labels_encoder: 0.6083 (0.5842)  labels_encoder_unscaled: 0.6083 (0.5842)  time: 0.0521  data: 0.0193  max mem: 593
Epoch: [4]  [ 950/1509]  eta: 0:00:28  lr: 0.000000  loss: 0.5400 (0.5849)  labels_encoder: 0.5400 (0.5849)  labels_encoder_unscaled: 0.5400 (0.5849)  time: 0.0495  data: 0.0209  max mem: 593
Epoch: [4]  [1000/1509]  eta: 0:00:26  lr: 0.000000  loss: 0.5770 (0.5835)  labels_encoder: 0.5770 (0.5835)  labels_encoder_unscaled: 0.5770 (0.5835)  time: 0.0492  data: 0.0206  max mem: 593
Epoch: [4]  [1050/1509]  eta: 0:00:23  lr: 0.000000  loss: 0.5793 (0.5845)  labels_encoder: 0.5793 (0.5845)  labels_encoder_unscaled: 0.5793 (0.5845)  time: 0.0490  data: 0.0173  max mem: 593
Epoch: [4]  [1100/1509]  eta: 0:00:20  lr: 0.000000  loss: 0.5789 (0.5850)  labels_encoder: 0.5789 (0.5850)  labels_encoder_unscaled: 0.5789 (0.5850)  time: 0.0497  data: 0.0217  max mem: 593
Epoch: [4]  [1150/1509]  eta: 0:00:18  lr: 0.000000  loss: 0.5675 (0.5847)  labels_encoder: 0.5675 (0.5847)  labels_encoder_unscaled: 0.5675 (0.5847)  time: 0.0494  data: 0.0206  max mem: 593
Epoch: [4]  [1200/1509]  eta: 0:00:15  lr: 0.000000  loss: 0.5908 (0.5844)  labels_encoder: 0.5908 (0.5844)  labels_encoder_unscaled: 0.5908 (0.5844)  time: 0.0493  data: 0.0187  max mem: 593
Epoch: [4]  [1250/1509]  eta: 0:00:13  lr: 0.000000  loss: 0.5500 (0.5841)  labels_encoder: 0.5500 (0.5841)  labels_encoder_unscaled: 0.5500 (0.5841)  time: 0.0480  data: 0.0199  max mem: 593
Epoch: [4]  [1300/1509]  eta: 0:00:10  lr: 0.000000  loss: 0.6278 (0.5843)  labels_encoder: 0.6278 (0.5843)  labels_encoder_unscaled: 0.6278 (0.5843)  time: 0.0514  data: 0.0225  max mem: 593
Epoch: [4]  [1350/1509]  eta: 0:00:08  lr: 0.000000  loss: 0.5864 (0.5837)  labels_encoder: 0.5864 (0.5837)  labels_encoder_unscaled: 0.5864 (0.5837)  time: 0.0457  data: 0.0081  max mem: 593
Epoch: [4]  [1400/1509]  eta: 0:00:05  lr: 0.000000  loss: 0.5305 (0.5842)  labels_encoder: 0.5305 (0.5842)  labels_encoder_unscaled: 0.5305 (0.5842)  time: 0.0463  data: 0.0173  max mem: 593
Epoch: [4]  [1450/1509]  eta: 0:00:03  lr: 0.000000  loss: 0.5758 (0.5840)  labels_encoder: 0.5758 (0.5840)  labels_encoder_unscaled: 0.5758 (0.5840)  time: 0.0480  data: 0.0212  max mem: 593
Epoch: [4]  [1500/1509]  eta: 0:00:00  lr: 0.000000  loss: 0.6126 (0.5848)  labels_encoder: 0.6126 (0.5848)  labels_encoder_unscaled: 0.6126 (0.5848)  time: 0.0487  data: 0.0219  max mem: 593
Epoch: [4]  [1508/1509]  eta: 0:00:00  lr: 0.000000  loss: 0.5700 (0.5845)  labels_encoder: 0.5700 (0.5845)  labels_encoder_unscaled: 0.5700 (0.5845)  time: 0.0492  data: 0.0222  max mem: 593
Epoch: [4] Total time: 0:01:17 (0.0511 s / it)
Averaged stats: lr: 0.000000  loss: 0.5700 (0.5845)  labels_encoder: 0.5700 (0.5845)  labels_encoder_unscaled: 0.5700 (0.5845)
Test:  [  0/559]  eta: 0:15:23  loss: 0.6323 (0.6323)  labels_encoder: 0.6323 (0.6323)  labels_encoder_unscaled: 0.6323 (0.6323)  time: 1.6515  data: 1.6326  max mem: 593
Test:  [ 50/559]  eta: 0:00:39  loss: 0.9304 (0.8861)  labels_encoder: 0.9304 (0.8861)  labels_encoder_unscaled: 0.9304 (0.8861)  time: 0.0440  data: 0.0256  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.4660 (0.8316)  labels_encoder: 0.4660 (0.8316)  labels_encoder_unscaled: 0.4660 (0.8316)  time: 0.0508  data: 0.0351  max mem: 593
Test:  [150/559]  eta: 0:00:23  loss: 0.4655 (0.8637)  labels_encoder: 0.4655 (0.8637)  labels_encoder_unscaled: 0.4655 (0.8637)  time: 0.0465  data: 0.0307  max mem: 593
Test:  [200/559]  eta: 0:00:19  loss: 0.5990 (0.8068)  labels_encoder: 0.5990 (0.8068)  labels_encoder_unscaled: 0.5990 (0.8068)  time: 0.0459  data: 0.0310  max mem: 593
Test:  [250/559]  eta: 0:00:16  loss: 0.8453 (0.9096)  labels_encoder: 0.8453 (0.9096)  labels_encoder_unscaled: 0.8453 (0.9096)  time: 0.0468  data: 0.0302  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.0778 (0.9660)  labels_encoder: 1.0778 (0.9660)  labels_encoder_unscaled: 1.0778 (0.9660)  time: 0.0489  data: 0.0335  max mem: 593
Test:  [350/559]  eta: 0:00:10  loss: 0.7719 (0.9808)  labels_encoder: 0.7719 (0.9808)  labels_encoder_unscaled: 0.7719 (0.9808)  time: 0.0468  data: 0.0310  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3685 (0.9563)  labels_encoder: 0.3685 (0.9563)  labels_encoder_unscaled: 0.3685 (0.9563)  time: 0.0479  data: 0.0321  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4388 (0.9344)  labels_encoder: 0.4388 (0.9344)  labels_encoder_unscaled: 0.4388 (0.9344)  time: 0.0496  data: 0.0337  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6305 (0.9168)  labels_encoder: 0.6305 (0.9168)  labels_encoder_unscaled: 0.6305 (0.9168)  time: 0.0487  data: 0.0331  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7431 (0.8928)  labels_encoder: 0.7431 (0.8928)  labels_encoder_unscaled: 0.7431 (0.8928)  time: 0.0484  data: 0.0334  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3331 (0.8865)  labels_encoder: 0.3331 (0.8865)  labels_encoder_unscaled: 0.3331 (0.8865)  time: 0.0451  data: 0.0302  max mem: 593
Test: Total time: 0:00:28 (0.0514 s / it)
Averaged stats: loss: 0.3331 (0.8865)  labels_encoder: 0.3331 (0.8865)  labels_encoder_unscaled: 0.3331 (0.8865)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_anet_features.pickle] mAP: 0.1300, mcAP: 0.8753

BaseballPitch: 0.0345
BasketballDunk: 0.0798
Billiards: 0.0050
CleanAndJerk: 0.4115
CliffDiving: 0.4049
CricketBowling: 0.0828
CricketShot: 0.0976
Diving: 0.0076
FrisbeeCatch: 0.1166
GolfSwing: 0.0656
HammerThrow: 0.1103
HighJump: 0.0449
JavelinThrow: 0.0887
LongJump: 0.3748
PoleVault: 0.1017
Shotput: 0.1356
SoccerPenalty: 0.0499
TennisSwing: 0.1931
ThrowDiscus: 0.0461
VolleyballSpiking: 0.1494
Training time 0:07:24
