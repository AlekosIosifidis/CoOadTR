Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:4
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1509]  eta: 1:17:15  lr: 0.000100  loss: 3.2833 (3.2833)  labels_encoder: 3.2833 (3.2833)  labels_encoder_unscaled: 3.2833 (3.2833)  time: 3.0718  data: 2.9077  max mem: 483
Epoch: [1]  [  50/1509]  eta: 0:02:29  lr: 0.000100  loss: 1.0031 (1.1032)  labels_encoder: 1.0031 (1.1032)  labels_encoder_unscaled: 1.0031 (1.1032)  time: 0.0448  data: 0.0096  max mem: 593
Epoch: [1]  [ 100/1509]  eta: 0:01:49  lr: 0.000100  loss: 0.9802 (1.0418)  labels_encoder: 0.9802 (1.0418)  labels_encoder_unscaled: 0.9802 (1.0418)  time: 0.0460  data: 0.0177  max mem: 593
Epoch: [1]  [ 150/1509]  eta: 0:01:32  lr: 0.000100  loss: 0.9494 (1.0186)  labels_encoder: 0.9494 (1.0186)  labels_encoder_unscaled: 0.9494 (1.0186)  time: 0.0488  data: 0.0201  max mem: 593
Epoch: [1]  [ 200/1509]  eta: 0:01:22  lr: 0.000100  loss: 0.8534 (0.9922)  labels_encoder: 0.8534 (0.9922)  labels_encoder_unscaled: 0.8534 (0.9922)  time: 0.0481  data: 0.0213  max mem: 593
Epoch: [1]  [ 250/1509]  eta: 0:01:16  lr: 0.000100  loss: 0.9000 (0.9765)  labels_encoder: 0.9000 (0.9765)  labels_encoder_unscaled: 0.9000 (0.9765)  time: 0.0473  data: 0.0095  max mem: 593
Epoch: [1]  [ 300/1509]  eta: 0:01:11  lr: 0.000100  loss: 0.8608 (0.9557)  labels_encoder: 0.8608 (0.9557)  labels_encoder_unscaled: 0.8608 (0.9557)  time: 0.0543  data: 0.0270  max mem: 593
Epoch: [1]  [ 350/1509]  eta: 0:01:06  lr: 0.000100  loss: 0.7548 (0.9333)  labels_encoder: 0.7548 (0.9333)  labels_encoder_unscaled: 0.7548 (0.9333)  time: 0.0499  data: 0.0203  max mem: 593
Epoch: [1]  [ 400/1509]  eta: 0:01:02  lr: 0.000100  loss: 0.7374 (0.9200)  labels_encoder: 0.7374 (0.9200)  labels_encoder_unscaled: 0.7374 (0.9200)  time: 0.0480  data: 0.0209  max mem: 593
Epoch: [1]  [ 450/1509]  eta: 0:00:58  lr: 0.000100  loss: 0.8395 (0.9123)  labels_encoder: 0.8395 (0.9123)  labels_encoder_unscaled: 0.8395 (0.9123)  time: 0.0499  data: 0.0190  max mem: 593
Epoch: [1]  [ 500/1509]  eta: 0:00:55  lr: 0.000100  loss: 0.8870 (0.9069)  labels_encoder: 0.8870 (0.9069)  labels_encoder_unscaled: 0.8870 (0.9069)  time: 0.0482  data: 0.0206  max mem: 593
Epoch: [1]  [ 550/1509]  eta: 0:00:52  lr: 0.000100  loss: 0.7686 (0.8980)  labels_encoder: 0.7686 (0.8980)  labels_encoder_unscaled: 0.7686 (0.8980)  time: 0.0508  data: 0.0152  max mem: 593
Epoch: [1]  [ 600/1509]  eta: 0:00:49  lr: 0.000100  loss: 0.7725 (0.8898)  labels_encoder: 0.7725 (0.8898)  labels_encoder_unscaled: 0.7725 (0.8898)  time: 0.0488  data: 0.0212  max mem: 593
Epoch: [1]  [ 650/1509]  eta: 0:00:45  lr: 0.000100  loss: 0.7115 (0.8827)  labels_encoder: 0.7115 (0.8827)  labels_encoder_unscaled: 0.7115 (0.8827)  time: 0.0488  data: 0.0214  max mem: 593
Epoch: [1]  [ 700/1509]  eta: 0:00:43  lr: 0.000100  loss: 0.7253 (0.8731)  labels_encoder: 0.7253 (0.8731)  labels_encoder_unscaled: 0.7253 (0.8731)  time: 0.0491  data: 0.0224  max mem: 593
Epoch: [1]  [ 750/1509]  eta: 0:00:40  lr: 0.000100  loss: 0.7360 (0.8675)  labels_encoder: 0.7360 (0.8675)  labels_encoder_unscaled: 0.7360 (0.8675)  time: 0.0475  data: 0.0205  max mem: 593
Epoch: [1]  [ 800/1509]  eta: 0:00:37  lr: 0.000100  loss: 0.6776 (0.8607)  labels_encoder: 0.6776 (0.8607)  labels_encoder_unscaled: 0.6776 (0.8607)  time: 0.0476  data: 0.0205  max mem: 593
Epoch: [1]  [ 850/1509]  eta: 0:00:34  lr: 0.000100  loss: 0.7511 (0.8566)  labels_encoder: 0.7511 (0.8566)  labels_encoder_unscaled: 0.7511 (0.8566)  time: 0.0464  data: 0.0187  max mem: 593
Epoch: [1]  [ 900/1509]  eta: 0:00:31  lr: 0.000100  loss: 0.6761 (0.8508)  labels_encoder: 0.6761 (0.8508)  labels_encoder_unscaled: 0.6761 (0.8508)  time: 0.0482  data: 0.0208  max mem: 593
Epoch: [1]  [ 950/1509]  eta: 0:00:29  lr: 0.000100  loss: 0.7686 (0.8455)  labels_encoder: 0.7686 (0.8455)  labels_encoder_unscaled: 0.7686 (0.8455)  time: 0.0479  data: 0.0211  max mem: 593
Epoch: [1]  [1000/1509]  eta: 0:00:26  lr: 0.000100  loss: 0.7399 (0.8413)  labels_encoder: 0.7399 (0.8413)  labels_encoder_unscaled: 0.7399 (0.8413)  time: 0.0481  data: 0.0220  max mem: 593
Epoch: [1]  [1050/1509]  eta: 0:00:23  lr: 0.000100  loss: 0.7095 (0.8384)  labels_encoder: 0.7095 (0.8384)  labels_encoder_unscaled: 0.7095 (0.8384)  time: 0.0484  data: 0.0215  max mem: 593
Epoch: [1]  [1100/1509]  eta: 0:00:21  lr: 0.000100  loss: 0.7268 (0.8336)  labels_encoder: 0.7268 (0.8336)  labels_encoder_unscaled: 0.7268 (0.8336)  time: 0.0461  data: 0.0173  max mem: 593
Epoch: [1]  [1150/1509]  eta: 0:00:18  lr: 0.000100  loss: 0.6946 (0.8277)  labels_encoder: 0.6946 (0.8277)  labels_encoder_unscaled: 0.6946 (0.8277)  time: 0.0484  data: 0.0213  max mem: 593
Epoch: [1]  [1200/1509]  eta: 0:00:15  lr: 0.000100  loss: 0.6275 (0.8217)  labels_encoder: 0.6275 (0.8217)  labels_encoder_unscaled: 0.6275 (0.8217)  time: 0.0483  data: 0.0211  max mem: 593
Epoch: [1]  [1250/1509]  eta: 0:00:13  lr: 0.000100  loss: 0.6635 (0.8173)  labels_encoder: 0.6635 (0.8173)  labels_encoder_unscaled: 0.6635 (0.8173)  time: 0.0489  data: 0.0217  max mem: 593
Epoch: [1]  [1300/1509]  eta: 0:00:10  lr: 0.000100  loss: 0.7255 (0.8133)  labels_encoder: 0.7255 (0.8133)  labels_encoder_unscaled: 0.7255 (0.8133)  time: 0.0494  data: 0.0222  max mem: 593
Epoch: [1]  [1350/1509]  eta: 0:00:08  lr: 0.000100  loss: 0.6238 (0.8088)  labels_encoder: 0.6238 (0.8088)  labels_encoder_unscaled: 0.6238 (0.8088)  time: 0.0496  data: 0.0156  max mem: 593
Epoch: [1]  [1400/1509]  eta: 0:00:05  lr: 0.000100  loss: 0.6269 (0.8039)  labels_encoder: 0.6269 (0.8039)  labels_encoder_unscaled: 0.6269 (0.8039)  time: 0.0479  data: 0.0199  max mem: 593
Epoch: [1]  [1450/1509]  eta: 0:00:02  lr: 0.000100  loss: 0.6838 (0.8004)  labels_encoder: 0.6838 (0.8004)  labels_encoder_unscaled: 0.6838 (0.8004)  time: 0.0486  data: 0.0211  max mem: 593
Epoch: [1]  [1500/1509]  eta: 0:00:00  lr: 0.000100  loss: 0.6742 (0.7970)  labels_encoder: 0.6742 (0.7970)  labels_encoder_unscaled: 0.6742 (0.7970)  time: 0.0480  data: 0.0212  max mem: 593
Epoch: [1]  [1508/1509]  eta: 0:00:00  lr: 0.000100  loss: 0.6742 (0.7959)  labels_encoder: 0.6742 (0.7959)  labels_encoder_unscaled: 0.6742 (0.7959)  time: 0.0463  data: 0.0162  max mem: 593
Epoch: [1] Total time: 0:01:16 (0.0509 s / it)
Averaged stats: lr: 0.000100  loss: 0.6742 (0.7959)  labels_encoder: 0.6742 (0.7959)  labels_encoder_unscaled: 0.6742 (0.7959)
Test:  [  0/559]  eta: 0:15:01  loss: 0.5808 (0.5808)  labels_encoder: 0.5808 (0.5808)  labels_encoder_unscaled: 0.5808 (0.5808)  time: 1.6123  data: 1.5936  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 1.0936 (0.9388)  labels_encoder: 1.0936 (0.9388)  labels_encoder_unscaled: 1.0936 (0.9388)  time: 0.0506  data: 0.0347  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.4255 (0.8554)  labels_encoder: 0.4255 (0.8554)  labels_encoder_unscaled: 0.4255 (0.8554)  time: 0.0489  data: 0.0330  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.7138 (0.8891)  labels_encoder: 0.7138 (0.8891)  labels_encoder_unscaled: 0.7138 (0.8891)  time: 0.0600  data: 0.0443  max mem: 593
Test:  [200/559]  eta: 0:00:21  loss: 0.6271 (0.8223)  labels_encoder: 0.6271 (0.8223)  labels_encoder_unscaled: 0.6271 (0.8223)  time: 0.0490  data: 0.0330  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7378 (0.9461)  labels_encoder: 0.7378 (0.9461)  labels_encoder_unscaled: 0.7378 (0.9461)  time: 0.0499  data: 0.0338  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.0351 (1.0114)  labels_encoder: 1.0351 (1.0114)  labels_encoder_unscaled: 1.0351 (1.0114)  time: 0.0490  data: 0.0331  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.6897 (1.0332)  labels_encoder: 0.6897 (1.0332)  labels_encoder_unscaled: 0.6897 (1.0332)  time: 0.0488  data: 0.0329  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3840 (1.0022)  labels_encoder: 0.3840 (1.0022)  labels_encoder_unscaled: 0.3840 (1.0022)  time: 0.0517  data: 0.0359  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4533 (0.9762)  labels_encoder: 0.4533 (0.9762)  labels_encoder_unscaled: 0.4533 (0.9762)  time: 0.0541  data: 0.0383  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6816 (0.9600)  labels_encoder: 0.6816 (0.9600)  labels_encoder_unscaled: 0.6816 (0.9600)  time: 0.0488  data: 0.0330  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6552 (0.9329)  labels_encoder: 0.6552 (0.9329)  labels_encoder_unscaled: 0.6552 (0.9329)  time: 0.0489  data: 0.0324  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4134 (0.9266)  labels_encoder: 0.4134 (0.9266)  labels_encoder_unscaled: 0.4134 (0.9266)  time: 0.0463  data: 0.0303  max mem: 593
Test: Total time: 0:00:29 (0.0536 s / it)
Averaged stats: loss: 0.4134 (0.9266)  labels_encoder: 0.4134 (0.9266)  labels_encoder_unscaled: 0.4134 (0.9266)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1150, mcAP: 0.8548

BaseballPitch: 0.0165
BasketballDunk: 0.0809
Billiards: 0.0040
CleanAndJerk: 0.3870
CliffDiving: 0.4841
CricketBowling: 0.0437
CricketShot: 0.0559
Diving: 0.0107
FrisbeeCatch: 0.0998
GolfSwing: 0.0375
HammerThrow: 0.0466
HighJump: 0.0158
JavelinThrow: 0.0748
LongJump: 0.3324
PoleVault: 0.1033
Shotput: 0.1212
SoccerPenalty: 0.0377
TennisSwing: 0.1956
ThrowDiscus: 0.0150
VolleyballSpiking: 0.1365
Epoch: [2]  [   0/1509]  eta: 0:42:13  lr: 0.000010  loss: 0.7397 (0.7397)  labels_encoder: 0.7397 (0.7397)  labels_encoder_unscaled: 0.7397 (0.7397)  time: 1.6789  data: 1.6419  max mem: 593
Epoch: [2]  [  50/1509]  eta: 0:02:09  lr: 0.000010  loss: 0.7002 (0.6747)  labels_encoder: 0.7002 (0.6747)  labels_encoder_unscaled: 0.7002 (0.6747)  time: 0.0615  data: 0.0226  max mem: 593
Epoch: [2]  [ 100/1509]  eta: 0:01:37  lr: 0.000010  loss: 0.6331 (0.6632)  labels_encoder: 0.6331 (0.6632)  labels_encoder_unscaled: 0.6331 (0.6632)  time: 0.0556  data: 0.0275  max mem: 593
Epoch: [2]  [ 150/1509]  eta: 0:01:25  lr: 0.000010  loss: 0.6023 (0.6598)  labels_encoder: 0.6023 (0.6598)  labels_encoder_unscaled: 0.6023 (0.6598)  time: 0.0472  data: 0.0198  max mem: 593
Epoch: [2]  [ 200/1509]  eta: 0:01:18  lr: 0.000010  loss: 0.6124 (0.6657)  labels_encoder: 0.6124 (0.6657)  labels_encoder_unscaled: 0.6124 (0.6657)  time: 0.0492  data: 0.0221  max mem: 593
Epoch: [2]  [ 250/1509]  eta: 0:01:12  lr: 0.000010  loss: 0.6222 (0.6657)  labels_encoder: 0.6222 (0.6657)  labels_encoder_unscaled: 0.6222 (0.6657)  time: 0.0485  data: 0.0216  max mem: 593
Epoch: [2]  [ 300/1509]  eta: 0:01:07  lr: 0.000010  loss: 0.5935 (0.6611)  labels_encoder: 0.5935 (0.6611)  labels_encoder_unscaled: 0.5935 (0.6611)  time: 0.0487  data: 0.0215  max mem: 593
Epoch: [2]  [ 350/1509]  eta: 0:01:03  lr: 0.000010  loss: 0.6363 (0.6588)  labels_encoder: 0.6363 (0.6588)  labels_encoder_unscaled: 0.6363 (0.6588)  time: 0.0499  data: 0.0227  max mem: 593
Epoch: [2]  [ 400/1509]  eta: 0:00:59  lr: 0.000010  loss: 0.6036 (0.6540)  labels_encoder: 0.6036 (0.6540)  labels_encoder_unscaled: 0.6036 (0.6540)  time: 0.0479  data: 0.0196  max mem: 593
Epoch: [2]  [ 450/1509]  eta: 0:00:56  lr: 0.000010  loss: 0.5990 (0.6490)  labels_encoder: 0.5990 (0.6490)  labels_encoder_unscaled: 0.5990 (0.6490)  time: 0.0475  data: 0.0191  max mem: 593
Epoch: [2]  [ 500/1509]  eta: 0:00:53  lr: 0.000010  loss: 0.6214 (0.6479)  labels_encoder: 0.6214 (0.6479)  labels_encoder_unscaled: 0.6214 (0.6479)  time: 0.0479  data: 0.0197  max mem: 593
Epoch: [2]  [ 550/1509]  eta: 0:00:50  lr: 0.000010  loss: 0.5684 (0.6445)  labels_encoder: 0.5684 (0.6445)  labels_encoder_unscaled: 0.5684 (0.6445)  time: 0.0479  data: 0.0195  max mem: 593
Epoch: [2]  [ 600/1509]  eta: 0:00:47  lr: 0.000010  loss: 0.5971 (0.6420)  labels_encoder: 0.5971 (0.6420)  labels_encoder_unscaled: 0.5971 (0.6420)  time: 0.0491  data: 0.0215  max mem: 593
Epoch: [2]  [ 650/1509]  eta: 0:00:44  lr: 0.000010  loss: 0.5713 (0.6403)  labels_encoder: 0.5713 (0.6403)  labels_encoder_unscaled: 0.5713 (0.6403)  time: 0.0457  data: 0.0173  max mem: 593
Epoch: [2]  [ 700/1509]  eta: 0:00:41  lr: 0.000010  loss: 0.6284 (0.6387)  labels_encoder: 0.6284 (0.6387)  labels_encoder_unscaled: 0.6284 (0.6387)  time: 0.0544  data: 0.0267  max mem: 593
Epoch: [2]  [ 750/1509]  eta: 0:00:39  lr: 0.000010  loss: 0.5892 (0.6377)  labels_encoder: 0.5892 (0.6377)  labels_encoder_unscaled: 0.5892 (0.6377)  time: 0.0483  data: 0.0214  max mem: 593
Epoch: [2]  [ 800/1509]  eta: 0:00:36  lr: 0.000010  loss: 0.6193 (0.6371)  labels_encoder: 0.6193 (0.6371)  labels_encoder_unscaled: 0.6193 (0.6371)  time: 0.0482  data: 0.0191  max mem: 593
Epoch: [2]  [ 850/1509]  eta: 0:00:33  lr: 0.000010  loss: 0.6614 (0.6365)  labels_encoder: 0.6614 (0.6365)  labels_encoder_unscaled: 0.6614 (0.6365)  time: 0.0503  data: 0.0221  max mem: 593
Epoch: [2]  [ 900/1509]  eta: 0:00:31  lr: 0.000010  loss: 0.6548 (0.6354)  labels_encoder: 0.6548 (0.6354)  labels_encoder_unscaled: 0.6548 (0.6354)  time: 0.0490  data: 0.0183  max mem: 593
Epoch: [2]  [ 950/1509]  eta: 0:00:28  lr: 0.000010  loss: 0.6234 (0.6335)  labels_encoder: 0.6234 (0.6335)  labels_encoder_unscaled: 0.6234 (0.6335)  time: 0.0481  data: 0.0212  max mem: 593
Epoch: [2]  [1000/1509]  eta: 0:00:25  lr: 0.000010  loss: 0.6210 (0.6327)  labels_encoder: 0.6210 (0.6327)  labels_encoder_unscaled: 0.6210 (0.6327)  time: 0.0515  data: 0.0250  max mem: 593
Epoch: [2]  [1050/1509]  eta: 0:00:23  lr: 0.000010  loss: 0.5900 (0.6315)  labels_encoder: 0.5900 (0.6315)  labels_encoder_unscaled: 0.5900 (0.6315)  time: 0.0511  data: 0.0247  max mem: 593
Epoch: [2]  [1100/1509]  eta: 0:00:20  lr: 0.000010  loss: 0.6226 (0.6308)  labels_encoder: 0.6226 (0.6308)  labels_encoder_unscaled: 0.6226 (0.6308)  time: 0.0477  data: 0.0203  max mem: 593
Epoch: [2]  [1150/1509]  eta: 0:00:18  lr: 0.000010  loss: 0.6191 (0.6292)  labels_encoder: 0.6191 (0.6292)  labels_encoder_unscaled: 0.6191 (0.6292)  time: 0.0475  data: 0.0203  max mem: 593
Epoch: [2]  [1200/1509]  eta: 0:00:15  lr: 0.000010  loss: 0.6157 (0.6279)  labels_encoder: 0.6157 (0.6279)  labels_encoder_unscaled: 0.6157 (0.6279)  time: 0.0484  data: 0.0211  max mem: 593
Epoch: [2]  [1250/1509]  eta: 0:00:13  lr: 0.000010  loss: 0.5992 (0.6265)  labels_encoder: 0.5992 (0.6265)  labels_encoder_unscaled: 0.5992 (0.6265)  time: 0.0472  data: 0.0170  max mem: 593
Epoch: [2]  [1300/1509]  eta: 0:00:10  lr: 0.000010  loss: 0.5836 (0.6255)  labels_encoder: 0.5836 (0.6255)  labels_encoder_unscaled: 0.5836 (0.6255)  time: 0.0475  data: 0.0203  max mem: 593
Epoch: [2]  [1350/1509]  eta: 0:00:07  lr: 0.000010  loss: 0.5709 (0.6243)  labels_encoder: 0.5709 (0.6243)  labels_encoder_unscaled: 0.5709 (0.6243)  time: 0.0487  data: 0.0218  max mem: 593
Epoch: [2]  [1400/1509]  eta: 0:00:05  lr: 0.000010  loss: 0.5908 (0.6231)  labels_encoder: 0.5908 (0.6231)  labels_encoder_unscaled: 0.5908 (0.6231)  time: 0.0611  data: 0.0291  max mem: 593
Epoch: [2]  [1450/1509]  eta: 0:00:02  lr: 0.000010  loss: 0.5787 (0.6222)  labels_encoder: 0.5787 (0.6222)  labels_encoder_unscaled: 0.5787 (0.6222)  time: 0.0474  data: 0.0193  max mem: 593
Epoch: [2]  [1500/1509]  eta: 0:00:00  lr: 0.000010  loss: 0.5658 (0.6215)  labels_encoder: 0.5658 (0.6215)  labels_encoder_unscaled: 0.5658 (0.6215)  time: 0.0511  data: 0.0193  max mem: 593
Epoch: [2]  [1508/1509]  eta: 0:00:00  lr: 0.000010  loss: 0.6436 (0.6216)  labels_encoder: 0.6436 (0.6216)  labels_encoder_unscaled: 0.6436 (0.6216)  time: 0.0459  data: 0.0145  max mem: 593
Epoch: [2] Total time: 0:01:16 (0.0505 s / it)
Averaged stats: lr: 0.000010  loss: 0.6436 (0.6216)  labels_encoder: 0.6436 (0.6216)  labels_encoder_unscaled: 0.6436 (0.6216)
Test:  [  0/559]  eta: 0:15:32  loss: 0.6279 (0.6279)  labels_encoder: 0.6279 (0.6279)  labels_encoder_unscaled: 0.6279 (0.6279)  time: 1.6677  data: 1.6488  max mem: 593
Test:  [ 50/559]  eta: 0:00:40  loss: 0.8282 (0.8936)  labels_encoder: 0.8282 (0.8936)  labels_encoder_unscaled: 0.8282 (0.8936)  time: 0.0506  data: 0.0337  max mem: 593
Test:  [100/559]  eta: 0:00:29  loss: 0.4270 (0.8331)  labels_encoder: 0.4270 (0.8331)  labels_encoder_unscaled: 0.4270 (0.8331)  time: 0.0476  data: 0.0317  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5501 (0.8685)  labels_encoder: 0.5501 (0.8685)  labels_encoder_unscaled: 0.5501 (0.8685)  time: 0.0488  data: 0.0338  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.7416 (0.8168)  labels_encoder: 0.7416 (0.8168)  labels_encoder_unscaled: 0.7416 (0.8168)  time: 0.0515  data: 0.0337  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7105 (0.9313)  labels_encoder: 0.7105 (0.9313)  labels_encoder_unscaled: 0.7105 (0.9313)  time: 0.0492  data: 0.0326  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.0428 (0.9748)  labels_encoder: 1.0428 (0.9748)  labels_encoder_unscaled: 1.0428 (0.9748)  time: 0.0479  data: 0.0316  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7094 (0.9913)  labels_encoder: 0.7094 (0.9913)  labels_encoder_unscaled: 0.7094 (0.9913)  time: 0.0494  data: 0.0336  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3703 (0.9657)  labels_encoder: 0.3703 (0.9657)  labels_encoder_unscaled: 0.3703 (0.9657)  time: 0.0497  data: 0.0338  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4139 (0.9439)  labels_encoder: 0.4139 (0.9439)  labels_encoder_unscaled: 0.4139 (0.9439)  time: 0.0484  data: 0.0326  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5921 (0.9270)  labels_encoder: 0.5921 (0.9270)  labels_encoder_unscaled: 0.5921 (0.9270)  time: 0.0495  data: 0.0333  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7246 (0.9016)  labels_encoder: 0.7246 (0.9016)  labels_encoder_unscaled: 0.7246 (0.9016)  time: 0.0470  data: 0.0312  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3668 (0.8954)  labels_encoder: 0.3668 (0.8954)  labels_encoder_unscaled: 0.3668 (0.8954)  time: 0.0452  data: 0.0299  max mem: 593
Test: Total time: 0:00:29 (0.0521 s / it)
Averaged stats: loss: 0.3668 (0.8954)  labels_encoder: 0.3668 (0.8954)  labels_encoder_unscaled: 0.3668 (0.8954)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1208, mcAP: 0.8722

BaseballPitch: 0.0292
BasketballDunk: 0.0939
Billiards: 0.0047
CleanAndJerk: 0.4176
CliffDiving: 0.3186
CricketBowling: 0.0966
CricketShot: 0.0999
Diving: 0.0047
FrisbeeCatch: 0.1407
GolfSwing: 0.0551
HammerThrow: 0.0822
HighJump: 0.0318
JavelinThrow: 0.0823
LongJump: 0.2845
PoleVault: 0.1151
Shotput: 0.1405
SoccerPenalty: 0.0460
TennisSwing: 0.1985
ThrowDiscus: 0.0344
VolleyballSpiking: 0.1398
Epoch: [3]  [   0/1509]  eta: 0:46:36  lr: 0.000001  loss: 0.8228 (0.8228)  labels_encoder: 0.8228 (0.8228)  labels_encoder_unscaled: 0.8228 (0.8228)  time: 1.8533  data: 1.8247  max mem: 593
Epoch: [3]  [  50/1509]  eta: 0:02:12  lr: 0.000001  loss: 0.5987 (0.6168)  labels_encoder: 0.5987 (0.6168)  labels_encoder_unscaled: 0.5987 (0.6168)  time: 0.0603  data: 0.0331  max mem: 593
Epoch: [3]  [ 100/1509]  eta: 0:01:40  lr: 0.000001  loss: 0.5709 (0.6129)  labels_encoder: 0.5709 (0.6129)  labels_encoder_unscaled: 0.5709 (0.6129)  time: 0.0510  data: 0.0214  max mem: 593
Epoch: [3]  [ 150/1509]  eta: 0:01:28  lr: 0.000001  loss: 0.6001 (0.6029)  labels_encoder: 0.6001 (0.6029)  labels_encoder_unscaled: 0.6001 (0.6029)  time: 0.0502  data: 0.0217  max mem: 593
Epoch: [3]  [ 200/1509]  eta: 0:01:20  lr: 0.000001  loss: 0.6146 (0.6040)  labels_encoder: 0.6146 (0.6040)  labels_encoder_unscaled: 0.6146 (0.6040)  time: 0.0439  data: 0.0093  max mem: 593
Epoch: [3]  [ 250/1509]  eta: 0:01:13  lr: 0.000001  loss: 0.5488 (0.5936)  labels_encoder: 0.5488 (0.5936)  labels_encoder_unscaled: 0.5488 (0.5936)  time: 0.0478  data: 0.0154  max mem: 593
Epoch: [3]  [ 300/1509]  eta: 0:01:08  lr: 0.000001  loss: 0.5297 (0.5915)  labels_encoder: 0.5297 (0.5915)  labels_encoder_unscaled: 0.5297 (0.5915)  time: 0.0497  data: 0.0225  max mem: 593
Epoch: [3]  [ 350/1509]  eta: 0:01:04  lr: 0.000001  loss: 0.5123 (0.5882)  labels_encoder: 0.5123 (0.5882)  labels_encoder_unscaled: 0.5123 (0.5882)  time: 0.0493  data: 0.0211  max mem: 593
Epoch: [3]  [ 400/1509]  eta: 0:01:00  lr: 0.000001  loss: 0.6072 (0.5887)  labels_encoder: 0.6072 (0.5887)  labels_encoder_unscaled: 0.6072 (0.5887)  time: 0.0493  data: 0.0169  max mem: 593
Epoch: [3]  [ 450/1509]  eta: 0:00:57  lr: 0.000001  loss: 0.6040 (0.5903)  labels_encoder: 0.6040 (0.5903)  labels_encoder_unscaled: 0.6040 (0.5903)  time: 0.0480  data: 0.0212  max mem: 593
Epoch: [3]  [ 500/1509]  eta: 0:00:54  lr: 0.000001  loss: 0.5943 (0.5913)  labels_encoder: 0.5943 (0.5913)  labels_encoder_unscaled: 0.5943 (0.5913)  time: 0.0483  data: 0.0215  max mem: 593
Epoch: [3]  [ 550/1509]  eta: 0:00:50  lr: 0.000001  loss: 0.5176 (0.5882)  labels_encoder: 0.5176 (0.5882)  labels_encoder_unscaled: 0.5176 (0.5882)  time: 0.0460  data: 0.0133  max mem: 593
Epoch: [3]  [ 600/1509]  eta: 0:00:47  lr: 0.000001  loss: 0.5804 (0.5886)  labels_encoder: 0.5804 (0.5886)  labels_encoder_unscaled: 0.5804 (0.5886)  time: 0.0480  data: 0.0206  max mem: 593
Epoch: [3]  [ 650/1509]  eta: 0:00:45  lr: 0.000001  loss: 0.5630 (0.5884)  labels_encoder: 0.5630 (0.5884)  labels_encoder_unscaled: 0.5630 (0.5884)  time: 0.0482  data: 0.0213  max mem: 593
Epoch: [3]  [ 700/1509]  eta: 0:00:42  lr: 0.000001  loss: 0.5960 (0.5880)  labels_encoder: 0.5960 (0.5880)  labels_encoder_unscaled: 0.5960 (0.5880)  time: 0.0477  data: 0.0192  max mem: 593
Epoch: [3]  [ 750/1509]  eta: 0:00:39  lr: 0.000001  loss: 0.5562 (0.5873)  labels_encoder: 0.5562 (0.5873)  labels_encoder_unscaled: 0.5562 (0.5873)  time: 0.0477  data: 0.0204  max mem: 593
Epoch: [3]  [ 800/1509]  eta: 0:00:36  lr: 0.000001  loss: 0.5647 (0.5872)  labels_encoder: 0.5647 (0.5872)  labels_encoder_unscaled: 0.5647 (0.5872)  time: 0.0482  data: 0.0205  max mem: 593
Epoch: [3]  [ 850/1509]  eta: 0:00:33  lr: 0.000001  loss: 0.5836 (0.5870)  labels_encoder: 0.5836 (0.5870)  labels_encoder_unscaled: 0.5836 (0.5870)  time: 0.0485  data: 0.0205  max mem: 593
Epoch: [3]  [ 900/1509]  eta: 0:00:31  lr: 0.000001  loss: 0.5386 (0.5872)  labels_encoder: 0.5386 (0.5872)  labels_encoder_unscaled: 0.5386 (0.5872)  time: 0.0478  data: 0.0196  max mem: 593
Epoch: [3]  [ 950/1509]  eta: 0:00:28  lr: 0.000001  loss: 0.6016 (0.5876)  labels_encoder: 0.6016 (0.5876)  labels_encoder_unscaled: 0.6016 (0.5876)  time: 0.0489  data: 0.0217  max mem: 593
Epoch: [3]  [1000/1509]  eta: 0:00:25  lr: 0.000001  loss: 0.5723 (0.5876)  labels_encoder: 0.5723 (0.5876)  labels_encoder_unscaled: 0.5723 (0.5876)  time: 0.0478  data: 0.0208  max mem: 593
Epoch: [3]  [1050/1509]  eta: 0:00:23  lr: 0.000001  loss: 0.6023 (0.5882)  labels_encoder: 0.6023 (0.5882)  labels_encoder_unscaled: 0.6023 (0.5882)  time: 0.0480  data: 0.0205  max mem: 593
Epoch: [3]  [1100/1509]  eta: 0:00:20  lr: 0.000001  loss: 0.5632 (0.5880)  labels_encoder: 0.5632 (0.5880)  labels_encoder_unscaled: 0.5632 (0.5880)  time: 0.0498  data: 0.0220  max mem: 593
Epoch: [3]  [1150/1509]  eta: 0:00:18  lr: 0.000001  loss: 0.5685 (0.5867)  labels_encoder: 0.5685 (0.5867)  labels_encoder_unscaled: 0.5685 (0.5867)  time: 0.0473  data: 0.0146  max mem: 593
Epoch: [3]  [1200/1509]  eta: 0:00:15  lr: 0.000001  loss: 0.5532 (0.5865)  labels_encoder: 0.5532 (0.5865)  labels_encoder_unscaled: 0.5532 (0.5865)  time: 0.0524  data: 0.0192  max mem: 593
Epoch: [3]  [1250/1509]  eta: 0:00:13  lr: 0.000001  loss: 0.5928 (0.5863)  labels_encoder: 0.5928 (0.5863)  labels_encoder_unscaled: 0.5928 (0.5863)  time: 0.0479  data: 0.0200  max mem: 593
Epoch: [3]  [1300/1509]  eta: 0:00:10  lr: 0.000001  loss: 0.5629 (0.5855)  labels_encoder: 0.5629 (0.5855)  labels_encoder_unscaled: 0.5629 (0.5855)  time: 0.0499  data: 0.0178  max mem: 593
Epoch: [3]  [1350/1509]  eta: 0:00:08  lr: 0.000001  loss: 0.5518 (0.5857)  labels_encoder: 0.5518 (0.5857)  labels_encoder_unscaled: 0.5518 (0.5857)  time: 0.0503  data: 0.0220  max mem: 593
Epoch: [3]  [1400/1509]  eta: 0:00:05  lr: 0.000001  loss: 0.5780 (0.5859)  labels_encoder: 0.5780 (0.5859)  labels_encoder_unscaled: 0.5780 (0.5859)  time: 0.0452  data: 0.0090  max mem: 593
Epoch: [3]  [1450/1509]  eta: 0:00:02  lr: 0.000001  loss: 0.5986 (0.5862)  labels_encoder: 0.5986 (0.5862)  labels_encoder_unscaled: 0.5986 (0.5862)  time: 0.0488  data: 0.0198  max mem: 593
Epoch: [3]  [1500/1509]  eta: 0:00:00  lr: 0.000001  loss: 0.5389 (0.5846)  labels_encoder: 0.5389 (0.5846)  labels_encoder_unscaled: 0.5389 (0.5846)  time: 0.0464  data: 0.0147  max mem: 593
Epoch: [3]  [1508/1509]  eta: 0:00:00  lr: 0.000001  loss: 0.5300 (0.5843)  labels_encoder: 0.5300 (0.5843)  labels_encoder_unscaled: 0.5300 (0.5843)  time: 0.0447  data: 0.0131  max mem: 593
Epoch: [3] Total time: 0:01:16 (0.0504 s / it)
Averaged stats: lr: 0.000001  loss: 0.5300 (0.5843)  labels_encoder: 0.5300 (0.5843)  labels_encoder_unscaled: 0.5300 (0.5843)
Test:  [  0/559]  eta: 0:17:11  loss: 0.6753 (0.6753)  labels_encoder: 0.6753 (0.6753)  labels_encoder_unscaled: 0.6753 (0.6753)  time: 1.8459  data: 1.8286  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.9069 (0.8891)  labels_encoder: 0.9069 (0.8891)  labels_encoder_unscaled: 0.9069 (0.8891)  time: 0.0488  data: 0.0315  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.5961 (0.8366)  labels_encoder: 0.5961 (0.8366)  labels_encoder_unscaled: 0.5961 (0.8366)  time: 0.0480  data: 0.0290  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5099 (0.8680)  labels_encoder: 0.5099 (0.8680)  labels_encoder_unscaled: 0.5099 (0.8680)  time: 0.0456  data: 0.0284  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.7547 (0.8113)  labels_encoder: 0.7547 (0.8113)  labels_encoder_unscaled: 0.7547 (0.8113)  time: 0.0501  data: 0.0343  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7186 (0.9128)  labels_encoder: 0.7186 (0.9128)  labels_encoder_unscaled: 0.7186 (0.9128)  time: 0.0494  data: 0.0334  max mem: 593
Test:  [300/559]  eta: 0:00:13  loss: 1.1266 (0.9658)  labels_encoder: 1.1266 (0.9658)  labels_encoder_unscaled: 1.1266 (0.9658)  time: 0.0479  data: 0.0294  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7214 (0.9833)  labels_encoder: 0.7214 (0.9833)  labels_encoder_unscaled: 0.7214 (0.9833)  time: 0.0488  data: 0.0332  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3519 (0.9573)  labels_encoder: 0.3519 (0.9573)  labels_encoder_unscaled: 0.3519 (0.9573)  time: 0.0470  data: 0.0313  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3808 (0.9334)  labels_encoder: 0.3808 (0.9334)  labels_encoder_unscaled: 0.3808 (0.9334)  time: 0.0525  data: 0.0340  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5479 (0.9172)  labels_encoder: 0.5479 (0.9172)  labels_encoder_unscaled: 0.5479 (0.9172)  time: 0.0477  data: 0.0317  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7775 (0.8937)  labels_encoder: 0.7775 (0.8937)  labels_encoder_unscaled: 0.7775 (0.8937)  time: 0.0468  data: 0.0300  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3377 (0.8876)  labels_encoder: 0.3377 (0.8876)  labels_encoder_unscaled: 0.3377 (0.8876)  time: 0.0461  data: 0.0288  max mem: 593
Test: Total time: 0:00:28 (0.0519 s / it)
Averaged stats: loss: 0.3377 (0.8876)  labels_encoder: 0.3377 (0.8876)  labels_encoder_unscaled: 0.3377 (0.8876)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1302, mcAP: 0.8780

BaseballPitch: 0.0361
BasketballDunk: 0.1170
Billiards: 0.0051
CleanAndJerk: 0.4155
CliffDiving: 0.3763
CricketBowling: 0.0862
CricketShot: 0.0969
Diving: 0.0060
FrisbeeCatch: 0.1384
GolfSwing: 0.0573
HammerThrow: 0.1076
HighJump: 0.0353
JavelinThrow: 0.0754
LongJump: 0.3354
PoleVault: 0.1136
Shotput: 0.1374
SoccerPenalty: 0.0505
TennisSwing: 0.1985
ThrowDiscus: 0.0643
VolleyballSpiking: 0.1504
Epoch: [4]  [   0/1509]  eta: 0:51:36  lr: 0.000000  loss: 0.5358 (0.5358)  labels_encoder: 0.5358 (0.5358)  labels_encoder_unscaled: 0.5358 (0.5358)  time: 2.0523  data: 2.0200  max mem: 593
Epoch: [4]  [  50/1509]  eta: 0:02:05  lr: 0.000000  loss: 0.5260 (0.5476)  labels_encoder: 0.5260 (0.5476)  labels_encoder_unscaled: 0.5260 (0.5476)  time: 0.0404  data: 0.0002  max mem: 593
Epoch: [4]  [ 100/1509]  eta: 0:01:35  lr: 0.000000  loss: 0.5860 (0.5683)  labels_encoder: 0.5860 (0.5683)  labels_encoder_unscaled: 0.5860 (0.5683)  time: 0.0521  data: 0.0236  max mem: 593
Epoch: [4]  [ 150/1509]  eta: 0:01:22  lr: 0.000000  loss: 0.5854 (0.5725)  labels_encoder: 0.5854 (0.5725)  labels_encoder_unscaled: 0.5854 (0.5725)  time: 0.0468  data: 0.0129  max mem: 593
Epoch: [4]  [ 200/1509]  eta: 0:01:15  lr: 0.000000  loss: 0.5884 (0.5730)  labels_encoder: 0.5884 (0.5730)  labels_encoder_unscaled: 0.5884 (0.5730)  time: 0.0488  data: 0.0199  max mem: 593
Epoch: [4]  [ 250/1509]  eta: 0:01:10  lr: 0.000000  loss: 0.5880 (0.5744)  labels_encoder: 0.5880 (0.5744)  labels_encoder_unscaled: 0.5880 (0.5744)  time: 0.0497  data: 0.0225  max mem: 593
Epoch: [4]  [ 300/1509]  eta: 0:01:06  lr: 0.000000  loss: 0.5835 (0.5747)  labels_encoder: 0.5835 (0.5747)  labels_encoder_unscaled: 0.5835 (0.5747)  time: 0.0493  data: 0.0220  max mem: 593
Epoch: [4]  [ 350/1509]  eta: 0:01:02  lr: 0.000000  loss: 0.5958 (0.5774)  labels_encoder: 0.5958 (0.5774)  labels_encoder_unscaled: 0.5958 (0.5774)  time: 0.0462  data: 0.0184  max mem: 593
Epoch: [4]  [ 400/1509]  eta: 0:00:59  lr: 0.000000  loss: 0.5142 (0.5755)  labels_encoder: 0.5142 (0.5755)  labels_encoder_unscaled: 0.5142 (0.5755)  time: 0.0481  data: 0.0199  max mem: 593
Epoch: [4]  [ 450/1509]  eta: 0:00:55  lr: 0.000000  loss: 0.5147 (0.5752)  labels_encoder: 0.5147 (0.5752)  labels_encoder_unscaled: 0.5147 (0.5752)  time: 0.0484  data: 0.0202  max mem: 593
Epoch: [4]  [ 500/1509]  eta: 0:00:52  lr: 0.000000  loss: 0.5932 (0.5755)  labels_encoder: 0.5932 (0.5755)  labels_encoder_unscaled: 0.5932 (0.5755)  time: 0.0472  data: 0.0162  max mem: 593
Epoch: [4]  [ 550/1509]  eta: 0:00:49  lr: 0.000000  loss: 0.5460 (0.5782)  labels_encoder: 0.5460 (0.5782)  labels_encoder_unscaled: 0.5460 (0.5782)  time: 0.0493  data: 0.0154  max mem: 593
Epoch: [4]  [ 600/1509]  eta: 0:00:47  lr: 0.000000  loss: 0.5746 (0.5759)  labels_encoder: 0.5746 (0.5759)  labels_encoder_unscaled: 0.5746 (0.5759)  time: 0.0533  data: 0.0200  max mem: 593
Epoch: [4]  [ 650/1509]  eta: 0:00:44  lr: 0.000000  loss: 0.5931 (0.5759)  labels_encoder: 0.5931 (0.5759)  labels_encoder_unscaled: 0.5931 (0.5759)  time: 0.0496  data: 0.0190  max mem: 593
Epoch: [4]  [ 700/1509]  eta: 0:00:41  lr: 0.000000  loss: 0.5286 (0.5761)  labels_encoder: 0.5286 (0.5761)  labels_encoder_unscaled: 0.5286 (0.5761)  time: 0.0498  data: 0.0217  max mem: 593
Epoch: [4]  [ 750/1509]  eta: 0:00:39  lr: 0.000000  loss: 0.5558 (0.5774)  labels_encoder: 0.5558 (0.5774)  labels_encoder_unscaled: 0.5558 (0.5774)  time: 0.0490  data: 0.0209  max mem: 593
Epoch: [4]  [ 800/1509]  eta: 0:00:36  lr: 0.000000  loss: 0.5538 (0.5775)  labels_encoder: 0.5538 (0.5775)  labels_encoder_unscaled: 0.5538 (0.5775)  time: 0.0477  data: 0.0200  max mem: 593
Epoch: [4]  [ 850/1509]  eta: 0:00:33  lr: 0.000000  loss: 0.6032 (0.5785)  labels_encoder: 0.6032 (0.5785)  labels_encoder_unscaled: 0.6032 (0.5785)  time: 0.0502  data: 0.0217  max mem: 593
Epoch: [4]  [ 900/1509]  eta: 0:00:30  lr: 0.000000  loss: 0.5949 (0.5783)  labels_encoder: 0.5949 (0.5783)  labels_encoder_unscaled: 0.5949 (0.5783)  time: 0.0484  data: 0.0130  max mem: 593
Epoch: [4]  [ 950/1509]  eta: 0:00:28  lr: 0.000000  loss: 0.5324 (0.5790)  labels_encoder: 0.5324 (0.5790)  labels_encoder_unscaled: 0.5324 (0.5790)  time: 0.0456  data: 0.0145  max mem: 593
Epoch: [4]  [1000/1509]  eta: 0:00:25  lr: 0.000000  loss: 0.5729 (0.5777)  labels_encoder: 0.5729 (0.5777)  labels_encoder_unscaled: 0.5729 (0.5777)  time: 0.0496  data: 0.0222  max mem: 593
Epoch: [4]  [1050/1509]  eta: 0:00:23  lr: 0.000000  loss: 0.5704 (0.5786)  labels_encoder: 0.5704 (0.5786)  labels_encoder_unscaled: 0.5704 (0.5786)  time: 0.0502  data: 0.0240  max mem: 593
Epoch: [4]  [1100/1509]  eta: 0:00:20  lr: 0.000000  loss: 0.5847 (0.5791)  labels_encoder: 0.5847 (0.5791)  labels_encoder_unscaled: 0.5847 (0.5791)  time: 0.0488  data: 0.0221  max mem: 593
Epoch: [4]  [1150/1509]  eta: 0:00:18  lr: 0.000000  loss: 0.5596 (0.5789)  labels_encoder: 0.5596 (0.5789)  labels_encoder_unscaled: 0.5596 (0.5789)  time: 0.0470  data: 0.0157  max mem: 593
Epoch: [4]  [1200/1509]  eta: 0:00:15  lr: 0.000000  loss: 0.5794 (0.5787)  labels_encoder: 0.5794 (0.5787)  labels_encoder_unscaled: 0.5794 (0.5787)  time: 0.0473  data: 0.0170  max mem: 593
Epoch: [4]  [1250/1509]  eta: 0:00:13  lr: 0.000000  loss: 0.5273 (0.5783)  labels_encoder: 0.5273 (0.5783)  labels_encoder_unscaled: 0.5273 (0.5783)  time: 0.0483  data: 0.0200  max mem: 593
Epoch: [4]  [1300/1509]  eta: 0:00:10  lr: 0.000000  loss: 0.6179 (0.5784)  labels_encoder: 0.6179 (0.5784)  labels_encoder_unscaled: 0.6179 (0.5784)  time: 0.0491  data: 0.0207  max mem: 593
Epoch: [4]  [1350/1509]  eta: 0:00:08  lr: 0.000000  loss: 0.5693 (0.5778)  labels_encoder: 0.5693 (0.5778)  labels_encoder_unscaled: 0.5693 (0.5778)  time: 0.0487  data: 0.0163  max mem: 593
Epoch: [4]  [1400/1509]  eta: 0:00:05  lr: 0.000000  loss: 0.5347 (0.5784)  labels_encoder: 0.5347 (0.5784)  labels_encoder_unscaled: 0.5347 (0.5784)  time: 0.0471  data: 0.0187  max mem: 593
Epoch: [4]  [1450/1509]  eta: 0:00:02  lr: 0.000000  loss: 0.5538 (0.5782)  labels_encoder: 0.5538 (0.5782)  labels_encoder_unscaled: 0.5538 (0.5782)  time: 0.0477  data: 0.0194  max mem: 593
Epoch: [4]  [1500/1509]  eta: 0:00:00  lr: 0.000000  loss: 0.6010 (0.5789)  labels_encoder: 0.6010 (0.5789)  labels_encoder_unscaled: 0.6010 (0.5789)  time: 0.0469  data: 0.0190  max mem: 593
Epoch: [4]  [1508/1509]  eta: 0:00:00  lr: 0.000000  loss: 0.5713 (0.5787)  labels_encoder: 0.5713 (0.5787)  labels_encoder_unscaled: 0.5713 (0.5787)  time: 0.0458  data: 0.0181  max mem: 593
Epoch: [4] Total time: 0:01:16 (0.0504 s / it)
Averaged stats: lr: 0.000000  loss: 0.5713 (0.5787)  labels_encoder: 0.5713 (0.5787)  labels_encoder_unscaled: 0.5713 (0.5787)
Test:  [  0/559]  eta: 0:19:25  loss: 0.6484 (0.6484)  labels_encoder: 0.6484 (0.6484)  labels_encoder_unscaled: 0.6484 (0.6484)  time: 2.0852  data: 2.0680  max mem: 593
Test:  [ 50/559]  eta: 0:00:43  loss: 0.9371 (0.9129)  labels_encoder: 0.9371 (0.9129)  labels_encoder_unscaled: 0.9371 (0.9129)  time: 0.0511  data: 0.0361  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.4393 (0.8476)  labels_encoder: 0.4393 (0.8476)  labels_encoder_unscaled: 0.4393 (0.8476)  time: 0.0498  data: 0.0348  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.4735 (0.8758)  labels_encoder: 0.4735 (0.8758)  labels_encoder_unscaled: 0.4735 (0.8758)  time: 0.0477  data: 0.0326  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6623 (0.8166)  labels_encoder: 0.6623 (0.8166)  labels_encoder_unscaled: 0.6623 (0.8166)  time: 0.0473  data: 0.0314  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7818 (0.9145)  labels_encoder: 0.7818 (0.9145)  labels_encoder_unscaled: 0.7818 (0.9145)  time: 0.0482  data: 0.0332  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1144 (0.9678)  labels_encoder: 1.1144 (0.9678)  labels_encoder_unscaled: 1.1144 (0.9678)  time: 0.0484  data: 0.0315  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7318 (0.9827)  labels_encoder: 0.7318 (0.9827)  labels_encoder_unscaled: 0.7318 (0.9827)  time: 0.0477  data: 0.0324  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3676 (0.9577)  labels_encoder: 0.3676 (0.9577)  labels_encoder_unscaled: 0.3676 (0.9577)  time: 0.0490  data: 0.0330  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4106 (0.9355)  labels_encoder: 0.4106 (0.9355)  labels_encoder_unscaled: 0.4106 (0.9355)  time: 0.0484  data: 0.0325  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.6009 (0.9183)  labels_encoder: 0.6009 (0.9183)  labels_encoder_unscaled: 0.6009 (0.9183)  time: 0.0485  data: 0.0326  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7721 (0.8940)  labels_encoder: 0.7721 (0.8940)  labels_encoder_unscaled: 0.7721 (0.8940)  time: 0.0470  data: 0.0319  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3245 (0.8878)  labels_encoder: 0.3245 (0.8878)  labels_encoder_unscaled: 0.3245 (0.8878)  time: 0.0445  data: 0.0300  max mem: 593
Test: Total time: 0:00:29 (0.0524 s / it)
Averaged stats: loss: 0.3245 (0.8878)  labels_encoder: 0.3245 (0.8878)  labels_encoder_unscaled: 0.3245 (0.8878)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1295, mcAP: 0.8770

BaseballPitch: 0.0364
BasketballDunk: 0.1040
Billiards: 0.0048
CleanAndJerk: 0.4165
CliffDiving: 0.3830
CricketBowling: 0.0891
CricketShot: 0.1058
Diving: 0.0059
FrisbeeCatch: 0.1216
GolfSwing: 0.0549
HammerThrow: 0.1117
HighJump: 0.0526
JavelinThrow: 0.0658
LongJump: 0.3734
PoleVault: 0.0983
Shotput: 0.1364
SoccerPenalty: 0.0504
TennisSwing: 0.1970
ThrowDiscus: 0.0376
VolleyballSpiking: 0.1447
Training time 0:07:12
