Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:1
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:1
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Sequential(
  10.521 M, 99.942% Params, 0.011 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 39.854% Params, 0.004 GMac, 39.368% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    6.294 M, 59.786% Params, 0.006 GMac, 60.334% MACs, 
    (0): BroadcastReduce(
      4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, reduce=sum_last_pairs
      (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): CoSiMultiheadAttention(
        4.194 M, 39.844% Params, 0.004 GMac, 40.617% MACs, 
        (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
      )
    )
    (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    (2): BroadcastReduce(
      2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, reduce=reduce_sum
      (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
      (1): Sequential(
        2.099 M, 19.942% Params, 0.002 GMac, 19.717% MACs, 
        (0): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.019% MACs, )
        (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        (3): Linear(1.05 M, 9.971% Params, 0.001 GMac, 9.849% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
        (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
      )
    )
    (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.302% Params, 0.0 GMac, 0.298% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 10656799.0
Model params: 10526751
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| Active memory         |   42156 KB |   42696 KB |   78140 KB |   35983 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   59392 KB |   59392 KB |   59392 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   17235 KB |   17235 KB |   70795 KB |   53560 KB |
|---------------------------------------------------------------------------|
| Allocations           |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| Active allocs         |      20    |      30    |     960    |     940    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       5    |     314    |     312    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 43168256 43721216 43168256
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1511]  eta: 0:56:02  lr: 0.000100  loss: 3.7501 (3.7501)  labels_encoder: 3.7501 (3.7501)  labels_encoder_unscaled: 3.7501 (3.7501)  time: 2.2253  data: 2.1885  max mem: 483
Epoch: [1]  [  50/1511]  eta: 0:02:26  lr: 0.000100  loss: 1.0320 (1.1610)  labels_encoder: 1.0320 (1.1610)  labels_encoder_unscaled: 1.0320 (1.1610)  time: 0.0498  data: 0.0158  max mem: 593
Epoch: [1]  [ 100/1511]  eta: 0:01:44  lr: 0.000100  loss: 0.9797 (1.0776)  labels_encoder: 0.9797 (1.0776)  labels_encoder_unscaled: 0.9797 (1.0776)  time: 0.0499  data: 0.0157  max mem: 593
Epoch: [1]  [ 150/1511]  eta: 0:01:28  lr: 0.000100  loss: 0.8535 (1.0281)  labels_encoder: 0.8535 (1.0281)  labels_encoder_unscaled: 0.8535 (1.0281)  time: 0.0471  data: 0.0196  max mem: 593
Epoch: [1]  [ 200/1511]  eta: 0:01:20  lr: 0.000100  loss: 0.8648 (0.9987)  labels_encoder: 0.8648 (0.9987)  labels_encoder_unscaled: 0.8648 (0.9987)  time: 0.0522  data: 0.0242  max mem: 593
Epoch: [1]  [ 250/1511]  eta: 0:01:14  lr: 0.000100  loss: 0.9056 (0.9797)  labels_encoder: 0.9056 (0.9797)  labels_encoder_unscaled: 0.9056 (0.9797)  time: 0.0482  data: 0.0206  max mem: 593
Epoch: [1]  [ 300/1511]  eta: 0:01:09  lr: 0.000100  loss: 0.8142 (0.9627)  labels_encoder: 0.8142 (0.9627)  labels_encoder_unscaled: 0.8142 (0.9627)  time: 0.0525  data: 0.0265  max mem: 593
Epoch: [1]  [ 350/1511]  eta: 0:01:05  lr: 0.000100  loss: 0.8585 (0.9497)  labels_encoder: 0.8585 (0.9497)  labels_encoder_unscaled: 0.8585 (0.9497)  time: 0.0494  data: 0.0208  max mem: 593
Epoch: [1]  [ 400/1511]  eta: 0:01:01  lr: 0.000100  loss: 0.7737 (0.9383)  labels_encoder: 0.7737 (0.9383)  labels_encoder_unscaled: 0.7737 (0.9383)  time: 0.0494  data: 0.0223  max mem: 593
Epoch: [1]  [ 450/1511]  eta: 0:00:58  lr: 0.000100  loss: 0.7956 (0.9252)  labels_encoder: 0.7956 (0.9252)  labels_encoder_unscaled: 0.7956 (0.9252)  time: 0.0499  data: 0.0231  max mem: 593
Epoch: [1]  [ 500/1511]  eta: 0:00:54  lr: 0.000100  loss: 0.8095 (0.9137)  labels_encoder: 0.8095 (0.9137)  labels_encoder_unscaled: 0.8095 (0.9137)  time: 0.0486  data: 0.0213  max mem: 593
Epoch: [1]  [ 550/1511]  eta: 0:00:51  lr: 0.000100  loss: 0.7797 (0.9026)  labels_encoder: 0.7797 (0.9026)  labels_encoder_unscaled: 0.7797 (0.9026)  time: 0.0548  data: 0.0277  max mem: 593
Epoch: [1]  [ 600/1511]  eta: 0:00:48  lr: 0.000100  loss: 0.7864 (0.8925)  labels_encoder: 0.7864 (0.8925)  labels_encoder_unscaled: 0.7864 (0.8925)  time: 0.0498  data: 0.0223  max mem: 593
Epoch: [1]  [ 650/1511]  eta: 0:00:45  lr: 0.000100  loss: 0.7805 (0.8845)  labels_encoder: 0.7805 (0.8845)  labels_encoder_unscaled: 0.7805 (0.8845)  time: 0.0508  data: 0.0237  max mem: 593
Epoch: [1]  [ 700/1511]  eta: 0:00:42  lr: 0.000100  loss: 0.7807 (0.8764)  labels_encoder: 0.7807 (0.8764)  labels_encoder_unscaled: 0.7807 (0.8764)  time: 0.0473  data: 0.0198  max mem: 593
Epoch: [1]  [ 750/1511]  eta: 0:00:40  lr: 0.000100  loss: 0.7593 (0.8710)  labels_encoder: 0.7593 (0.8710)  labels_encoder_unscaled: 0.7593 (0.8710)  time: 0.0487  data: 0.0161  max mem: 593
Epoch: [1]  [ 800/1511]  eta: 0:00:37  lr: 0.000100  loss: 0.7139 (0.8637)  labels_encoder: 0.7139 (0.8637)  labels_encoder_unscaled: 0.7139 (0.8637)  time: 0.0496  data: 0.0167  max mem: 593
Epoch: [1]  [ 850/1511]  eta: 0:00:34  lr: 0.000100  loss: 0.6826 (0.8558)  labels_encoder: 0.6826 (0.8558)  labels_encoder_unscaled: 0.6826 (0.8558)  time: 0.0478  data: 0.0166  max mem: 593
Epoch: [1]  [ 900/1511]  eta: 0:00:31  lr: 0.000100  loss: 0.6968 (0.8502)  labels_encoder: 0.6968 (0.8502)  labels_encoder_unscaled: 0.6968 (0.8502)  time: 0.0473  data: 0.0197  max mem: 593
Epoch: [1]  [ 950/1511]  eta: 0:00:29  lr: 0.000100  loss: 0.7429 (0.8450)  labels_encoder: 0.7429 (0.8450)  labels_encoder_unscaled: 0.7429 (0.8450)  time: 0.0474  data: 0.0112  max mem: 593
Epoch: [1]  [1000/1511]  eta: 0:00:26  lr: 0.000100  loss: 0.6745 (0.8383)  labels_encoder: 0.6745 (0.8383)  labels_encoder_unscaled: 0.6745 (0.8383)  time: 0.0479  data: 0.0203  max mem: 593
Epoch: [1]  [1050/1511]  eta: 0:00:23  lr: 0.000100  loss: 0.6312 (0.8322)  labels_encoder: 0.6312 (0.8322)  labels_encoder_unscaled: 0.6312 (0.8322)  time: 0.0483  data: 0.0206  max mem: 593
Epoch: [1]  [1100/1511]  eta: 0:00:21  lr: 0.000100  loss: 0.7477 (0.8286)  labels_encoder: 0.7477 (0.8286)  labels_encoder_unscaled: 0.7477 (0.8286)  time: 0.0484  data: 0.0207  max mem: 593
Epoch: [1]  [1150/1511]  eta: 0:00:18  lr: 0.000100  loss: 0.7391 (0.8241)  labels_encoder: 0.7391 (0.8241)  labels_encoder_unscaled: 0.7391 (0.8241)  time: 0.0479  data: 0.0142  max mem: 593
Epoch: [1]  [1200/1511]  eta: 0:00:15  lr: 0.000100  loss: 0.7411 (0.8204)  labels_encoder: 0.7411 (0.8204)  labels_encoder_unscaled: 0.7411 (0.8204)  time: 0.0471  data: 0.0199  max mem: 593
Epoch: [1]  [1250/1511]  eta: 0:00:13  lr: 0.000100  loss: 0.6566 (0.8163)  labels_encoder: 0.6566 (0.8163)  labels_encoder_unscaled: 0.6566 (0.8163)  time: 0.0485  data: 0.0201  max mem: 593
Epoch: [1]  [1300/1511]  eta: 0:00:10  lr: 0.000100  loss: 0.6726 (0.8113)  labels_encoder: 0.6726 (0.8113)  labels_encoder_unscaled: 0.6726 (0.8113)  time: 0.0487  data: 0.0225  max mem: 593
Epoch: [1]  [1350/1511]  eta: 0:00:08  lr: 0.000100  loss: 0.6729 (0.8083)  labels_encoder: 0.6729 (0.8083)  labels_encoder_unscaled: 0.6729 (0.8083)  time: 0.0480  data: 0.0169  max mem: 593
Epoch: [1]  [1400/1511]  eta: 0:00:05  lr: 0.000100  loss: 0.6546 (0.8032)  labels_encoder: 0.6546 (0.8032)  labels_encoder_unscaled: 0.6546 (0.8032)  time: 0.0460  data: 0.0148  max mem: 593
Epoch: [1]  [1450/1511]  eta: 0:00:03  lr: 0.000100  loss: 0.6633 (0.7987)  labels_encoder: 0.6633 (0.7987)  labels_encoder_unscaled: 0.6633 (0.7987)  time: 0.0481  data: 0.0178  max mem: 593
Epoch: [1]  [1500/1511]  eta: 0:00:00  lr: 0.000100  loss: 0.6926 (0.7949)  labels_encoder: 0.6926 (0.7949)  labels_encoder_unscaled: 0.6926 (0.7949)  time: 0.0474  data: 0.0202  max mem: 593
Epoch: [1]  [1510/1511]  eta: 0:00:00  lr: 0.000100  loss: 0.6838 (0.7943)  labels_encoder: 0.6838 (0.7943)  labels_encoder_unscaled: 0.6838 (0.7943)  time: 0.0459  data: 0.0190  max mem: 593
Epoch: [1] Total time: 0:01:16 (0.0508 s / it)
Averaged stats: lr: 0.000100  loss: 0.6838 (0.7943)  labels_encoder: 0.6838 (0.7943)  labels_encoder_unscaled: 0.6838 (0.7943)
Test:  [  0/559]  eta: 0:15:43  loss: 0.6611 (0.6611)  labels_encoder: 0.6611 (0.6611)  labels_encoder_unscaled: 0.6611 (0.6611)  time: 1.6874  data: 1.6696  max mem: 593
Test:  [ 50/559]  eta: 0:00:41  loss: 0.9782 (0.9957)  labels_encoder: 0.9782 (0.9957)  labels_encoder_unscaled: 0.9782 (0.9957)  time: 0.0371  data: 0.0177  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.5156 (0.9291)  labels_encoder: 0.5156 (0.9291)  labels_encoder_unscaled: 0.5156 (0.9291)  time: 0.0477  data: 0.0311  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.6821 (0.9394)  labels_encoder: 0.6821 (0.9394)  labels_encoder_unscaled: 0.6821 (0.9394)  time: 0.0527  data: 0.0366  max mem: 593
Test:  [200/559]  eta: 0:00:21  loss: 0.5710 (0.8684)  labels_encoder: 0.5710 (0.8684)  labels_encoder_unscaled: 0.5710 (0.8684)  time: 0.0489  data: 0.0327  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.8181 (0.9882)  labels_encoder: 0.8181 (0.9882)  labels_encoder_unscaled: 0.8181 (0.9882)  time: 0.0495  data: 0.0332  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1370 (1.0422)  labels_encoder: 1.1370 (1.0422)  labels_encoder_unscaled: 1.1370 (1.0422)  time: 0.0481  data: 0.0314  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8761 (1.0682)  labels_encoder: 0.8761 (1.0682)  labels_encoder_unscaled: 0.8761 (1.0682)  time: 0.0490  data: 0.0332  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.4853 (1.0473)  labels_encoder: 0.4853 (1.0473)  labels_encoder_unscaled: 0.4853 (1.0473)  time: 0.0493  data: 0.0339  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.4968 (1.0212)  labels_encoder: 0.4968 (1.0212)  labels_encoder_unscaled: 0.4968 (1.0212)  time: 0.0498  data: 0.0328  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5801 (0.9952)  labels_encoder: 0.5801 (0.9952)  labels_encoder_unscaled: 0.5801 (0.9952)  time: 0.0552  data: 0.0396  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6710 (0.9692)  labels_encoder: 0.6710 (0.9692)  labels_encoder_unscaled: 0.6710 (0.9692)  time: 0.0495  data: 0.0337  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3966 (0.9624)  labels_encoder: 0.3966 (0.9624)  labels_encoder_unscaled: 0.3966 (0.9624)  time: 0.0461  data: 0.0307  max mem: 593
Test: Total time: 0:00:29 (0.0536 s / it)
Averaged stats: loss: 0.3966 (0.9624)  labels_encoder: 0.3966 (0.9624)  labels_encoder_unscaled: 0.3966 (0.9624)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1160, mcAP: 0.8570

BaseballPitch: 0.0216
BasketballDunk: 0.1099
Billiards: 0.0044
CleanAndJerk: 0.3728
CliffDiving: 0.4722
CricketBowling: 0.0805
CricketShot: 0.0857
Diving: 0.0076
FrisbeeCatch: 0.0829
GolfSwing: 0.0541
HammerThrow: 0.0744
HighJump: 0.0318
JavelinThrow: 0.0740
LongJump: 0.3079
PoleVault: 0.0909
Shotput: 0.1127
SoccerPenalty: 0.0479
TennisSwing: 0.1765
ThrowDiscus: 0.0173
VolleyballSpiking: 0.0948
Epoch: [2]  [   0/1511]  eta: 0:44:41  lr: 0.000010  loss: 0.6998 (0.6998)  labels_encoder: 0.6998 (0.6998)  labels_encoder_unscaled: 0.6998 (0.6998)  time: 1.7746  data: 1.7255  max mem: 593
Epoch: [2]  [  50/1511]  eta: 0:02:05  lr: 0.000010  loss: 0.6524 (0.6624)  labels_encoder: 0.6524 (0.6624)  labels_encoder_unscaled: 0.6524 (0.6624)  time: 0.0559  data: 0.0233  max mem: 593
Epoch: [2]  [ 100/1511]  eta: 0:01:33  lr: 0.000010  loss: 0.6528 (0.6600)  labels_encoder: 0.6528 (0.6600)  labels_encoder_unscaled: 0.6528 (0.6600)  time: 0.0468  data: 0.0193  max mem: 593
Epoch: [2]  [ 150/1511]  eta: 0:01:21  lr: 0.000010  loss: 0.6686 (0.6697)  labels_encoder: 0.6686 (0.6697)  labels_encoder_unscaled: 0.6686 (0.6697)  time: 0.0482  data: 0.0205  max mem: 593
Epoch: [2]  [ 200/1511]  eta: 0:01:14  lr: 0.000010  loss: 0.6248 (0.6627)  labels_encoder: 0.6248 (0.6627)  labels_encoder_unscaled: 0.6248 (0.6627)  time: 0.0485  data: 0.0211  max mem: 593
Epoch: [2]  [ 250/1511]  eta: 0:01:09  lr: 0.000010  loss: 0.6899 (0.6654)  labels_encoder: 0.6899 (0.6654)  labels_encoder_unscaled: 0.6899 (0.6654)  time: 0.0485  data: 0.0208  max mem: 593
Epoch: [2]  [ 300/1511]  eta: 0:01:05  lr: 0.000010  loss: 0.6416 (0.6593)  labels_encoder: 0.6416 (0.6593)  labels_encoder_unscaled: 0.6416 (0.6593)  time: 0.0480  data: 0.0201  max mem: 593
Epoch: [2]  [ 350/1511]  eta: 0:01:02  lr: 0.000010  loss: 0.7021 (0.6564)  labels_encoder: 0.7021 (0.6564)  labels_encoder_unscaled: 0.7021 (0.6564)  time: 0.0499  data: 0.0191  max mem: 593
Epoch: [2]  [ 400/1511]  eta: 0:00:59  lr: 0.000010  loss: 0.6020 (0.6521)  labels_encoder: 0.6020 (0.6521)  labels_encoder_unscaled: 0.6020 (0.6521)  time: 0.0523  data: 0.0227  max mem: 593
Epoch: [2]  [ 450/1511]  eta: 0:00:55  lr: 0.000010  loss: 0.6152 (0.6475)  labels_encoder: 0.6152 (0.6475)  labels_encoder_unscaled: 0.6152 (0.6475)  time: 0.0457  data: 0.0147  max mem: 593
Epoch: [2]  [ 500/1511]  eta: 0:00:52  lr: 0.000010  loss: 0.5671 (0.6455)  labels_encoder: 0.5671 (0.6455)  labels_encoder_unscaled: 0.5671 (0.6455)  time: 0.0486  data: 0.0223  max mem: 593
Epoch: [2]  [ 550/1511]  eta: 0:00:49  lr: 0.000010  loss: 0.6130 (0.6417)  labels_encoder: 0.6130 (0.6417)  labels_encoder_unscaled: 0.6130 (0.6417)  time: 0.0488  data: 0.0226  max mem: 593
Epoch: [2]  [ 600/1511]  eta: 0:00:47  lr: 0.000010  loss: 0.6025 (0.6406)  labels_encoder: 0.6025 (0.6406)  labels_encoder_unscaled: 0.6025 (0.6406)  time: 0.0482  data: 0.0210  max mem: 593
Epoch: [2]  [ 650/1511]  eta: 0:00:44  lr: 0.000010  loss: 0.6150 (0.6393)  labels_encoder: 0.6150 (0.6393)  labels_encoder_unscaled: 0.6150 (0.6393)  time: 0.0483  data: 0.0211  max mem: 593
Epoch: [2]  [ 700/1511]  eta: 0:00:41  lr: 0.000010  loss: 0.6318 (0.6390)  labels_encoder: 0.6318 (0.6390)  labels_encoder_unscaled: 0.6318 (0.6390)  time: 0.0494  data: 0.0185  max mem: 593
Epoch: [2]  [ 750/1511]  eta: 0:00:38  lr: 0.000010  loss: 0.6383 (0.6369)  labels_encoder: 0.6383 (0.6369)  labels_encoder_unscaled: 0.6383 (0.6369)  time: 0.0463  data: 0.0157  max mem: 593
Epoch: [2]  [ 800/1511]  eta: 0:00:36  lr: 0.000010  loss: 0.6873 (0.6367)  labels_encoder: 0.6873 (0.6367)  labels_encoder_unscaled: 0.6873 (0.6367)  time: 0.0533  data: 0.0248  max mem: 593
Epoch: [2]  [ 850/1511]  eta: 0:00:33  lr: 0.000010  loss: 0.6307 (0.6360)  labels_encoder: 0.6307 (0.6360)  labels_encoder_unscaled: 0.6307 (0.6360)  time: 0.0490  data: 0.0207  max mem: 593
Epoch: [2]  [ 900/1511]  eta: 0:00:31  lr: 0.000010  loss: 0.6042 (0.6336)  labels_encoder: 0.6042 (0.6336)  labels_encoder_unscaled: 0.6042 (0.6336)  time: 0.0481  data: 0.0197  max mem: 593
Epoch: [2]  [ 950/1511]  eta: 0:00:28  lr: 0.000010  loss: 0.5660 (0.6323)  labels_encoder: 0.5660 (0.6323)  labels_encoder_unscaled: 0.5660 (0.6323)  time: 0.0505  data: 0.0221  max mem: 593
Epoch: [2]  [1000/1511]  eta: 0:00:25  lr: 0.000010  loss: 0.6047 (0.6310)  labels_encoder: 0.6047 (0.6310)  labels_encoder_unscaled: 0.6047 (0.6310)  time: 0.0484  data: 0.0199  max mem: 593
Epoch: [2]  [1050/1511]  eta: 0:00:23  lr: 0.000010  loss: 0.5525 (0.6297)  labels_encoder: 0.5525 (0.6297)  labels_encoder_unscaled: 0.5525 (0.6297)  time: 0.0498  data: 0.0222  max mem: 593
Epoch: [2]  [1100/1511]  eta: 0:00:20  lr: 0.000010  loss: 0.5989 (0.6298)  labels_encoder: 0.5989 (0.6298)  labels_encoder_unscaled: 0.5989 (0.6298)  time: 0.0473  data: 0.0115  max mem: 593
Epoch: [2]  [1150/1511]  eta: 0:00:18  lr: 0.000010  loss: 0.6047 (0.6288)  labels_encoder: 0.6047 (0.6288)  labels_encoder_unscaled: 0.6047 (0.6288)  time: 0.0483  data: 0.0206  max mem: 593
Epoch: [2]  [1200/1511]  eta: 0:00:15  lr: 0.000010  loss: 0.5906 (0.6280)  labels_encoder: 0.5906 (0.6280)  labels_encoder_unscaled: 0.5906 (0.6280)  time: 0.0492  data: 0.0217  max mem: 593
Epoch: [2]  [1250/1511]  eta: 0:00:13  lr: 0.000010  loss: 0.6351 (0.6273)  labels_encoder: 0.6351 (0.6273)  labels_encoder_unscaled: 0.6351 (0.6273)  time: 0.0505  data: 0.0228  max mem: 593
Epoch: [2]  [1300/1511]  eta: 0:00:10  lr: 0.000010  loss: 0.5734 (0.6263)  labels_encoder: 0.5734 (0.6263)  labels_encoder_unscaled: 0.5734 (0.6263)  time: 0.0482  data: 0.0205  max mem: 593
Epoch: [2]  [1350/1511]  eta: 0:00:08  lr: 0.000010  loss: 0.5404 (0.6249)  labels_encoder: 0.5404 (0.6249)  labels_encoder_unscaled: 0.5404 (0.6249)  time: 0.0467  data: 0.0151  max mem: 593
Epoch: [2]  [1400/1511]  eta: 0:00:05  lr: 0.000010  loss: 0.5170 (0.6241)  labels_encoder: 0.5170 (0.6241)  labels_encoder_unscaled: 0.5170 (0.6241)  time: 0.0575  data: 0.0281  max mem: 593
Epoch: [2]  [1450/1511]  eta: 0:00:03  lr: 0.000010  loss: 0.5575 (0.6230)  labels_encoder: 0.5575 (0.6230)  labels_encoder_unscaled: 0.5575 (0.6230)  time: 0.0469  data: 0.0184  max mem: 593
Epoch: [2]  [1500/1511]  eta: 0:00:00  lr: 0.000010  loss: 0.5813 (0.6219)  labels_encoder: 0.5813 (0.6219)  labels_encoder_unscaled: 0.5813 (0.6219)  time: 0.0480  data: 0.0200  max mem: 593
Epoch: [2]  [1510/1511]  eta: 0:00:00  lr: 0.000010  loss: 0.6099 (0.6220)  labels_encoder: 0.6099 (0.6220)  labels_encoder_unscaled: 0.6099 (0.6220)  time: 0.0467  data: 0.0189  max mem: 593
Epoch: [2] Total time: 0:01:15 (0.0501 s / it)
Averaged stats: lr: 0.000010  loss: 0.6099 (0.6220)  labels_encoder: 0.6099 (0.6220)  labels_encoder_unscaled: 0.6099 (0.6220)
Test:  [  0/559]  eta: 0:17:18  loss: 0.5786 (0.5786)  labels_encoder: 0.5786 (0.5786)  labels_encoder_unscaled: 0.5786 (0.5786)  time: 1.8569  data: 1.8382  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.9584 (0.9147)  labels_encoder: 0.9584 (0.9147)  labels_encoder_unscaled: 0.9584 (0.9147)  time: 0.0394  data: 0.0207  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.4382 (0.8528)  labels_encoder: 0.4382 (0.8528)  labels_encoder_unscaled: 0.4382 (0.8528)  time: 0.0492  data: 0.0331  max mem: 593
Test:  [150/559]  eta: 0:00:24  loss: 0.5128 (0.8820)  labels_encoder: 0.5128 (0.8820)  labels_encoder_unscaled: 0.5128 (0.8820)  time: 0.0481  data: 0.0322  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.8365 (0.8225)  labels_encoder: 0.8365 (0.8225)  labels_encoder_unscaled: 0.8365 (0.8225)  time: 0.0488  data: 0.0321  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7215 (0.9429)  labels_encoder: 0.7215 (0.9429)  labels_encoder_unscaled: 0.7215 (0.9429)  time: 0.0506  data: 0.0347  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1859 (1.0013)  labels_encoder: 1.1859 (1.0013)  labels_encoder_unscaled: 1.1859 (1.0013)  time: 0.0482  data: 0.0320  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7069 (1.0430)  labels_encoder: 0.7069 (1.0430)  labels_encoder_unscaled: 0.7069 (1.0430)  time: 0.0482  data: 0.0316  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3163 (1.0119)  labels_encoder: 0.3163 (1.0119)  labels_encoder_unscaled: 0.3163 (1.0119)  time: 0.0502  data: 0.0351  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3870 (0.9843)  labels_encoder: 0.3870 (0.9843)  labels_encoder_unscaled: 0.3870 (0.9843)  time: 0.0520  data: 0.0370  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5369 (0.9659)  labels_encoder: 0.5369 (0.9659)  labels_encoder_unscaled: 0.5369 (0.9659)  time: 0.0490  data: 0.0340  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.8275 (0.9375)  labels_encoder: 0.8275 (0.9375)  labels_encoder_unscaled: 0.8275 (0.9375)  time: 0.0475  data: 0.0317  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.4087 (0.9303)  labels_encoder: 0.4087 (0.9303)  labels_encoder_unscaled: 0.4087 (0.9303)  time: 0.0469  data: 0.0315  max mem: 593
Test: Total time: 0:00:30 (0.0542 s / it)
Averaged stats: loss: 0.4087 (0.9303)  labels_encoder: 0.4087 (0.9303)  labels_encoder_unscaled: 0.4087 (0.9303)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1251, mcAP: 0.8803

BaseballPitch: 0.0366
BasketballDunk: 0.0881
Billiards: 0.0063
CleanAndJerk: 0.3717
CliffDiving: 0.4593
CricketBowling: 0.0698
CricketShot: 0.1093
Diving: 0.0189
FrisbeeCatch: 0.1145
GolfSwing: 0.0740
HammerThrow: 0.0941
HighJump: 0.0551
JavelinThrow: 0.0495
LongJump: 0.3528
PoleVault: 0.0817
Shotput: 0.1247
SoccerPenalty: 0.0577
TennisSwing: 0.1424
ThrowDiscus: 0.0604
VolleyballSpiking: 0.1346
Epoch: [3]  [   0/1511]  eta: 0:48:04  lr: 0.000001  loss: 0.6468 (0.6468)  labels_encoder: 0.6468 (0.6468)  labels_encoder_unscaled: 0.6468 (0.6468)  time: 1.9093  data: 1.8657  max mem: 593
Epoch: [3]  [  50/1511]  eta: 0:02:05  lr: 0.000001  loss: 0.5540 (0.6218)  labels_encoder: 0.5540 (0.6218)  labels_encoder_unscaled: 0.5540 (0.6218)  time: 0.0519  data: 0.0131  max mem: 593
Epoch: [3]  [ 100/1511]  eta: 0:01:35  lr: 0.000001  loss: 0.5916 (0.6147)  labels_encoder: 0.5916 (0.6147)  labels_encoder_unscaled: 0.5916 (0.6147)  time: 0.0484  data: 0.0171  max mem: 593
Epoch: [3]  [ 150/1511]  eta: 0:01:24  lr: 0.000001  loss: 0.6077 (0.6150)  labels_encoder: 0.6077 (0.6150)  labels_encoder_unscaled: 0.6077 (0.6150)  time: 0.0465  data: 0.0179  max mem: 593
Epoch: [3]  [ 200/1511]  eta: 0:01:16  lr: 0.000001  loss: 0.6422 (0.6219)  labels_encoder: 0.6422 (0.6219)  labels_encoder_unscaled: 0.6422 (0.6219)  time: 0.0483  data: 0.0163  max mem: 593
Epoch: [3]  [ 250/1511]  eta: 0:01:11  lr: 0.000001  loss: 0.5729 (0.6198)  labels_encoder: 0.5729 (0.6198)  labels_encoder_unscaled: 0.5729 (0.6198)  time: 0.0465  data: 0.0182  max mem: 593
Epoch: [3]  [ 300/1511]  eta: 0:01:07  lr: 0.000001  loss: 0.5686 (0.6153)  labels_encoder: 0.5686 (0.6153)  labels_encoder_unscaled: 0.5686 (0.6153)  time: 0.0497  data: 0.0200  max mem: 593
Epoch: [3]  [ 350/1511]  eta: 0:01:03  lr: 0.000001  loss: 0.5418 (0.6104)  labels_encoder: 0.5418 (0.6104)  labels_encoder_unscaled: 0.5418 (0.6104)  time: 0.0496  data: 0.0214  max mem: 593
Epoch: [3]  [ 400/1511]  eta: 0:00:59  lr: 0.000001  loss: 0.6778 (0.6111)  labels_encoder: 0.6778 (0.6111)  labels_encoder_unscaled: 0.6778 (0.6111)  time: 0.0475  data: 0.0191  max mem: 593
Epoch: [3]  [ 450/1511]  eta: 0:00:56  lr: 0.000001  loss: 0.5481 (0.6090)  labels_encoder: 0.5481 (0.6090)  labels_encoder_unscaled: 0.5481 (0.6090)  time: 0.0483  data: 0.0177  max mem: 593
Epoch: [3]  [ 500/1511]  eta: 0:00:53  lr: 0.000001  loss: 0.5763 (0.6081)  labels_encoder: 0.5763 (0.6081)  labels_encoder_unscaled: 0.5763 (0.6081)  time: 0.0515  data: 0.0207  max mem: 593
Epoch: [3]  [ 550/1511]  eta: 0:00:50  lr: 0.000001  loss: 0.5944 (0.6103)  labels_encoder: 0.5944 (0.6103)  labels_encoder_unscaled: 0.5944 (0.6103)  time: 0.0489  data: 0.0205  max mem: 593
Epoch: [3]  [ 600/1511]  eta: 0:00:47  lr: 0.000001  loss: 0.5777 (0.6085)  labels_encoder: 0.5777 (0.6085)  labels_encoder_unscaled: 0.5777 (0.6085)  time: 0.0487  data: 0.0150  max mem: 593
Epoch: [3]  [ 650/1511]  eta: 0:00:44  lr: 0.000001  loss: 0.6015 (0.6072)  labels_encoder: 0.6015 (0.6072)  labels_encoder_unscaled: 0.6015 (0.6072)  time: 0.0472  data: 0.0208  max mem: 593
Epoch: [3]  [ 700/1511]  eta: 0:00:41  lr: 0.000001  loss: 0.5794 (0.6059)  labels_encoder: 0.5794 (0.6059)  labels_encoder_unscaled: 0.5794 (0.6059)  time: 0.0486  data: 0.0212  max mem: 593
Epoch: [3]  [ 750/1511]  eta: 0:00:39  lr: 0.000001  loss: 0.5973 (0.6042)  labels_encoder: 0.5973 (0.6042)  labels_encoder_unscaled: 0.5973 (0.6042)  time: 0.0515  data: 0.0244  max mem: 593
Epoch: [3]  [ 800/1511]  eta: 0:00:36  lr: 0.000001  loss: 0.5427 (0.6020)  labels_encoder: 0.5427 (0.6020)  labels_encoder_unscaled: 0.5427 (0.6020)  time: 0.0488  data: 0.0205  max mem: 593
Epoch: [3]  [ 850/1511]  eta: 0:00:33  lr: 0.000001  loss: 0.6257 (0.6026)  labels_encoder: 0.6257 (0.6026)  labels_encoder_unscaled: 0.6257 (0.6026)  time: 0.0481  data: 0.0196  max mem: 593
Epoch: [3]  [ 900/1511]  eta: 0:00:31  lr: 0.000001  loss: 0.5415 (0.6012)  labels_encoder: 0.5415 (0.6012)  labels_encoder_unscaled: 0.5415 (0.6012)  time: 0.0488  data: 0.0203  max mem: 593
Epoch: [3]  [ 950/1511]  eta: 0:00:28  lr: 0.000001  loss: 0.5870 (0.6002)  labels_encoder: 0.5870 (0.6002)  labels_encoder_unscaled: 0.5870 (0.6002)  time: 0.0481  data: 0.0203  max mem: 593
Epoch: [3]  [1000/1511]  eta: 0:00:26  lr: 0.000001  loss: 0.5971 (0.5992)  labels_encoder: 0.5971 (0.5992)  labels_encoder_unscaled: 0.5971 (0.5992)  time: 0.0522  data: 0.0246  max mem: 593
Epoch: [3]  [1050/1511]  eta: 0:00:23  lr: 0.000001  loss: 0.5729 (0.5986)  labels_encoder: 0.5729 (0.5986)  labels_encoder_unscaled: 0.5729 (0.5986)  time: 0.0482  data: 0.0197  max mem: 593
Epoch: [3]  [1100/1511]  eta: 0:00:20  lr: 0.000001  loss: 0.5265 (0.5971)  labels_encoder: 0.5265 (0.5971)  labels_encoder_unscaled: 0.5265 (0.5971)  time: 0.0482  data: 0.0209  max mem: 593
Epoch: [3]  [1150/1511]  eta: 0:00:18  lr: 0.000001  loss: 0.5389 (0.5958)  labels_encoder: 0.5389 (0.5958)  labels_encoder_unscaled: 0.5389 (0.5958)  time: 0.0483  data: 0.0200  max mem: 593
Epoch: [3]  [1200/1511]  eta: 0:00:15  lr: 0.000001  loss: 0.5303 (0.5940)  labels_encoder: 0.5303 (0.5940)  labels_encoder_unscaled: 0.5303 (0.5940)  time: 0.0503  data: 0.0220  max mem: 593
Epoch: [3]  [1250/1511]  eta: 0:00:13  lr: 0.000001  loss: 0.5582 (0.5930)  labels_encoder: 0.5582 (0.5930)  labels_encoder_unscaled: 0.5582 (0.5930)  time: 0.0488  data: 0.0156  max mem: 593
Epoch: [3]  [1300/1511]  eta: 0:00:10  lr: 0.000001  loss: 0.5590 (0.5931)  labels_encoder: 0.5590 (0.5931)  labels_encoder_unscaled: 0.5590 (0.5931)  time: 0.0474  data: 0.0201  max mem: 593
Epoch: [3]  [1350/1511]  eta: 0:00:08  lr: 0.000001  loss: 0.5633 (0.5927)  labels_encoder: 0.5633 (0.5927)  labels_encoder_unscaled: 0.5633 (0.5927)  time: 0.0533  data: 0.0210  max mem: 593
Epoch: [3]  [1400/1511]  eta: 0:00:05  lr: 0.000001  loss: 0.5523 (0.5923)  labels_encoder: 0.5523 (0.5923)  labels_encoder_unscaled: 0.5523 (0.5923)  time: 0.0547  data: 0.0273  max mem: 593
Epoch: [3]  [1450/1511]  eta: 0:00:03  lr: 0.000001  loss: 0.5396 (0.5919)  labels_encoder: 0.5396 (0.5919)  labels_encoder_unscaled: 0.5396 (0.5919)  time: 0.0502  data: 0.0226  max mem: 593
Epoch: [3]  [1500/1511]  eta: 0:00:00  lr: 0.000001  loss: 0.5479 (0.5918)  labels_encoder: 0.5479 (0.5918)  labels_encoder_unscaled: 0.5479 (0.5918)  time: 0.0467  data: 0.0152  max mem: 593
Epoch: [3]  [1510/1511]  eta: 0:00:00  lr: 0.000001  loss: 0.5141 (0.5915)  labels_encoder: 0.5141 (0.5915)  labels_encoder_unscaled: 0.5141 (0.5915)  time: 0.0439  data: 0.0100  max mem: 593
Epoch: [3] Total time: 0:01:16 (0.0507 s / it)
Averaged stats: lr: 0.000001  loss: 0.5141 (0.5915)  labels_encoder: 0.5141 (0.5915)  labels_encoder_unscaled: 0.5141 (0.5915)
Test:  [  0/559]  eta: 0:16:02  loss: 0.5911 (0.5911)  labels_encoder: 0.5911 (0.5911)  labels_encoder_unscaled: 0.5911 (0.5911)  time: 1.7213  data: 1.7012  max mem: 593
Test:  [ 50/559]  eta: 0:00:44  loss: 0.7466 (0.8688)  labels_encoder: 0.7466 (0.8688)  labels_encoder_unscaled: 0.7466 (0.8688)  time: 0.0477  data: 0.0315  max mem: 593
Test:  [100/559]  eta: 0:00:31  loss: 0.4833 (0.8340)  labels_encoder: 0.4833 (0.8340)  labels_encoder_unscaled: 0.4833 (0.8340)  time: 0.0538  data: 0.0379  max mem: 593
Test:  [150/559]  eta: 0:00:26  loss: 0.5708 (0.8590)  labels_encoder: 0.5708 (0.8590)  labels_encoder_unscaled: 0.5708 (0.8590)  time: 0.0530  data: 0.0366  max mem: 593
Test:  [200/559]  eta: 0:00:21  loss: 0.7034 (0.8030)  labels_encoder: 0.7034 (0.8030)  labels_encoder_unscaled: 0.7034 (0.8030)  time: 0.0502  data: 0.0347  max mem: 593
Test:  [250/559]  eta: 0:00:18  loss: 0.7145 (0.9021)  labels_encoder: 0.7145 (0.9021)  labels_encoder_unscaled: 0.7145 (0.9021)  time: 0.0478  data: 0.0304  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1511 (0.9563)  labels_encoder: 1.1511 (0.9563)  labels_encoder_unscaled: 1.1511 (0.9563)  time: 0.0492  data: 0.0334  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.8101 (0.9778)  labels_encoder: 0.8101 (0.9778)  labels_encoder_unscaled: 0.8101 (0.9778)  time: 0.0511  data: 0.0344  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3797 (0.9539)  labels_encoder: 0.3797 (0.9539)  labels_encoder_unscaled: 0.3797 (0.9539)  time: 0.0499  data: 0.0342  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3884 (0.9313)  labels_encoder: 0.3884 (0.9313)  labels_encoder_unscaled: 0.3884 (0.9313)  time: 0.0504  data: 0.0337  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5377 (0.9122)  labels_encoder: 0.5377 (0.9122)  labels_encoder_unscaled: 0.5377 (0.9122)  time: 0.0487  data: 0.0317  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.7183 (0.8880)  labels_encoder: 0.7183 (0.8880)  labels_encoder_unscaled: 0.7183 (0.8880)  time: 0.0484  data: 0.0332  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3565 (0.8819)  labels_encoder: 0.3565 (0.8819)  labels_encoder_unscaled: 0.3565 (0.8819)  time: 0.0469  data: 0.0323  max mem: 593
Test: Total time: 0:00:30 (0.0543 s / it)
Averaged stats: loss: 0.3565 (0.8819)  labels_encoder: 0.3565 (0.8819)  labels_encoder_unscaled: 0.3565 (0.8819)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1358, mcAP: 0.8811

BaseballPitch: 0.0367
BasketballDunk: 0.1103
Billiards: 0.0047
CleanAndJerk: 0.4093
CliffDiving: 0.4485
CricketBowling: 0.0928
CricketShot: 0.1215
Diving: 0.0090
FrisbeeCatch: 0.1537
GolfSwing: 0.0701
HammerThrow: 0.1275
HighJump: 0.0622
JavelinThrow: 0.0965
LongJump: 0.2854
PoleVault: 0.1098
Shotput: 0.1372
SoccerPenalty: 0.0538
TennisSwing: 0.1748
ThrowDiscus: 0.0675
VolleyballSpiking: 0.1439
Epoch: [4]  [   0/1511]  eta: 0:47:52  lr: 0.000000  loss: 0.6575 (0.6575)  labels_encoder: 0.6575 (0.6575)  labels_encoder_unscaled: 0.6575 (0.6575)  time: 1.9011  data: 1.8745  max mem: 593
Epoch: [4]  [  50/1511]  eta: 0:02:13  lr: 0.000000  loss: 0.5671 (0.5843)  labels_encoder: 0.5671 (0.5843)  labels_encoder_unscaled: 0.5671 (0.5843)  time: 0.0586  data: 0.0323  max mem: 593
Epoch: [4]  [ 100/1511]  eta: 0:01:43  lr: 0.000000  loss: 0.5706 (0.5851)  labels_encoder: 0.5706 (0.5851)  labels_encoder_unscaled: 0.5706 (0.5851)  time: 0.0506  data: 0.0220  max mem: 593
Epoch: [4]  [ 150/1511]  eta: 0:01:28  lr: 0.000000  loss: 0.5299 (0.5774)  labels_encoder: 0.5299 (0.5774)  labels_encoder_unscaled: 0.5299 (0.5774)  time: 0.0482  data: 0.0169  max mem: 593
Epoch: [4]  [ 200/1511]  eta: 0:01:21  lr: 0.000000  loss: 0.5636 (0.5796)  labels_encoder: 0.5636 (0.5796)  labels_encoder_unscaled: 0.5636 (0.5796)  time: 0.0539  data: 0.0208  max mem: 593
Epoch: [4]  [ 250/1511]  eta: 0:01:16  lr: 0.000000  loss: 0.5530 (0.5743)  labels_encoder: 0.5530 (0.5743)  labels_encoder_unscaled: 0.5530 (0.5743)  time: 0.0555  data: 0.0282  max mem: 593
Epoch: [4]  [ 300/1511]  eta: 0:01:12  lr: 0.000000  loss: 0.5708 (0.5739)  labels_encoder: 0.5708 (0.5739)  labels_encoder_unscaled: 0.5708 (0.5739)  time: 0.0530  data: 0.0220  max mem: 593
Epoch: [4]  [ 350/1511]  eta: 0:01:07  lr: 0.000000  loss: 0.5736 (0.5720)  labels_encoder: 0.5736 (0.5720)  labels_encoder_unscaled: 0.5736 (0.5720)  time: 0.0487  data: 0.0212  max mem: 593
Epoch: [4]  [ 400/1511]  eta: 0:01:04  lr: 0.000000  loss: 0.5898 (0.5741)  labels_encoder: 0.5898 (0.5741)  labels_encoder_unscaled: 0.5898 (0.5741)  time: 0.0583  data: 0.0310  max mem: 593
Epoch: [4]  [ 450/1511]  eta: 0:01:00  lr: 0.000000  loss: 0.5666 (0.5751)  labels_encoder: 0.5666 (0.5751)  labels_encoder_unscaled: 0.5666 (0.5751)  time: 0.0489  data: 0.0205  max mem: 593
Epoch: [4]  [ 500/1511]  eta: 0:00:57  lr: 0.000000  loss: 0.5514 (0.5735)  labels_encoder: 0.5514 (0.5735)  labels_encoder_unscaled: 0.5514 (0.5735)  time: 0.0564  data: 0.0268  max mem: 593
Epoch: [4]  [ 550/1511]  eta: 0:00:54  lr: 0.000000  loss: 0.5903 (0.5740)  labels_encoder: 0.5903 (0.5740)  labels_encoder_unscaled: 0.5903 (0.5740)  time: 0.0581  data: 0.0298  max mem: 593
Epoch: [4]  [ 600/1511]  eta: 0:00:51  lr: 0.000000  loss: 0.5960 (0.5750)  labels_encoder: 0.5960 (0.5750)  labels_encoder_unscaled: 0.5960 (0.5750)  time: 0.0510  data: 0.0186  max mem: 593
Epoch: [4]  [ 650/1511]  eta: 0:00:48  lr: 0.000000  loss: 0.6204 (0.5775)  labels_encoder: 0.6204 (0.5775)  labels_encoder_unscaled: 0.6204 (0.5775)  time: 0.0488  data: 0.0167  max mem: 593
Epoch: [4]  [ 700/1511]  eta: 0:00:45  lr: 0.000000  loss: 0.6051 (0.5779)  labels_encoder: 0.6051 (0.5779)  labels_encoder_unscaled: 0.6051 (0.5779)  time: 0.0499  data: 0.0171  max mem: 593
Epoch: [4]  [ 750/1511]  eta: 0:00:42  lr: 0.000000  loss: 0.6257 (0.5782)  labels_encoder: 0.6257 (0.5782)  labels_encoder_unscaled: 0.6257 (0.5782)  time: 0.0549  data: 0.0275  max mem: 593
Epoch: [4]  [ 800/1511]  eta: 0:00:39  lr: 0.000000  loss: 0.5931 (0.5791)  labels_encoder: 0.5931 (0.5791)  labels_encoder_unscaled: 0.5931 (0.5791)  time: 0.0590  data: 0.0309  max mem: 593
Epoch: [4]  [ 850/1511]  eta: 0:00:36  lr: 0.000000  loss: 0.5500 (0.5785)  labels_encoder: 0.5500 (0.5785)  labels_encoder_unscaled: 0.5500 (0.5785)  time: 0.0506  data: 0.0221  max mem: 593
Epoch: [4]  [ 900/1511]  eta: 0:00:33  lr: 0.000000  loss: 0.5728 (0.5789)  labels_encoder: 0.5728 (0.5789)  labels_encoder_unscaled: 0.5728 (0.5789)  time: 0.0542  data: 0.0242  max mem: 593
Epoch: [4]  [ 950/1511]  eta: 0:00:30  lr: 0.000000  loss: 0.5719 (0.5791)  labels_encoder: 0.5719 (0.5791)  labels_encoder_unscaled: 0.5719 (0.5791)  time: 0.0505  data: 0.0222  max mem: 593
Epoch: [4]  [1000/1511]  eta: 0:00:28  lr: 0.000000  loss: 0.5902 (0.5793)  labels_encoder: 0.5902 (0.5793)  labels_encoder_unscaled: 0.5902 (0.5793)  time: 0.0511  data: 0.0235  max mem: 593
Epoch: [4]  [1050/1511]  eta: 0:00:25  lr: 0.000000  loss: 0.5285 (0.5787)  labels_encoder: 0.5285 (0.5787)  labels_encoder_unscaled: 0.5285 (0.5787)  time: 0.0498  data: 0.0213  max mem: 593
Epoch: [4]  [1100/1511]  eta: 0:00:22  lr: 0.000000  loss: 0.5495 (0.5790)  labels_encoder: 0.5495 (0.5790)  labels_encoder_unscaled: 0.5495 (0.5790)  time: 0.0549  data: 0.0266  max mem: 593
Epoch: [4]  [1150/1511]  eta: 0:00:19  lr: 0.000000  loss: 0.5808 (0.5795)  labels_encoder: 0.5808 (0.5795)  labels_encoder_unscaled: 0.5808 (0.5795)  time: 0.0527  data: 0.0264  max mem: 593
Epoch: [4]  [1200/1511]  eta: 0:00:17  lr: 0.000000  loss: 0.5700 (0.5797)  labels_encoder: 0.5700 (0.5797)  labels_encoder_unscaled: 0.5700 (0.5797)  time: 0.0499  data: 0.0224  max mem: 593
Epoch: [4]  [1250/1511]  eta: 0:00:14  lr: 0.000000  loss: 0.6126 (0.5792)  labels_encoder: 0.6126 (0.5792)  labels_encoder_unscaled: 0.6126 (0.5792)  time: 0.0477  data: 0.0186  max mem: 593
Epoch: [4]  [1300/1511]  eta: 0:00:11  lr: 0.000000  loss: 0.5393 (0.5792)  labels_encoder: 0.5393 (0.5792)  labels_encoder_unscaled: 0.5393 (0.5792)  time: 0.0497  data: 0.0221  max mem: 593
Epoch: [4]  [1350/1511]  eta: 0:00:08  lr: 0.000000  loss: 0.5471 (0.5787)  labels_encoder: 0.5471 (0.5787)  labels_encoder_unscaled: 0.5471 (0.5787)  time: 0.0490  data: 0.0196  max mem: 593
Epoch: [4]  [1400/1511]  eta: 0:00:06  lr: 0.000000  loss: 0.5575 (0.5786)  labels_encoder: 0.5575 (0.5786)  labels_encoder_unscaled: 0.5575 (0.5786)  time: 0.0582  data: 0.0303  max mem: 593
Epoch: [4]  [1450/1511]  eta: 0:00:03  lr: 0.000000  loss: 0.5344 (0.5789)  labels_encoder: 0.5344 (0.5789)  labels_encoder_unscaled: 0.5344 (0.5789)  time: 0.0522  data: 0.0233  max mem: 593
Epoch: [4]  [1500/1511]  eta: 0:00:00  lr: 0.000000  loss: 0.5210 (0.5783)  labels_encoder: 0.5210 (0.5783)  labels_encoder_unscaled: 0.5210 (0.5783)  time: 0.0547  data: 0.0231  max mem: 593
Epoch: [4]  [1510/1511]  eta: 0:00:00  lr: 0.000000  loss: 0.5284 (0.5786)  labels_encoder: 0.5284 (0.5786)  labels_encoder_unscaled: 0.5284 (0.5786)  time: 0.0535  data: 0.0220  max mem: 593
Epoch: [4] Total time: 0:01:22 (0.0544 s / it)
Averaged stats: lr: 0.000000  loss: 0.5284 (0.5786)  labels_encoder: 0.5284 (0.5786)  labels_encoder_unscaled: 0.5284 (0.5786)
Test:  [  0/559]  eta: 0:16:55  loss: 0.5594 (0.5594)  labels_encoder: 0.5594 (0.5594)  labels_encoder_unscaled: 0.5594 (0.5594)  time: 1.8174  data: 1.7984  max mem: 593
Test:  [ 50/559]  eta: 0:00:42  loss: 0.7640 (0.8628)  labels_encoder: 0.7640 (0.8628)  labels_encoder_unscaled: 0.7640 (0.8628)  time: 0.0468  data: 0.0308  max mem: 593
Test:  [100/559]  eta: 0:00:30  loss: 0.5002 (0.8221)  labels_encoder: 0.5002 (0.8221)  labels_encoder_unscaled: 0.5002 (0.8221)  time: 0.0490  data: 0.0330  max mem: 593
Test:  [150/559]  eta: 0:00:25  loss: 0.4735 (0.8525)  labels_encoder: 0.4735 (0.8525)  labels_encoder_unscaled: 0.4735 (0.8525)  time: 0.0508  data: 0.0351  max mem: 593
Test:  [200/559]  eta: 0:00:20  loss: 0.6604 (0.7953)  labels_encoder: 0.6604 (0.7953)  labels_encoder_unscaled: 0.6604 (0.7953)  time: 0.0484  data: 0.0318  max mem: 593
Test:  [250/559]  eta: 0:00:17  loss: 0.7878 (0.8933)  labels_encoder: 0.7878 (0.8933)  labels_encoder_unscaled: 0.7878 (0.8933)  time: 0.0504  data: 0.0344  max mem: 593
Test:  [300/559]  eta: 0:00:14  loss: 1.1785 (0.9504)  labels_encoder: 1.1785 (0.9504)  labels_encoder_unscaled: 1.1785 (0.9504)  time: 0.0485  data: 0.0324  max mem: 593
Test:  [350/559]  eta: 0:00:11  loss: 0.7862 (0.9739)  labels_encoder: 0.7862 (0.9739)  labels_encoder_unscaled: 0.7862 (0.9739)  time: 0.0507  data: 0.0348  max mem: 593
Test:  [400/559]  eta: 0:00:08  loss: 0.3633 (0.9492)  labels_encoder: 0.3633 (0.9492)  labels_encoder_unscaled: 0.3633 (0.9492)  time: 0.0458  data: 0.0309  max mem: 593
Test:  [450/559]  eta: 0:00:05  loss: 0.3983 (0.9272)  labels_encoder: 0.3983 (0.9272)  labels_encoder_unscaled: 0.3983 (0.9272)  time: 0.0499  data: 0.0348  max mem: 593
Test:  [500/559]  eta: 0:00:03  loss: 0.5677 (0.9110)  labels_encoder: 0.5677 (0.9110)  labels_encoder_unscaled: 0.5677 (0.9110)  time: 0.0485  data: 0.0319  max mem: 593
Test:  [550/559]  eta: 0:00:00  loss: 0.6926 (0.8868)  labels_encoder: 0.6926 (0.8868)  labels_encoder_unscaled: 0.6926 (0.8868)  time: 0.0481  data: 0.0322  max mem: 593
Test:  [558/559]  eta: 0:00:00  loss: 0.3749 (0.8807)  labels_encoder: 0.3749 (0.8807)  labels_encoder_unscaled: 0.3749 (0.8807)  time: 0.0471  data: 0.0316  max mem: 593
Test: Total time: 0:00:29 (0.0533 s / it)
Averaged stats: loss: 0.3749 (0.8807)  labels_encoder: 0.3749 (0.8807)  labels_encoder_unscaled: 0.3749 (0.8807)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1347, mcAP: 0.8808

BaseballPitch: 0.0402
BasketballDunk: 0.1090
Billiards: 0.0047
CleanAndJerk: 0.4045
CliffDiving: 0.4439
CricketBowling: 0.0768
CricketShot: 0.1079
Diving: 0.0143
FrisbeeCatch: 0.1468
GolfSwing: 0.0632
HammerThrow: 0.1299
HighJump: 0.0655
JavelinThrow: 0.0792
LongJump: 0.3297
PoleVault: 0.1094
Shotput: 0.1342
SoccerPenalty: 0.0562
TennisSwing: 0.1882
ThrowDiscus: 0.0332
VolleyballSpiking: 0.1565
Training time 0:07:21
