Unable to compile CoConv C++ implementation. Falling back to Python version.
[Errno 2] No such file or directory: '/home/lh/.conda/envs/oadtr/lib/python3.8/site-packages/continual/conv.cpp'
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'conv_flops_counter_hook'
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
dropout_p is not supported yet and will be skipped
Failed to add flops_counter_hook: module 'ptflops.flops_counter' has no attribute 'MODULES_MAPPING'
Not using distributed mode
lr:0.0001
batch_size:128
weight_decay:0.0001
epochs:5
resize_feature:False
lr_drop:1
clip_max_norm:1.0
dataparallel:False
removelog:False
version:v3
query_num:8
decoder_layers:5
decoder_embedding_dim:1024
decoder_embedding_dim_out:1024
decoder_attn_dropout_rate:0.1
decoder_num_heads:4
classification_pred_loss_coef:0.5
enc_layers:64
lr_backbone:0.0001
feature:tvseries_kin_features.pickle
dim_feature:4096
patch_dim:1
embedding_dim:1024
num_heads:8
num_layers:2
attn_dropout_rate:0.1
positional_encoding_type:recycling_fixed
num_embeddings:127
hidden_dim:1024
dropout_rate:0.1
numclass:31
classification_x_loss_coef:0.3
classification_h_loss_coef:1
similar_loss_coef:0.1
margin:1.0
dataset:tvseries
dataset_file:data/data_info_new.json
frozen_weights:None
thumos_data_path:/home/dancer/mycode/Temporal.Online.Detection/Online.TRN.Pytorch/preprocess/
thumos_anno_path:data/thumos_{}_anno.pickle
remove_difficult:False
device:cuda
output_dir:models
seed:3
resume:
start_epoch:1
eval:False
num_workers:8
world_size:1
dist_url:tcp://127.0.0.1:12342
train_session_set:['24_ep1', '24_ep2', '24_ep3', 'Breaking_Bad_ep1', 'Breaking_Bad_ep2', 'How_I_Met_Your_Mother_ep1', 'How_I_Met_Your_Mother_ep2', 'How_I_Met_Your_Mother_ep3', 'How_I_Met_Your_Mother_ep4', 'How_I_Met_Your_Mother_ep5', 'How_I_Met_Your_Mother_ep6', 'Mad_Men_ep1', 'Mad_Men_ep2', 'Modern_Family_ep1', 'Modern_Family_ep2', 'Modern_Family_ep3', 'Modern_Family_ep4', 'Modern_Family_ep6', 'Sons_of_Anarchy_ep1', 'Sons_of_Anarchy_ep2']
test_session_set:['24_ep4', 'Breaking_Bad_ep3', 'Mad_Men_ep3', 'How_I_Met_Your_Mother_ep7', 'How_I_Met_Your_Mother_ep8', 'Modern_Family_ep5', 'Sons_of_Anarchy_ep3']
class_index:['background', 'Pick something up', 'Point', 'Drink', 'Stand up', 'Run', 'Sit down', 'Read', 'Smoke', 'Drive car', 'Open door', 'Give something', 'Use computer', 'Write', 'Go down stairway', 'Close door', 'Throw something', 'Go up stairway', 'Get in/out of car', 'Hang up phone', 'Eat', 'Answer phone', 'Dress up', 'Clap', 'Undress', 'Kiss', 'Fall/trip', 'Wave', 'Pour', 'Punch', 'Fire weapon']
distributed:False
position encoding : recycling_fixed
Warning: variables __flops__ or __params__ are already defined for the moduleGELU ptflops can affect your code!
Sequential(
  16.814 M, 99.939% Params, 0.412 GMac, 100.000% MACs, 
  (0): Linear(4.195 M, 24.936% Params, 0.004 GMac, 1.018% MACs, in_features=4096, out_features=1024, bias=True, channel_dim=1)
  (1): RecyclingPositionalEncoding(
    0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 
    (pe): CyclicPositionalEncoding(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, )
  )
  (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
  (3): Sequential(
    12.587 M, 74.814% Params, 0.408 GMac, 98.974% MACs, 
    (0): Sequential(
      6.294 M, 37.407% Params, 0.205 GMac, 49.804% MACs, 
      (0): BroadcastReduce(
        4.194 M, 24.930% Params, 0.071 GMac, 17.179% MACs, reduce=reduce_sum
        (0): RetroactiveUnity(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 63)
        (1): CoReMultiheadAttention(
          4.194 M, 24.930% Params, 0.071 GMac, 17.179% MACs, 
          (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
        )
      )
      (1): Lambda(Sequential(
        2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
        (0): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
        (1): Residual(
          2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
          (fn): Sequential(
            2.099 M, 12.477% Params, 0.134 GMac, 32.625% MACs, 
            (0): Linear(1.05 M, 6.239% Params, 0.067 GMac, 16.305% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
            (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.016% MACs, )
            (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
            (3): Linear(1.05 M, 6.239% Params, 0.067 GMac, 16.305% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
            (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          )
        )
        (2): LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True)
      ))
    )
    (1): Lambda(Sequential(
      6.294 M, 37.407% Params, 0.203 GMac, 49.170% MACs, 
      (0): BroadcastReduce(
        4.194 M, 24.930% Params, 0.203 GMac, 49.153% MACs, reduce=sum_last_pairs
        (0): SelectOrDelay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
        (1): CoSiMultiheadAttention(
          4.194 M, 24.930% Params, 0.203 GMac, 49.153% MACs, 
          (out_proj): NonDynamicallyQuantizableLinear(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=False)
        )
      )
      (1): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
      (2): BroadcastReduce(
        2.099 M, 12.477% Params, 0.0 GMac, 0.017% MACs, reduce=reduce_sum
        (0): Delay(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, 0)
        (1): Sequential(
          2.099 M, 12.477% Params, 0.0 GMac, 0.017% MACs, 
          (0): Linear(1.05 M, 6.239% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
          (1): GELU(0.0 M, 0.000% Params, 0.0 GMac, 0.016% MACs, )
          (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
          (3): Linear(1.05 M, 6.239% Params, 0.0 GMac, 0.000% MACs, in_features=1024, out_features=1024, bias=True, channel_dim=1)
          (4): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.1, inplace=False)
        )
      )
      (3): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
    ), takes_time=True)
    (2): Lambda(unity, squeeze_last, squeeze_last, takes_time=True)
  )
  (4): Lambda(LayerNorm(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, (1024,), eps=1e-05, elementwise_affine=True))
  (5): Linear(0.032 M, 0.189% Params, 0.0 GMac, 0.008% MACs, in_features=1024, out_features=31, bias=True, channel_dim=1)
)
Model FLOPs: 411997217.0
Model params: 16824351
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   67522 KB |   69842 KB |  260138 KB |  192616 KB |
|---------------------------------------------------------------------------|
| Active memory         |   67522 KB |   69842 KB |  260138 KB |  192616 KB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   83968 KB |   83968 KB |   83968 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   16445 KB |   16445 KB |  302954 KB |  286508 KB |
|---------------------------------------------------------------------------|
| Allocations           |      34    |     103    |    3333    |    3299    |
|---------------------------------------------------------------------------|
| Active allocs         |      34    |     103    |    3333    |    3299    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      12    |    1458    |    1448    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Memory state pre, max, post inference: 69143040 71518720 69143040
Loaded tvseries_kin_features.pickle
Loaded tvseries_kin_features.pickle
Start training
Epoch: [1]  [   0/1510]  eta: 1:19:26  lr: 0.000100  loss: 2.9984 (2.9984)  labels_encoder: 2.9984 (2.9984)  labels_encoder_unscaled: 2.9984 (2.9984)  time: 3.1565  data: 2.4454  max mem: 1013
Epoch: [1]  [  50/1510]  eta: 0:04:56  lr: 0.000100  loss: 1.0425 (1.1292)  labels_encoder: 1.0425 (1.1292)  labels_encoder_unscaled: 1.0425 (1.1292)  time: 0.1399  data: 0.0002  max mem: 1206
Epoch: [1]  [ 100/1510]  eta: 0:03:59  lr: 0.000100  loss: 1.0270 (1.0593)  labels_encoder: 1.0270 (1.0593)  labels_encoder_unscaled: 1.0270 (1.0593)  time: 0.1292  data: 0.0002  max mem: 1206
Epoch: [1]  [ 150/1510]  eta: 0:03:35  lr: 0.000100  loss: 0.9479 (1.0245)  labels_encoder: 0.9479 (1.0245)  labels_encoder_unscaled: 0.9479 (1.0245)  time: 0.1435  data: 0.0002  max mem: 1206
Epoch: [1]  [ 200/1510]  eta: 0:03:19  lr: 0.000100  loss: 0.9474 (0.9981)  labels_encoder: 0.9474 (0.9981)  labels_encoder_unscaled: 0.9474 (0.9981)  time: 0.1303  data: 0.0002  max mem: 1206
Epoch: [1]  [ 250/1510]  eta: 0:03:05  lr: 0.000100  loss: 0.7578 (0.9589)  labels_encoder: 0.7578 (0.9589)  labels_encoder_unscaled: 0.7578 (0.9589)  time: 0.1263  data: 0.0002  max mem: 1206
Epoch: [1]  [ 300/1510]  eta: 0:02:55  lr: 0.000100  loss: 0.8508 (0.9422)  labels_encoder: 0.8508 (0.9422)  labels_encoder_unscaled: 0.8508 (0.9422)  time: 0.1313  data: 0.0003  max mem: 1206
Epoch: [1]  [ 350/1510]  eta: 0:02:45  lr: 0.000100  loss: 0.8084 (0.9301)  labels_encoder: 0.8084 (0.9301)  labels_encoder_unscaled: 0.8084 (0.9301)  time: 0.1297  data: 0.0002  max mem: 1206
Epoch: [1]  [ 400/1510]  eta: 0:02:36  lr: 0.000100  loss: 0.8197 (0.9165)  labels_encoder: 0.8197 (0.9165)  labels_encoder_unscaled: 0.8197 (0.9165)  time: 0.1252  data: 0.0002  max mem: 1206
Epoch: [1]  [ 450/1510]  eta: 0:02:28  lr: 0.000100  loss: 0.7672 (0.9027)  labels_encoder: 0.7672 (0.9027)  labels_encoder_unscaled: 0.7672 (0.9027)  time: 0.1363  data: 0.0002  max mem: 1206
Epoch: [1]  [ 500/1510]  eta: 0:02:21  lr: 0.000100  loss: 0.7583 (0.8908)  labels_encoder: 0.7583 (0.8908)  labels_encoder_unscaled: 0.7583 (0.8908)  time: 0.1305  data: 0.0002  max mem: 1206
Epoch: [1]  [ 550/1510]  eta: 0:02:14  lr: 0.000100  loss: 0.7999 (0.8817)  labels_encoder: 0.7999 (0.8817)  labels_encoder_unscaled: 0.7999 (0.8817)  time: 0.1335  data: 0.0002  max mem: 1206
Epoch: [1]  [ 600/1510]  eta: 0:02:06  lr: 0.000100  loss: 0.7373 (0.8734)  labels_encoder: 0.7373 (0.8734)  labels_encoder_unscaled: 0.7373 (0.8734)  time: 0.1273  data: 0.0002  max mem: 1206
Epoch: [1]  [ 650/1510]  eta: 0:01:58  lr: 0.000100  loss: 0.7463 (0.8640)  labels_encoder: 0.7463 (0.8640)  labels_encoder_unscaled: 0.7463 (0.8640)  time: 0.1353  data: 0.0002  max mem: 1206
Epoch: [1]  [ 700/1510]  eta: 0:01:51  lr: 0.000100  loss: 0.7440 (0.8564)  labels_encoder: 0.7440 (0.8564)  labels_encoder_unscaled: 0.7440 (0.8564)  time: 0.1386  data: 0.0002  max mem: 1206
Epoch: [1]  [ 750/1510]  eta: 0:01:44  lr: 0.000100  loss: 0.7257 (0.8508)  labels_encoder: 0.7257 (0.8508)  labels_encoder_unscaled: 0.7257 (0.8508)  time: 0.1391  data: 0.0003  max mem: 1206
Epoch: [1]  [ 800/1510]  eta: 0:01:38  lr: 0.000100  loss: 0.7445 (0.8431)  labels_encoder: 0.7445 (0.8431)  labels_encoder_unscaled: 0.7445 (0.8431)  time: 0.1329  data: 0.0002  max mem: 1206
Epoch: [1]  [ 850/1510]  eta: 0:01:30  lr: 0.000100  loss: 0.6812 (0.8363)  labels_encoder: 0.6812 (0.8363)  labels_encoder_unscaled: 0.6812 (0.8363)  time: 0.1353  data: 0.0002  max mem: 1206
Epoch: [1]  [ 900/1510]  eta: 0:01:23  lr: 0.000100  loss: 0.7064 (0.8294)  labels_encoder: 0.7064 (0.8294)  labels_encoder_unscaled: 0.7064 (0.8294)  time: 0.1305  data: 0.0002  max mem: 1206
Epoch: [1]  [ 950/1510]  eta: 0:01:16  lr: 0.000100  loss: 0.7520 (0.8243)  labels_encoder: 0.7520 (0.8243)  labels_encoder_unscaled: 0.7520 (0.8243)  time: 0.1271  data: 0.0002  max mem: 1206
Epoch: [1]  [1000/1510]  eta: 0:01:10  lr: 0.000100  loss: 0.7401 (0.8194)  labels_encoder: 0.7401 (0.8194)  labels_encoder_unscaled: 0.7401 (0.8194)  time: 0.1448  data: 0.0002  max mem: 1206
Epoch: [1]  [1050/1510]  eta: 0:01:03  lr: 0.000100  loss: 0.7258 (0.8148)  labels_encoder: 0.7258 (0.8148)  labels_encoder_unscaled: 0.7258 (0.8148)  time: 0.1319  data: 0.0002  max mem: 1206
Epoch: [1]  [1100/1510]  eta: 0:00:56  lr: 0.000100  loss: 0.6917 (0.8111)  labels_encoder: 0.6917 (0.8111)  labels_encoder_unscaled: 0.6917 (0.8111)  time: 0.1358  data: 0.0002  max mem: 1206
Epoch: [1]  [1150/1510]  eta: 0:00:49  lr: 0.000100  loss: 0.6720 (0.8069)  labels_encoder: 0.6720 (0.8069)  labels_encoder_unscaled: 0.6720 (0.8069)  time: 0.1291  data: 0.0002  max mem: 1206
Epoch: [1]  [1200/1510]  eta: 0:00:42  lr: 0.000100  loss: 0.6249 (0.8010)  labels_encoder: 0.6249 (0.8010)  labels_encoder_unscaled: 0.6249 (0.8010)  time: 0.1396  data: 0.0002  max mem: 1206
Epoch: [1]  [1250/1510]  eta: 0:00:35  lr: 0.000100  loss: 0.6492 (0.7979)  labels_encoder: 0.6492 (0.7979)  labels_encoder_unscaled: 0.6492 (0.7979)  time: 0.1300  data: 0.0002  max mem: 1206
Epoch: [1]  [1300/1510]  eta: 0:00:28  lr: 0.000100  loss: 0.6254 (0.7930)  labels_encoder: 0.6254 (0.7930)  labels_encoder_unscaled: 0.6254 (0.7930)  time: 0.1290  data: 0.0002  max mem: 1206
Epoch: [1]  [1350/1510]  eta: 0:00:21  lr: 0.000100  loss: 0.6954 (0.7890)  labels_encoder: 0.6954 (0.7890)  labels_encoder_unscaled: 0.6954 (0.7890)  time: 0.1297  data: 0.0002  max mem: 1206
Epoch: [1]  [1400/1510]  eta: 0:00:15  lr: 0.000100  loss: 0.6375 (0.7842)  labels_encoder: 0.6375 (0.7842)  labels_encoder_unscaled: 0.6375 (0.7842)  time: 0.1352  data: 0.0002  max mem: 1206
Epoch: [1]  [1450/1510]  eta: 0:00:08  lr: 0.000100  loss: 0.6527 (0.7808)  labels_encoder: 0.6527 (0.7808)  labels_encoder_unscaled: 0.6527 (0.7808)  time: 0.1362  data: 0.0002  max mem: 1206
Epoch: [1]  [1500/1510]  eta: 0:00:01  lr: 0.000100  loss: 0.6408 (0.7773)  labels_encoder: 0.6408 (0.7773)  labels_encoder_unscaled: 0.6408 (0.7773)  time: 0.1218  data: 0.0003  max mem: 1206
Epoch: [1]  [1509/1510]  eta: 0:00:00  lr: 0.000100  loss: 0.6427 (0.7767)  labels_encoder: 0.6427 (0.7767)  labels_encoder_unscaled: 0.6427 (0.7767)  time: 0.1155  data: 0.0002  max mem: 1206
Epoch: [1] Total time: 0:03:25 (0.1363 s / it)
Averaged stats: lr: 0.000100  loss: 0.6427 (0.7767)  labels_encoder: 0.6427 (0.7767)  labels_encoder_unscaled: 0.6427 (0.7767)
Test:  [  0/559]  eta: 0:18:34  loss: 0.6839 (0.6839)  labels_encoder: 0.6839 (0.6839)  labels_encoder_unscaled: 0.6839 (0.6839)  time: 1.9933  data: 1.9285  max mem: 1206
Test:  [ 50/559]  eta: 0:00:49  loss: 1.5215 (1.1166)  labels_encoder: 1.5215 (1.1166)  labels_encoder_unscaled: 1.5215 (1.1166)  time: 0.0515  data: 0.0001  max mem: 1206
Test:  [100/559]  eta: 0:00:36  loss: 0.7103 (1.0240)  labels_encoder: 0.7103 (1.0240)  labels_encoder_unscaled: 0.7103 (1.0240)  time: 0.0618  data: 0.0002  max mem: 1206
Test:  [150/559]  eta: 0:00:29  loss: 0.5596 (1.0036)  labels_encoder: 0.5596 (1.0036)  labels_encoder_unscaled: 0.5596 (1.0036)  time: 0.0592  data: 0.0002  max mem: 1206
Test:  [200/559]  eta: 0:00:24  loss: 0.7041 (0.9150)  labels_encoder: 0.7041 (0.9150)  labels_encoder_unscaled: 0.7041 (0.9150)  time: 0.0564  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:20  loss: 0.9428 (1.0323)  labels_encoder: 0.9428 (1.0323)  labels_encoder_unscaled: 0.9428 (1.0323)  time: 0.0622  data: 0.0002  max mem: 1206
Test:  [300/559]  eta: 0:00:16  loss: 1.4799 (1.0832)  labels_encoder: 1.4799 (1.0832)  labels_encoder_unscaled: 1.4799 (1.0832)  time: 0.0565  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:13  loss: 0.8287 (1.0975)  labels_encoder: 0.8287 (1.0975)  labels_encoder_unscaled: 0.8287 (1.0975)  time: 0.0655  data: 0.0002  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.4465 (1.0674)  labels_encoder: 0.4465 (1.0674)  labels_encoder_unscaled: 0.4465 (1.0674)  time: 0.0549  data: 0.0001  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.3984 (1.0329)  labels_encoder: 0.3984 (1.0329)  labels_encoder_unscaled: 0.3984 (1.0329)  time: 0.0592  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.6348 (1.0105)  labels_encoder: 0.6348 (1.0105)  labels_encoder_unscaled: 0.6348 (1.0105)  time: 0.0514  data: 0.0001  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.8395 (0.9850)  labels_encoder: 0.8395 (0.9850)  labels_encoder_unscaled: 0.8395 (0.9850)  time: 0.0477  data: 0.0001  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.7181 (0.9792)  labels_encoder: 0.7181 (0.9792)  labels_encoder_unscaled: 0.7181 (0.9792)  time: 0.0396  data: 0.0001  max mem: 1206
Test: Total time: 0:00:34 (0.0621 s / it)
Averaged stats: loss: 0.7181 (0.9792)  labels_encoder: 0.7181 (0.9792)  labels_encoder_unscaled: 0.7181 (0.9792)
(21, 71496)
(21, 71496)
[Epoch-1] [IDU-tvseries_kin_features.pickle] mAP: 0.1234, mcAP: 0.8796

BaseballPitch: 0.0473
BasketballDunk: 0.0744
Billiards: 0.0049
CleanAndJerk: 0.3767
CliffDiving: 0.5431
CricketBowling: 0.0579
CricketShot: 0.0833
Diving: 0.0259
FrisbeeCatch: 0.0800
GolfSwing: 0.0259
HammerThrow: 0.0973
HighJump: 0.0483
JavelinThrow: 0.0682
LongJump: 0.3033
PoleVault: 0.0862
Shotput: 0.1216
SoccerPenalty: 0.0536
TennisSwing: 0.1356
ThrowDiscus: 0.1071
VolleyballSpiking: 0.1277
Epoch: [2]  [   0/1510]  eta: 0:48:08  lr: 0.000010  loss: 0.6374 (0.6374)  labels_encoder: 0.6374 (0.6374)  labels_encoder_unscaled: 0.6374 (0.6374)  time: 1.9131  data: 1.7229  max mem: 1206
Epoch: [2]  [  50/1510]  eta: 0:04:18  lr: 0.000010  loss: 0.6403 (0.6332)  labels_encoder: 0.6403 (0.6332)  labels_encoder_unscaled: 0.6403 (0.6332)  time: 0.1374  data: 0.0002  max mem: 1206
Epoch: [2]  [ 100/1510]  eta: 0:03:39  lr: 0.000010  loss: 0.6383 (0.6342)  labels_encoder: 0.6383 (0.6342)  labels_encoder_unscaled: 0.6383 (0.6342)  time: 0.1343  data: 0.0002  max mem: 1206
Epoch: [2]  [ 150/1510]  eta: 0:03:24  lr: 0.000010  loss: 0.5802 (0.6215)  labels_encoder: 0.5802 (0.6215)  labels_encoder_unscaled: 0.5802 (0.6215)  time: 0.1413  data: 0.0002  max mem: 1206
Epoch: [2]  [ 200/1510]  eta: 0:03:14  lr: 0.000010  loss: 0.5431 (0.6239)  labels_encoder: 0.5431 (0.6239)  labels_encoder_unscaled: 0.5431 (0.6239)  time: 0.1475  data: 0.0002  max mem: 1206
Epoch: [2]  [ 250/1510]  eta: 0:03:03  lr: 0.000010  loss: 0.6193 (0.6174)  labels_encoder: 0.6193 (0.6174)  labels_encoder_unscaled: 0.6193 (0.6174)  time: 0.1300  data: 0.0002  max mem: 1206
Epoch: [2]  [ 300/1510]  eta: 0:02:54  lr: 0.000010  loss: 0.5624 (0.6099)  labels_encoder: 0.5624 (0.6099)  labels_encoder_unscaled: 0.5624 (0.6099)  time: 0.1270  data: 0.0002  max mem: 1206
Epoch: [2]  [ 350/1510]  eta: 0:02:46  lr: 0.000010  loss: 0.6170 (0.6091)  labels_encoder: 0.6170 (0.6091)  labels_encoder_unscaled: 0.6170 (0.6091)  time: 0.1433  data: 0.0002  max mem: 1206
Epoch: [2]  [ 400/1510]  eta: 0:02:37  lr: 0.000010  loss: 0.5324 (0.6042)  labels_encoder: 0.5324 (0.6042)  labels_encoder_unscaled: 0.5324 (0.6042)  time: 0.1349  data: 0.0002  max mem: 1206
Epoch: [2]  [ 450/1510]  eta: 0:02:29  lr: 0.000010  loss: 0.5920 (0.6022)  labels_encoder: 0.5920 (0.6022)  labels_encoder_unscaled: 0.5920 (0.6022)  time: 0.1466  data: 0.0003  max mem: 1206
Epoch: [2]  [ 500/1510]  eta: 0:02:22  lr: 0.000010  loss: 0.5902 (0.5993)  labels_encoder: 0.5902 (0.5993)  labels_encoder_unscaled: 0.5902 (0.5993)  time: 0.1336  data: 0.0002  max mem: 1206
Epoch: [2]  [ 550/1510]  eta: 0:02:14  lr: 0.000010  loss: 0.5999 (0.5978)  labels_encoder: 0.5999 (0.5978)  labels_encoder_unscaled: 0.5999 (0.5978)  time: 0.1388  data: 0.0002  max mem: 1206
Epoch: [2]  [ 600/1510]  eta: 0:02:07  lr: 0.000010  loss: 0.5511 (0.5934)  labels_encoder: 0.5511 (0.5934)  labels_encoder_unscaled: 0.5511 (0.5934)  time: 0.1379  data: 0.0002  max mem: 1206
Epoch: [2]  [ 650/1510]  eta: 0:02:00  lr: 0.000010  loss: 0.5558 (0.5916)  labels_encoder: 0.5558 (0.5916)  labels_encoder_unscaled: 0.5558 (0.5916)  time: 0.1419  data: 0.0002  max mem: 1206
Epoch: [2]  [ 700/1510]  eta: 0:01:53  lr: 0.000010  loss: 0.5511 (0.5910)  labels_encoder: 0.5511 (0.5910)  labels_encoder_unscaled: 0.5511 (0.5910)  time: 0.1405  data: 0.0003  max mem: 1206
Epoch: [2]  [ 750/1510]  eta: 0:01:46  lr: 0.000010  loss: 0.5543 (0.5886)  labels_encoder: 0.5543 (0.5886)  labels_encoder_unscaled: 0.5543 (0.5886)  time: 0.1365  data: 0.0002  max mem: 1206
Epoch: [2]  [ 800/1510]  eta: 0:01:39  lr: 0.000010  loss: 0.5764 (0.5879)  labels_encoder: 0.5764 (0.5879)  labels_encoder_unscaled: 0.5764 (0.5879)  time: 0.1414  data: 0.0003  max mem: 1206
Epoch: [2]  [ 850/1510]  eta: 0:01:31  lr: 0.000010  loss: 0.6133 (0.5874)  labels_encoder: 0.6133 (0.5874)  labels_encoder_unscaled: 0.6133 (0.5874)  time: 0.1283  data: 0.0002  max mem: 1206
Epoch: [2]  [ 900/1510]  eta: 0:01:24  lr: 0.000010  loss: 0.5015 (0.5842)  labels_encoder: 0.5015 (0.5842)  labels_encoder_unscaled: 0.5015 (0.5842)  time: 0.1342  data: 0.0002  max mem: 1206
Epoch: [2]  [ 950/1510]  eta: 0:01:17  lr: 0.000010  loss: 0.5921 (0.5835)  labels_encoder: 0.5921 (0.5835)  labels_encoder_unscaled: 0.5921 (0.5835)  time: 0.1330  data: 0.0002  max mem: 1206
Epoch: [2]  [1000/1510]  eta: 0:01:10  lr: 0.000010  loss: 0.5416 (0.5819)  labels_encoder: 0.5416 (0.5819)  labels_encoder_unscaled: 0.5416 (0.5819)  time: 0.1246  data: 0.0002  max mem: 1206
Epoch: [2]  [1050/1510]  eta: 0:01:03  lr: 0.000010  loss: 0.5452 (0.5800)  labels_encoder: 0.5452 (0.5800)  labels_encoder_unscaled: 0.5452 (0.5800)  time: 0.1384  data: 0.0002  max mem: 1206
Epoch: [2]  [1100/1510]  eta: 0:00:56  lr: 0.000010  loss: 0.5614 (0.5789)  labels_encoder: 0.5614 (0.5789)  labels_encoder_unscaled: 0.5614 (0.5789)  time: 0.1297  data: 0.0002  max mem: 1206
Epoch: [2]  [1150/1510]  eta: 0:00:49  lr: 0.000010  loss: 0.5195 (0.5782)  labels_encoder: 0.5195 (0.5782)  labels_encoder_unscaled: 0.5195 (0.5782)  time: 0.1403  data: 0.0002  max mem: 1206
Epoch: [2]  [1200/1510]  eta: 0:00:42  lr: 0.000010  loss: 0.5382 (0.5767)  labels_encoder: 0.5382 (0.5767)  labels_encoder_unscaled: 0.5382 (0.5767)  time: 0.1471  data: 0.0002  max mem: 1206
Epoch: [2]  [1250/1510]  eta: 0:00:35  lr: 0.000010  loss: 0.5708 (0.5760)  labels_encoder: 0.5708 (0.5760)  labels_encoder_unscaled: 0.5708 (0.5760)  time: 0.1422  data: 0.0002  max mem: 1206
Epoch: [2]  [1300/1510]  eta: 0:00:29  lr: 0.000010  loss: 0.5303 (0.5760)  labels_encoder: 0.5303 (0.5760)  labels_encoder_unscaled: 0.5303 (0.5760)  time: 0.1399  data: 0.0003  max mem: 1206
Epoch: [2]  [1350/1510]  eta: 0:00:22  lr: 0.000010  loss: 0.5391 (0.5750)  labels_encoder: 0.5391 (0.5750)  labels_encoder_unscaled: 0.5391 (0.5750)  time: 0.1269  data: 0.0002  max mem: 1206
Epoch: [2]  [1400/1510]  eta: 0:00:15  lr: 0.000010  loss: 0.5577 (0.5741)  labels_encoder: 0.5577 (0.5741)  labels_encoder_unscaled: 0.5577 (0.5741)  time: 0.1377  data: 0.0002  max mem: 1206
Epoch: [2]  [1450/1510]  eta: 0:00:08  lr: 0.000010  loss: 0.5437 (0.5733)  labels_encoder: 0.5437 (0.5733)  labels_encoder_unscaled: 0.5437 (0.5733)  time: 0.1470  data: 0.0002  max mem: 1206
Epoch: [2]  [1500/1510]  eta: 0:00:01  lr: 0.000010  loss: 0.5016 (0.5714)  labels_encoder: 0.5016 (0.5714)  labels_encoder_unscaled: 0.5016 (0.5714)  time: 0.1388  data: 0.0003  max mem: 1206
Epoch: [2]  [1509/1510]  eta: 0:00:00  lr: 0.000010  loss: 0.5016 (0.5715)  labels_encoder: 0.5016 (0.5715)  labels_encoder_unscaled: 0.5016 (0.5715)  time: 0.1263  data: 0.0003  max mem: 1206
Epoch: [2] Total time: 0:03:28 (0.1384 s / it)
Averaged stats: lr: 0.000010  loss: 0.5016 (0.5715)  labels_encoder: 0.5016 (0.5715)  labels_encoder_unscaled: 0.5016 (0.5715)
Test:  [  0/559]  eta: 0:16:56  loss: 0.6029 (0.6029)  labels_encoder: 0.6029 (0.6029)  labels_encoder_unscaled: 0.6029 (0.6029)  time: 1.8186  data: 1.7519  max mem: 1206
Test:  [ 50/559]  eta: 0:00:49  loss: 0.8335 (0.9127)  labels_encoder: 0.8335 (0.9127)  labels_encoder_unscaled: 0.8335 (0.9127)  time: 0.0665  data: 0.0002  max mem: 1206
Test:  [100/559]  eta: 0:00:36  loss: 0.4620 (0.8525)  labels_encoder: 0.4620 (0.8525)  labels_encoder_unscaled: 0.4620 (0.8525)  time: 0.0582  data: 0.0002  max mem: 1206
Test:  [150/559]  eta: 0:00:29  loss: 0.5303 (0.8691)  labels_encoder: 0.5303 (0.8691)  labels_encoder_unscaled: 0.5303 (0.8691)  time: 0.0651  data: 0.0002  max mem: 1206
Test:  [200/559]  eta: 0:00:24  loss: 0.6501 (0.8150)  labels_encoder: 0.6501 (0.8150)  labels_encoder_unscaled: 0.6501 (0.8150)  time: 0.0530  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:20  loss: 0.8605 (0.9272)  labels_encoder: 0.8605 (0.9272)  labels_encoder_unscaled: 0.8605 (0.9272)  time: 0.0550  data: 0.0002  max mem: 1206
Test:  [300/559]  eta: 0:00:16  loss: 1.1322 (0.9754)  labels_encoder: 1.1322 (0.9754)  labels_encoder_unscaled: 1.1322 (0.9754)  time: 0.0584  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:13  loss: 0.8038 (0.9970)  labels_encoder: 0.8038 (0.9970)  labels_encoder_unscaled: 0.8038 (0.9970)  time: 0.0603  data: 0.0002  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.3031 (0.9744)  labels_encoder: 0.3031 (0.9744)  labels_encoder_unscaled: 0.3031 (0.9744)  time: 0.0540  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.4108 (0.9510)  labels_encoder: 0.4108 (0.9510)  labels_encoder_unscaled: 0.4108 (0.9510)  time: 0.0519  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.5930 (0.9352)  labels_encoder: 0.5930 (0.9352)  labels_encoder_unscaled: 0.5930 (0.9352)  time: 0.0538  data: 0.0002  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.7105 (0.9102)  labels_encoder: 0.7105 (0.9102)  labels_encoder_unscaled: 0.7105 (0.9102)  time: 0.0484  data: 0.0001  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3556 (0.9037)  labels_encoder: 0.3556 (0.9037)  labels_encoder_unscaled: 0.3556 (0.9037)  time: 0.0388  data: 0.0001  max mem: 1206
Test: Total time: 0:00:34 (0.0610 s / it)
Averaged stats: loss: 0.3556 (0.9037)  labels_encoder: 0.3556 (0.9037)  labels_encoder_unscaled: 0.3556 (0.9037)
(21, 71496)
(21, 71496)
[Epoch-2] [IDU-tvseries_kin_features.pickle] mAP: 0.1259, mcAP: 0.8815

BaseballPitch: 0.0470
BasketballDunk: 0.1034
Billiards: 0.0045
CleanAndJerk: 0.3768
CliffDiving: 0.4737
CricketBowling: 0.0546
CricketShot: 0.1050
Diving: 0.0115
FrisbeeCatch: 0.1203
GolfSwing: 0.0569
HammerThrow: 0.1002
HighJump: 0.0456
JavelinThrow: 0.0564
LongJump: 0.2940
PoleVault: 0.1103
Shotput: 0.1331
SoccerPenalty: 0.0515
TennisSwing: 0.1733
ThrowDiscus: 0.0511
VolleyballSpiking: 0.1488
Epoch: [3]  [   0/1510]  eta: 0:53:52  lr: 0.000001  loss: 0.4268 (0.4268)  labels_encoder: 0.4268 (0.4268)  labels_encoder_unscaled: 0.4268 (0.4268)  time: 2.1406  data: 1.9699  max mem: 1206
Epoch: [3]  [  50/1510]  eta: 0:04:04  lr: 0.000001  loss: 0.5150 (0.5475)  labels_encoder: 0.5150 (0.5475)  labels_encoder_unscaled: 0.5150 (0.5475)  time: 0.1260  data: 0.0002  max mem: 1206
Epoch: [3]  [ 100/1510]  eta: 0:03:34  lr: 0.000001  loss: 0.5192 (0.5376)  labels_encoder: 0.5192 (0.5376)  labels_encoder_unscaled: 0.5192 (0.5376)  time: 0.1376  data: 0.0002  max mem: 1206
Epoch: [3]  [ 150/1510]  eta: 0:03:20  lr: 0.000001  loss: 0.5291 (0.5304)  labels_encoder: 0.5291 (0.5304)  labels_encoder_unscaled: 0.5291 (0.5304)  time: 0.1386  data: 0.0002  max mem: 1206
Epoch: [3]  [ 200/1510]  eta: 0:03:08  lr: 0.000001  loss: 0.4915 (0.5360)  labels_encoder: 0.4915 (0.5360)  labels_encoder_unscaled: 0.4915 (0.5360)  time: 0.1294  data: 0.0002  max mem: 1206
Epoch: [3]  [ 250/1510]  eta: 0:02:59  lr: 0.000001  loss: 0.5028 (0.5341)  labels_encoder: 0.5028 (0.5341)  labels_encoder_unscaled: 0.5028 (0.5341)  time: 0.1367  data: 0.0002  max mem: 1206
Epoch: [3]  [ 300/1510]  eta: 0:02:50  lr: 0.000001  loss: 0.5135 (0.5342)  labels_encoder: 0.5135 (0.5342)  labels_encoder_unscaled: 0.5135 (0.5342)  time: 0.1291  data: 0.0002  max mem: 1206
Epoch: [3]  [ 350/1510]  eta: 0:02:41  lr: 0.000001  loss: 0.4883 (0.5316)  labels_encoder: 0.4883 (0.5316)  labels_encoder_unscaled: 0.4883 (0.5316)  time: 0.1272  data: 0.0002  max mem: 1206
Epoch: [3]  [ 400/1510]  eta: 0:02:33  lr: 0.000001  loss: 0.4881 (0.5310)  labels_encoder: 0.4881 (0.5310)  labels_encoder_unscaled: 0.4881 (0.5310)  time: 0.1350  data: 0.0002  max mem: 1206
Epoch: [3]  [ 450/1510]  eta: 0:02:25  lr: 0.000001  loss: 0.5454 (0.5303)  labels_encoder: 0.5454 (0.5303)  labels_encoder_unscaled: 0.5454 (0.5303)  time: 0.1241  data: 0.0002  max mem: 1206
Epoch: [3]  [ 500/1510]  eta: 0:02:17  lr: 0.000001  loss: 0.5377 (0.5297)  labels_encoder: 0.5377 (0.5297)  labels_encoder_unscaled: 0.5377 (0.5297)  time: 0.1355  data: 0.0002  max mem: 1206
Epoch: [3]  [ 550/1510]  eta: 0:02:10  lr: 0.000001  loss: 0.5737 (0.5301)  labels_encoder: 0.5737 (0.5301)  labels_encoder_unscaled: 0.5737 (0.5301)  time: 0.1393  data: 0.0003  max mem: 1206
Epoch: [3]  [ 600/1510]  eta: 0:02:04  lr: 0.000001  loss: 0.5528 (0.5310)  labels_encoder: 0.5528 (0.5310)  labels_encoder_unscaled: 0.5528 (0.5310)  time: 0.1383  data: 0.0002  max mem: 1206
Epoch: [3]  [ 650/1510]  eta: 0:01:58  lr: 0.000001  loss: 0.5023 (0.5302)  labels_encoder: 0.5023 (0.5302)  labels_encoder_unscaled: 0.5023 (0.5302)  time: 0.1518  data: 0.0003  max mem: 1206
Epoch: [3]  [ 700/1510]  eta: 0:01:51  lr: 0.000001  loss: 0.5351 (0.5310)  labels_encoder: 0.5351 (0.5310)  labels_encoder_unscaled: 0.5351 (0.5310)  time: 0.1472  data: 0.0002  max mem: 1206
Epoch: [3]  [ 750/1510]  eta: 0:01:45  lr: 0.000001  loss: 0.5166 (0.5302)  labels_encoder: 0.5166 (0.5302)  labels_encoder_unscaled: 0.5166 (0.5302)  time: 0.1389  data: 0.0002  max mem: 1206
Epoch: [3]  [ 800/1510]  eta: 0:01:38  lr: 0.000001  loss: 0.5173 (0.5296)  labels_encoder: 0.5173 (0.5296)  labels_encoder_unscaled: 0.5173 (0.5296)  time: 0.1374  data: 0.0002  max mem: 1206
Epoch: [3]  [ 850/1510]  eta: 0:01:31  lr: 0.000001  loss: 0.5346 (0.5291)  labels_encoder: 0.5346 (0.5291)  labels_encoder_unscaled: 0.5346 (0.5291)  time: 0.1427  data: 0.0002  max mem: 1206
Epoch: [3]  [ 900/1510]  eta: 0:01:24  lr: 0.000001  loss: 0.4762 (0.5284)  labels_encoder: 0.4762 (0.5284)  labels_encoder_unscaled: 0.4762 (0.5284)  time: 0.1321  data: 0.0002  max mem: 1206
Epoch: [3]  [ 950/1510]  eta: 0:01:17  lr: 0.000001  loss: 0.5244 (0.5286)  labels_encoder: 0.5244 (0.5286)  labels_encoder_unscaled: 0.5244 (0.5286)  time: 0.1390  data: 0.0002  max mem: 1206
Epoch: [3]  [1000/1510]  eta: 0:01:10  lr: 0.000001  loss: 0.4918 (0.5283)  labels_encoder: 0.4918 (0.5283)  labels_encoder_unscaled: 0.4918 (0.5283)  time: 0.1274  data: 0.0002  max mem: 1206
Epoch: [3]  [1050/1510]  eta: 0:01:03  lr: 0.000001  loss: 0.5145 (0.5277)  labels_encoder: 0.5145 (0.5277)  labels_encoder_unscaled: 0.5145 (0.5277)  time: 0.1264  data: 0.0002  max mem: 1206
Epoch: [3]  [1100/1510]  eta: 0:00:56  lr: 0.000001  loss: 0.5548 (0.5276)  labels_encoder: 0.5548 (0.5276)  labels_encoder_unscaled: 0.5548 (0.5276)  time: 0.1361  data: 0.0002  max mem: 1206
Epoch: [3]  [1150/1510]  eta: 0:00:49  lr: 0.000001  loss: 0.5301 (0.5269)  labels_encoder: 0.5301 (0.5269)  labels_encoder_unscaled: 0.5301 (0.5269)  time: 0.1277  data: 0.0002  max mem: 1206
Epoch: [3]  [1200/1510]  eta: 0:00:42  lr: 0.000001  loss: 0.5171 (0.5270)  labels_encoder: 0.5171 (0.5270)  labels_encoder_unscaled: 0.5171 (0.5270)  time: 0.1319  data: 0.0002  max mem: 1206
Epoch: [3]  [1250/1510]  eta: 0:00:35  lr: 0.000001  loss: 0.5598 (0.5283)  labels_encoder: 0.5598 (0.5283)  labels_encoder_unscaled: 0.5598 (0.5283)  time: 0.1328  data: 0.0002  max mem: 1206
Epoch: [3]  [1300/1510]  eta: 0:00:28  lr: 0.000001  loss: 0.5081 (0.5278)  labels_encoder: 0.5081 (0.5278)  labels_encoder_unscaled: 0.5081 (0.5278)  time: 0.1260  data: 0.0002  max mem: 1206
Epoch: [3]  [1350/1510]  eta: 0:00:21  lr: 0.000001  loss: 0.5040 (0.5275)  labels_encoder: 0.5040 (0.5275)  labels_encoder_unscaled: 0.5040 (0.5275)  time: 0.1448  data: 0.0002  max mem: 1206
Epoch: [3]  [1400/1510]  eta: 0:00:15  lr: 0.000001  loss: 0.4825 (0.5276)  labels_encoder: 0.4825 (0.5276)  labels_encoder_unscaled: 0.4825 (0.5276)  time: 0.1362  data: 0.0002  max mem: 1206
Epoch: [3]  [1450/1510]  eta: 0:00:08  lr: 0.000001  loss: 0.4800 (0.5274)  labels_encoder: 0.4800 (0.5274)  labels_encoder_unscaled: 0.4800 (0.5274)  time: 0.1387  data: 0.0002  max mem: 1206
Epoch: [3]  [1500/1510]  eta: 0:00:01  lr: 0.000001  loss: 0.4945 (0.5271)  labels_encoder: 0.4945 (0.5271)  labels_encoder_unscaled: 0.4945 (0.5271)  time: 0.1328  data: 0.0004  max mem: 1206
Epoch: [3]  [1509/1510]  eta: 0:00:00  lr: 0.000001  loss: 0.5240 (0.5271)  labels_encoder: 0.5240 (0.5271)  labels_encoder_unscaled: 0.5240 (0.5271)  time: 0.1254  data: 0.0004  max mem: 1206
Epoch: [3] Total time: 0:03:26 (0.1371 s / it)
Averaged stats: lr: 0.000001  loss: 0.5240 (0.5271)  labels_encoder: 0.5240 (0.5271)  labels_encoder_unscaled: 0.5240 (0.5271)
Test:  [  0/559]  eta: 0:15:54  loss: 0.5446 (0.5446)  labels_encoder: 0.5446 (0.5446)  labels_encoder_unscaled: 0.5446 (0.5446)  time: 1.7077  data: 1.6338  max mem: 1206
Test:  [ 50/559]  eta: 0:00:51  loss: 0.7762 (0.8752)  labels_encoder: 0.7762 (0.8752)  labels_encoder_unscaled: 0.7762 (0.8752)  time: 0.0589  data: 0.0002  max mem: 1206
Test:  [100/559]  eta: 0:00:37  loss: 0.5959 (0.8466)  labels_encoder: 0.5959 (0.8466)  labels_encoder_unscaled: 0.5959 (0.8466)  time: 0.0649  data: 0.0002  max mem: 1206
Test:  [150/559]  eta: 0:00:30  loss: 0.5090 (0.8683)  labels_encoder: 0.5090 (0.8683)  labels_encoder_unscaled: 0.5090 (0.8683)  time: 0.0625  data: 0.0002  max mem: 1206
Test:  [200/559]  eta: 0:00:25  loss: 0.6268 (0.8110)  labels_encoder: 0.6268 (0.8110)  labels_encoder_unscaled: 0.6268 (0.8110)  time: 0.0631  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:21  loss: 0.6905 (0.9239)  labels_encoder: 0.6905 (0.9239)  labels_encoder_unscaled: 0.6905 (0.9239)  time: 0.0595  data: 0.0002  max mem: 1206
Test:  [300/559]  eta: 0:00:17  loss: 1.0745 (0.9807)  labels_encoder: 1.0745 (0.9807)  labels_encoder_unscaled: 1.0745 (0.9807)  time: 0.0594  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:13  loss: 0.7501 (1.0045)  labels_encoder: 0.7501 (1.0045)  labels_encoder_unscaled: 0.7501 (1.0045)  time: 0.0634  data: 0.0002  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.3453 (0.9771)  labels_encoder: 0.3453 (0.9771)  labels_encoder_unscaled: 0.3453 (0.9771)  time: 0.0634  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:07  loss: 0.4316 (0.9519)  labels_encoder: 0.4316 (0.9519)  labels_encoder_unscaled: 0.4316 (0.9519)  time: 0.0577  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.6151 (0.9320)  labels_encoder: 0.6151 (0.9320)  labels_encoder_unscaled: 0.6151 (0.9320)  time: 0.0587  data: 0.0002  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.7281 (0.9069)  labels_encoder: 0.7281 (0.9069)  labels_encoder_unscaled: 0.7281 (0.9069)  time: 0.0556  data: 0.0001  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3705 (0.9003)  labels_encoder: 0.3705 (0.9003)  labels_encoder_unscaled: 0.3705 (0.9003)  time: 0.0378  data: 0.0001  max mem: 1206
Test: Total time: 0:00:36 (0.0644 s / it)
Averaged stats: loss: 0.3705 (0.9003)  labels_encoder: 0.3705 (0.9003)  labels_encoder_unscaled: 0.3705 (0.9003)
(21, 71496)
(21, 71496)
[Epoch-3] [IDU-tvseries_kin_features.pickle] mAP: 0.1295, mcAP: 0.8822

BaseballPitch: 0.0442
BasketballDunk: 0.1158
Billiards: 0.0045
CleanAndJerk: 0.4182
CliffDiving: 0.3974
CricketBowling: 0.0503
CricketShot: 0.0883
Diving: 0.0072
FrisbeeCatch: 0.1102
GolfSwing: 0.0496
HammerThrow: 0.1117
HighJump: 0.0633
JavelinThrow: 0.0574
LongJump: 0.3108
PoleVault: 0.1002
Shotput: 0.1383
SoccerPenalty: 0.0503
TennisSwing: 0.1747
ThrowDiscus: 0.1466
VolleyballSpiking: 0.1514
Epoch: [4]  [   0/1510]  eta: 0:49:13  lr: 0.000000  loss: 0.5127 (0.5127)  labels_encoder: 0.5127 (0.5127)  labels_encoder_unscaled: 0.5127 (0.5127)  time: 1.9560  data: 1.8395  max mem: 1206
Epoch: [4]  [  50/1510]  eta: 0:03:52  lr: 0.000000  loss: 0.5303 (0.5264)  labels_encoder: 0.5303 (0.5264)  labels_encoder_unscaled: 0.5303 (0.5264)  time: 0.1175  data: 0.0002  max mem: 1206
Epoch: [4]  [ 100/1510]  eta: 0:03:28  lr: 0.000000  loss: 0.5415 (0.5286)  labels_encoder: 0.5415 (0.5286)  labels_encoder_unscaled: 0.5415 (0.5286)  time: 0.1408  data: 0.0002  max mem: 1206
Epoch: [4]  [ 150/1510]  eta: 0:03:13  lr: 0.000000  loss: 0.4368 (0.5191)  labels_encoder: 0.4368 (0.5191)  labels_encoder_unscaled: 0.4368 (0.5191)  time: 0.1386  data: 0.0002  max mem: 1206
Epoch: [4]  [ 200/1510]  eta: 0:03:03  lr: 0.000000  loss: 0.4567 (0.5163)  labels_encoder: 0.4567 (0.5163)  labels_encoder_unscaled: 0.4567 (0.5163)  time: 0.1335  data: 0.0002  max mem: 1206
Epoch: [4]  [ 250/1510]  eta: 0:02:56  lr: 0.000000  loss: 0.4976 (0.5206)  labels_encoder: 0.4976 (0.5206)  labels_encoder_unscaled: 0.4976 (0.5206)  time: 0.1436  data: 0.0003  max mem: 1206
Epoch: [4]  [ 300/1510]  eta: 0:02:48  lr: 0.000000  loss: 0.5221 (0.5225)  labels_encoder: 0.5221 (0.5225)  labels_encoder_unscaled: 0.5221 (0.5225)  time: 0.1271  data: 0.0002  max mem: 1206
Epoch: [4]  [ 350/1510]  eta: 0:02:40  lr: 0.000000  loss: 0.5225 (0.5199)  labels_encoder: 0.5225 (0.5199)  labels_encoder_unscaled: 0.5225 (0.5199)  time: 0.1299  data: 0.0002  max mem: 1206
Epoch: [4]  [ 400/1510]  eta: 0:02:33  lr: 0.000000  loss: 0.5332 (0.5198)  labels_encoder: 0.5332 (0.5198)  labels_encoder_unscaled: 0.5332 (0.5198)  time: 0.1359  data: 0.0002  max mem: 1206
Epoch: [4]  [ 450/1510]  eta: 0:02:25  lr: 0.000000  loss: 0.4858 (0.5202)  labels_encoder: 0.4858 (0.5202)  labels_encoder_unscaled: 0.4858 (0.5202)  time: 0.1258  data: 0.0002  max mem: 1206
Epoch: [4]  [ 500/1510]  eta: 0:02:18  lr: 0.000000  loss: 0.4923 (0.5206)  labels_encoder: 0.4923 (0.5206)  labels_encoder_unscaled: 0.4923 (0.5206)  time: 0.1373  data: 0.0002  max mem: 1206
Epoch: [4]  [ 550/1510]  eta: 0:02:11  lr: 0.000000  loss: 0.5121 (0.5205)  labels_encoder: 0.5121 (0.5205)  labels_encoder_unscaled: 0.5121 (0.5205)  time: 0.1362  data: 0.0002  max mem: 1206
Epoch: [4]  [ 600/1510]  eta: 0:02:04  lr: 0.000000  loss: 0.4592 (0.5205)  labels_encoder: 0.4592 (0.5205)  labels_encoder_unscaled: 0.4592 (0.5205)  time: 0.1416  data: 0.0002  max mem: 1206
Epoch: [4]  [ 650/1510]  eta: 0:01:57  lr: 0.000000  loss: 0.4784 (0.5212)  labels_encoder: 0.4784 (0.5212)  labels_encoder_unscaled: 0.4784 (0.5212)  time: 0.1319  data: 0.0002  max mem: 1206
Epoch: [4]  [ 700/1510]  eta: 0:01:50  lr: 0.000000  loss: 0.4965 (0.5219)  labels_encoder: 0.4965 (0.5219)  labels_encoder_unscaled: 0.4965 (0.5219)  time: 0.1348  data: 0.0002  max mem: 1206
Epoch: [4]  [ 750/1510]  eta: 0:01:43  lr: 0.000000  loss: 0.5436 (0.5217)  labels_encoder: 0.5436 (0.5217)  labels_encoder_unscaled: 0.5436 (0.5217)  time: 0.1273  data: 0.0002  max mem: 1206
Epoch: [4]  [ 800/1510]  eta: 0:01:36  lr: 0.000000  loss: 0.5038 (0.5222)  labels_encoder: 0.5038 (0.5222)  labels_encoder_unscaled: 0.5038 (0.5222)  time: 0.1405  data: 0.0002  max mem: 1206
Epoch: [4]  [ 850/1510]  eta: 0:01:29  lr: 0.000000  loss: 0.4734 (0.5217)  labels_encoder: 0.4734 (0.5217)  labels_encoder_unscaled: 0.4734 (0.5217)  time: 0.1279  data: 0.0002  max mem: 1206
Epoch: [4]  [ 900/1510]  eta: 0:01:23  lr: 0.000000  loss: 0.5321 (0.5228)  labels_encoder: 0.5321 (0.5228)  labels_encoder_unscaled: 0.5321 (0.5228)  time: 0.1316  data: 0.0002  max mem: 1206
Epoch: [4]  [ 950/1510]  eta: 0:01:16  lr: 0.000000  loss: 0.4915 (0.5231)  labels_encoder: 0.4915 (0.5231)  labels_encoder_unscaled: 0.4915 (0.5231)  time: 0.1307  data: 0.0002  max mem: 1206
Epoch: [4]  [1000/1510]  eta: 0:01:09  lr: 0.000000  loss: 0.5494 (0.5240)  labels_encoder: 0.5494 (0.5240)  labels_encoder_unscaled: 0.5494 (0.5240)  time: 0.1262  data: 0.0002  max mem: 1206
Epoch: [4]  [1050/1510]  eta: 0:01:02  lr: 0.000000  loss: 0.4478 (0.5232)  labels_encoder: 0.4478 (0.5232)  labels_encoder_unscaled: 0.4478 (0.5232)  time: 0.1345  data: 0.0002  max mem: 1206
Epoch: [4]  [1100/1510]  eta: 0:00:55  lr: 0.000000  loss: 0.5177 (0.5225)  labels_encoder: 0.5177 (0.5225)  labels_encoder_unscaled: 0.5177 (0.5225)  time: 0.1432  data: 0.0002  max mem: 1206
Epoch: [4]  [1150/1510]  eta: 0:00:48  lr: 0.000000  loss: 0.5006 (0.5220)  labels_encoder: 0.5006 (0.5220)  labels_encoder_unscaled: 0.5006 (0.5220)  time: 0.1356  data: 0.0002  max mem: 1206
Epoch: [4]  [1200/1510]  eta: 0:00:42  lr: 0.000000  loss: 0.5066 (0.5220)  labels_encoder: 0.5066 (0.5220)  labels_encoder_unscaled: 0.5066 (0.5220)  time: 0.1399  data: 0.0002  max mem: 1206
Epoch: [4]  [1250/1510]  eta: 0:00:35  lr: 0.000000  loss: 0.4954 (0.5217)  labels_encoder: 0.4954 (0.5217)  labels_encoder_unscaled: 0.4954 (0.5217)  time: 0.1423  data: 0.0003  max mem: 1206
Epoch: [4]  [1300/1510]  eta: 0:00:28  lr: 0.000000  loss: 0.4761 (0.5214)  labels_encoder: 0.4761 (0.5214)  labels_encoder_unscaled: 0.4761 (0.5214)  time: 0.1367  data: 0.0002  max mem: 1206
Epoch: [4]  [1350/1510]  eta: 0:00:21  lr: 0.000000  loss: 0.5277 (0.5212)  labels_encoder: 0.5277 (0.5212)  labels_encoder_unscaled: 0.5277 (0.5212)  time: 0.1306  data: 0.0002  max mem: 1206
Epoch: [4]  [1400/1510]  eta: 0:00:14  lr: 0.000000  loss: 0.5116 (0.5209)  labels_encoder: 0.5116 (0.5209)  labels_encoder_unscaled: 0.5116 (0.5209)  time: 0.1273  data: 0.0002  max mem: 1206
Epoch: [4]  [1450/1510]  eta: 0:00:08  lr: 0.000000  loss: 0.5531 (0.5207)  labels_encoder: 0.5531 (0.5207)  labels_encoder_unscaled: 0.5531 (0.5207)  time: 0.1240  data: 0.0002  max mem: 1206
Epoch: [4]  [1500/1510]  eta: 0:00:01  lr: 0.000000  loss: 0.5290 (0.5211)  labels_encoder: 0.5290 (0.5211)  labels_encoder_unscaled: 0.5290 (0.5211)  time: 0.1305  data: 0.0003  max mem: 1206
Epoch: [4]  [1509/1510]  eta: 0:00:00  lr: 0.000000  loss: 0.4616 (0.5208)  labels_encoder: 0.4616 (0.5208)  labels_encoder_unscaled: 0.4616 (0.5208)  time: 0.1255  data: 0.0003  max mem: 1206
Epoch: [4] Total time: 0:03:25 (0.1359 s / it)
Averaged stats: lr: 0.000000  loss: 0.4616 (0.5208)  labels_encoder: 0.4616 (0.5208)  labels_encoder_unscaled: 0.4616 (0.5208)
Test:  [  0/559]  eta: 0:15:25  loss: 0.5733 (0.5733)  labels_encoder: 0.5733 (0.5733)  labels_encoder_unscaled: 0.5733 (0.5733)  time: 1.6560  data: 1.5972  max mem: 1206
Test:  [ 50/559]  eta: 0:00:47  loss: 0.8760 (0.9070)  labels_encoder: 0.8760 (0.9070)  labels_encoder_unscaled: 0.8760 (0.9070)  time: 0.0512  data: 0.0010  max mem: 1206
Test:  [100/559]  eta: 0:00:34  loss: 0.5227 (0.8486)  labels_encoder: 0.5227 (0.8486)  labels_encoder_unscaled: 0.5227 (0.8486)  time: 0.0581  data: 0.0002  max mem: 1206
Test:  [150/559]  eta: 0:00:28  loss: 0.5217 (0.8714)  labels_encoder: 0.5217 (0.8714)  labels_encoder_unscaled: 0.5217 (0.8714)  time: 0.0604  data: 0.0011  max mem: 1206
Test:  [200/559]  eta: 0:00:24  loss: 0.5747 (0.8139)  labels_encoder: 0.5747 (0.8139)  labels_encoder_unscaled: 0.5747 (0.8139)  time: 0.0591  data: 0.0002  max mem: 1206
Test:  [250/559]  eta: 0:00:20  loss: 0.7056 (0.9277)  labels_encoder: 0.7056 (0.9277)  labels_encoder_unscaled: 0.7056 (0.9277)  time: 0.0665  data: 0.0002  max mem: 1206
Test:  [300/559]  eta: 0:00:17  loss: 1.2029 (0.9813)  labels_encoder: 1.2029 (0.9813)  labels_encoder_unscaled: 1.2029 (0.9813)  time: 0.0571  data: 0.0002  max mem: 1206
Test:  [350/559]  eta: 0:00:13  loss: 0.7768 (1.0051)  labels_encoder: 0.7768 (1.0051)  labels_encoder_unscaled: 0.7768 (1.0051)  time: 0.0597  data: 0.0002  max mem: 1206
Test:  [400/559]  eta: 0:00:10  loss: 0.3288 (0.9788)  labels_encoder: 0.3288 (0.9788)  labels_encoder_unscaled: 0.3288 (0.9788)  time: 0.0567  data: 0.0002  max mem: 1206
Test:  [450/559]  eta: 0:00:06  loss: 0.4620 (0.9527)  labels_encoder: 0.4620 (0.9527)  labels_encoder_unscaled: 0.4620 (0.9527)  time: 0.0571  data: 0.0002  max mem: 1206
Test:  [500/559]  eta: 0:00:03  loss: 0.6252 (0.9323)  labels_encoder: 0.6252 (0.9323)  labels_encoder_unscaled: 0.6252 (0.9323)  time: 0.0508  data: 0.0001  max mem: 1206
Test:  [550/559]  eta: 0:00:00  loss: 0.7230 (0.9070)  labels_encoder: 0.7230 (0.9070)  labels_encoder_unscaled: 0.7230 (0.9070)  time: 0.0538  data: 0.0001  max mem: 1206
Test:  [558/559]  eta: 0:00:00  loss: 0.3606 (0.9008)  labels_encoder: 0.3606 (0.9008)  labels_encoder_unscaled: 0.3606 (0.9008)  time: 0.0472  data: 0.0001  max mem: 1206
Test: Total time: 0:00:34 (0.0625 s / it)
Averaged stats: loss: 0.3606 (0.9008)  labels_encoder: 0.3606 (0.9008)  labels_encoder_unscaled: 0.3606 (0.9008)
(21, 71496)
(21, 71496)
[Epoch-4] [IDU-tvseries_kin_features.pickle] mAP: 0.1283, mcAP: 0.8812

BaseballPitch: 0.0644
BasketballDunk: 0.1074
Billiards: 0.0045
CleanAndJerk: 0.4041
CliffDiving: 0.4201
CricketBowling: 0.0546
CricketShot: 0.0976
Diving: 0.0076
FrisbeeCatch: 0.1141
GolfSwing: 0.0561
HammerThrow: 0.1224
HighJump: 0.0487
JavelinThrow: 0.0537
LongJump: 0.3114
PoleVault: 0.0980
Shotput: 0.1360
SoccerPenalty: 0.0513
TennisSwing: 0.1620
ThrowDiscus: 0.0959
VolleyballSpiking: 0.1558
Training time 0:16:18
